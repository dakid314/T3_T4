{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 13:46:40.099004: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-23 13:46:40.101282: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-07-23 13:46:40.101289: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-23 13:46:40.619332: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-07-23 13:46:40.619345: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-07-23 13:46:40.619355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (A7LAB): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import libfeatureselection\n",
    "import libpybiofeature\n",
    "from libmodel import t3mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/md0/Users/georgezhao/Source/TxSEml_Addon'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "work_Dir = utils.workdir.workdir(os.getcwd(), 4)\n",
    "work_Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "protype, cter_bool, db_size = 2, False, 'small'\n",
    "Tx_arg = {\n",
    "    \"type\": f'T{protype}',\n",
    "    # 'seq_id': os.path.join(work_Dir, *['data', 'db', f'T{protype}', 'seq_id.json']),\n",
    "    'shufflesplit_index_file': os.path.join(work_Dir, *['data', 'db', f'T{protype}', 'seq_id_shufflesplit.json']),\n",
    "    'fasta': {\n",
    "        'cter': cter_bool,\n",
    "        'sp': {\n",
    "            'p': \"data/T2SE/spT2SE.fasta\",\n",
    "            'n': \"data/T2SE/sp_paired_non_t2se.fasta\"\n",
    "        },\n",
    "        'nosp': {\n",
    "            'p': \"data/T2SE/nospT2SE.fasta\",\n",
    "            'n': \"data/T2SE/nosp_paired_non_t2se.fasta\"\n",
    "        },\n",
    "    },\n",
    "    'bliulab': {\n",
    "        'PC': {\n",
    "            'sp': {\n",
    "                'p': \"out/libfeatureselection/SP_feature_research/featuredb/spT2SE_PCPseAAC.csv\",\n",
    "                'n': \"out/libfeatureselection/SP_feature_research/featuredb/sp_paired_non_t2se_PCPseAAC.csv\",\n",
    "            },\n",
    "            'nosp': {\n",
    "                'p': \"out/libfeatureselection/SP_feature_research/featuredb/nospT2SE_PCPseAAC.csv\",\n",
    "                'n': \"out/libfeatureselection/SP_feature_research/featuredb/nosp_paired_non_t2se_PCPseAAC.csv\"\n",
    "            },\n",
    "        },\n",
    "        'SC': {\n",
    "            'sp': {\n",
    "                'p': \"out/libfeatureselection/SP_feature_research/featuredb/spT2SE_SCPseAAC.csv\",\n",
    "                'n': \"out/libfeatureselection/SP_feature_research/featuredb/sp_paired_non_t2se_SCPseAAC.csv\",\n",
    "            },\n",
    "            'nosp': {\n",
    "                'p': \"out/libfeatureselection/SP_feature_research/featuredb/nospT2SE_SCPseAAC.csv\",\n",
    "                'n': \"out/libfeatureselection/SP_feature_research/featuredb/nosp_paired_non_t2se_SCPseAAC.csv\"\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"ss\": {\n",
    "        'sp': {\n",
    "            'p': \"out/libfeatureselection/SP_feature_research/featuredb/bert/sp_p_ss.pkl\",\n",
    "            'n': \"out/libfeatureselection/SP_feature_research/featuredb/bert/sp_n_ss.pkl\",\n",
    "        },\n",
    "        'nosp': {\n",
    "            'p': \"out/libfeatureselection/SP_feature_research/featuredb/bert/nosp_p_ss.pkl\",\n",
    "            'n': \"out/libfeatureselection/SP_feature_research/featuredb/bert/nosp_n_ss.pkl\",\n",
    "        },\n",
    "    },\n",
    "    \"sa\": {\n",
    "        'sp': {\n",
    "            'p': \"out/libfeatureselection/SP_feature_research/featuredb/bert/sp_p_sa.pkl\",\n",
    "            'n': \"out/libfeatureselection/SP_feature_research/featuredb/bert/sp_n_sa.pkl\",\n",
    "        },\n",
    "        'nosp': {\n",
    "            'p': \"out/libfeatureselection/SP_feature_research/featuredb/bert/nosp_p_sa.pkl\",\n",
    "            'n': \"out/libfeatureselection/SP_feature_research/featuredb/bert/nosp_n_sa.pkl\",\n",
    "        },\n",
    "    },\n",
    "    \"diso\": {\n",
    "        'sp': {\n",
    "            'p': \"out/libfeatureselection/SP_feature_research/featuredb/bert/sp_p_diso.pkl\",\n",
    "            'n': \"out/libfeatureselection/SP_feature_research/featuredb/bert/sp_n_diso.pkl\",\n",
    "        },\n",
    "        'nosp': {\n",
    "            'p': \"out/libfeatureselection/SP_feature_research/featuredb/bert/nosp_p_diso.pkl\",\n",
    "            'n': \"out/libfeatureselection/SP_feature_research/featuredb/bert/nosp_n_diso.pkl\",\n",
    "        },\n",
    "    },\n",
    "    'possum': {\n",
    "        'index': \"out/libfeatureselection/SP_feature_research/featuredb/possum/possum_index.json\",\n",
    "        'pssm_fdb_pattern': \"out/libfeatureselection/SP_feature_research/featuredb/possum/{zipid}_pssm_features.zip\",\n",
    "        'pssm_rdb_pattern': \"out/libfeatureselection/SP_feature_research/featuredb/possum/{zipid}_pssm_files.zip\"\n",
    "    },\n",
    "    'model': {\n",
    "        'size': db_size,\n",
    "        'cter': cter_bool,\n",
    "        \"path_to_save_dir\": f\"out/libfeatureselection/T2/model/T4EffPred_SP/model/\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_id_dict = {\n",
    "    \"sp\": {\n",
    "        \"p\": [ seq.id for seq in SeqIO.parse(Tx_arg['fasta']['sp']['p'], \"fasta\") ],\n",
    "        \"n\": [ seq.id for seq in SeqIO.parse(Tx_arg['fasta']['sp']['n'], \"fasta\") ],\n",
    "    },\n",
    "    \"nosp\": {\n",
    "        \"p\": [ seq.id for seq in SeqIO.parse(Tx_arg['fasta']['nosp']['p'], \"fasta\") ],\n",
    "        \"n\": [ seq.id for seq in SeqIO.parse(Tx_arg['fasta']['nosp']['n'], \"fasta\") ],\n",
    "    },\n",
    "}\n",
    "with open(f\"data/T2SE/seq_id.json\", \"w+\", encoding=\"UTF-8\") as f:\n",
    "    json.dump(\n",
    "        obj=seq_id_dict,\n",
    "        fp=f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_set = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "possum_index_dict = None\n",
    "with open(Tx_arg['possum']['index'], 'r', encoding='UTF-8') as f:\n",
    "    possum_index_dict = json.load(f)\n",
    "\n",
    "feature_data_set.append({\n",
    "    \"name\": \"PSSM_feature\",\n",
    "    \"sp_p\": libpybiofeature.libdataloader.pssm_tools.get_all_pssm_feature(\n",
    "        possum_index_list=possum_index_dict['data']['sp_p'],\n",
    "        feature_name_list=[\n",
    "            'smoothed_pssm', 'aac_pssm',\n",
    "            'rpm_pssm', 'pse_pssm', 'dp_pssm',\n",
    "        ],\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        path_to_with_pattern=Tx_arg['possum']['pssm_fdb_pattern']\n",
    "    ).loc[seq_id_dict['sp']['p'], :],\n",
    "    \"sp_n\": libpybiofeature.libdataloader.pssm_tools.get_all_pssm_feature(\n",
    "        possum_index_list=possum_index_dict['data']['sp_n'],\n",
    "        feature_name_list=[\n",
    "            'smoothed_pssm', 'aac_pssm',\n",
    "            'rpm_pssm', 'pse_pssm', 'dp_pssm',\n",
    "        ],\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        path_to_with_pattern=Tx_arg['possum']['pssm_fdb_pattern']\n",
    "    ).loc[seq_id_dict['sp']['n'], :],\n",
    "    \"nosp_p\": libpybiofeature.libdataloader.pssm_tools.get_all_pssm_feature(\n",
    "        possum_index_list=possum_index_dict['data']['nosp_p'],\n",
    "        feature_name_list=[\n",
    "            'smoothed_pssm', 'aac_pssm',\n",
    "            'rpm_pssm', 'pse_pssm', 'dp_pssm',\n",
    "        ],\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        path_to_with_pattern=Tx_arg['possum']['pssm_fdb_pattern']\n",
    "    ).loc[seq_id_dict['nosp']['p'], :],\n",
    "    \"nosp_n\": libpybiofeature.libdataloader.pssm_tools.get_all_pssm_feature(\n",
    "        possum_index_list=possum_index_dict['data']['nosp_n'],\n",
    "        feature_name_list=[\n",
    "            'smoothed_pssm', 'aac_pssm',\n",
    "            'rpm_pssm', 'pse_pssm', 'dp_pssm',\n",
    "        ],\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        path_to_with_pattern=Tx_arg['possum']['pssm_fdb_pattern']\n",
    "    ).loc[seq_id_dict['nosp']['n'], :],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_AAC: 100%|██████████| 44/44 [00:00<00:00, 53710.53it/s]\n",
      "sp_n_AAC: 100%|██████████| 44/44 [00:00<00:00, 99060.32it/s]\n",
      "nosp_p_AAC: 100%|██████████| 11/11 [00:00<00:00, 52191.57it/s]\n",
      "nosp_n_AAC: 100%|██████████| 11/11 [00:00<00:00, 64079.64it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"AAC\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p'\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n'\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p'\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_DAC: 100%|██████████| 44/44 [00:00<00:00, 8925.78it/s]\n",
      "sp_n_DAC: 100%|██████████| 44/44 [00:00<00:00, 16317.36it/s]\n",
      "nosp_p_DAC: 100%|██████████| 11/11 [00:00<00:00, 11069.42it/s]\n",
      "nosp_n_DAC: 100%|██████████| 11/11 [00:00<00:00, 15267.16it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"DAC\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p'\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n'\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p'\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_TAC: 100%|██████████| 44/44 [00:00<00:00, 1938.99it/s]\n",
      "sp_n_TAC: 100%|██████████| 44/44 [00:00<00:00, 2132.14it/s]\n",
      "nosp_p_TAC: 100%|██████████| 11/11 [00:00<00:00, 1825.56it/s]\n",
      "nosp_n_TAC: 100%|██████████| 11/11 [00:00<00:00, 2096.10it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"TAC\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_tac_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p'\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_tac_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n'\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_tac_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p'\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_tac_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_CTDC: 100%|██████████| 44/44 [00:00<00:00, 17002.89it/s]\n",
      "sp_n_CTDC: 100%|██████████| 44/44 [00:00<00:00, 25455.09it/s]\n",
      "nosp_p_CTDC: 100%|██████████| 11/11 [00:00<00:00, 15028.45it/s]\n",
      "nosp_n_CTDC: 100%|██████████| 11/11 [00:00<00:00, 24979.61it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"CTDC\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_CTDC_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p'\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_CTDC_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n'\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_CTDC_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p'\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_CTDC_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_CTDD: 100%|██████████| 44/44 [00:00<00:00, 696.32it/s]\n",
      "sp_n_CTDD: 100%|██████████| 44/44 [00:00<00:00, 1060.68it/s]\n",
      "nosp_p_CTDD: 100%|██████████| 11/11 [00:00<00:00, 609.94it/s]\n",
      "nosp_n_CTDD: 100%|██████████| 11/11 [00:00<00:00, 1196.17it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"CTDD\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_CTDD_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p'\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_CTDD_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n'\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_CTDD_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p'\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_CTDD_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_CTDT: 100%|██████████| 44/44 [00:00<00:00, 912.67it/s]\n",
      "sp_n_CTDT: 100%|██████████| 44/44 [00:00<00:00, 1435.42it/s]\n",
      "nosp_p_CTDT: 100%|██████████| 11/11 [00:00<00:00, 840.60it/s]\n",
      "nosp_n_CTDT: 100%|██████████| 11/11 [00:00<00:00, 1572.51it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"CTDT\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_CTDT_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p'\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_CTDT_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n'\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_CTDT_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p'\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_CTDT_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_CKSAAP: 100%|██████████| 44/44 [00:00<00:00, 1445.24it/s]\n",
      "sp_n_CKSAAP: 100%|██████████| 44/44 [00:00<00:00, 2250.90it/s]\n",
      "nosp_p_CKSAAP: 100%|██████████| 11/11 [00:00<00:00, 1376.78it/s]\n",
      "nosp_n_CKSAAP: 100%|██████████| 11/11 [00:00<00:00, 2498.10it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"CKSAAP\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_CKSAAP_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p'\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_CKSAAP_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n'\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_CKSAAP_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p'\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_CKSAAP_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_CTriad: 100%|██████████| 44/44 [00:00<00:00, 6835.42it/s]\n",
      "sp_n_CTriad: 100%|██████████| 44/44 [00:00<00:00, 10331.38it/s]\n",
      "nosp_p_CTriad: 100%|██████████| 11/11 [00:00<00:00, 6359.39it/s]\n",
      "nosp_n_CTriad: 100%|██████████| 11/11 [00:00<00:00, 9913.48it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"CJ\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_conjoint_td_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p'\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_conjoint_td_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n'\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_conjoint_td_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p'\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_conjoint_td_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"SS-100-Onehot\",\n",
    "    \"sp_p\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['ss']['sp']['p'],\n",
    "        id_list=seq_id_dict['sp']['p'],\n",
    "        dim=3\n",
    "    ),\n",
    "    \"sp_n\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['ss']['sp']['n'],\n",
    "        id_list=seq_id_dict['sp']['n'],\n",
    "        dim=3\n",
    "    ),\n",
    "    \"nosp_p\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['ss']['nosp']['p'],\n",
    "        id_list=seq_id_dict['nosp']['p'],\n",
    "        dim=3\n",
    "    ),\n",
    "    \"nosp_n\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['ss']['nosp']['n'],\n",
    "        id_list=seq_id_dict['nosp']['n'],\n",
    "        dim=3\n",
    "    )\n",
    "})\n",
    "feature_data_set.append({\n",
    "    \"name\": \"SA-100-Onehot\",\n",
    "    \"sp_p\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['sa']['sp']['p'],\n",
    "        id_list=seq_id_dict['sp']['p'],\n",
    "        dim=2\n",
    "    ),\n",
    "    \"sp_n\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['sa']['sp']['n'],\n",
    "        id_list=seq_id_dict['sp']['n'],\n",
    "        dim=2\n",
    "    ),\n",
    "    \"nosp_p\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['sa']['nosp']['p'],\n",
    "        id_list=seq_id_dict['nosp']['p'],\n",
    "        dim=2\n",
    "    ),\n",
    "    \"nosp_n\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['sa']['nosp']['n'],\n",
    "        id_list=seq_id_dict['nosp']['n'],\n",
    "        dim=2\n",
    "    )\n",
    "})\n",
    "feature_data_set.append({\n",
    "    \"name\": \"DISO-100-Onehot\",\n",
    "    \"sp_p\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['diso']['sp']['p'],\n",
    "        id_list=seq_id_dict['sp']['p'],\n",
    "        dim=2\n",
    "    ),\n",
    "    \"sp_n\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['diso']['sp']['n'],\n",
    "        id_list=seq_id_dict['sp']['n'],\n",
    "        dim=2\n",
    "    ),\n",
    "    \"nosp_p\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['diso']['nosp']['p'],\n",
    "        id_list=seq_id_dict['nosp']['p'],\n",
    "        dim=2\n",
    "    ),\n",
    "    \"nosp_n\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['diso']['nosp']['n'],\n",
    "        id_list=seq_id_dict['nosp']['n'],\n",
    "        dim=2\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_PSE_data(\n",
    "    path_to_csv: str,\n",
    "    path_to_fasta: str,\n",
    "):\n",
    "    df = pd.read_csv(path_to_csv, index_col=None, header=None)\n",
    "    df.index = [\n",
    "        seq.id for seq in SeqIO.parse(path_to_fasta, \"fasta\")\n",
    "    ]\n",
    "    df.columns = list(\"ACDEFGHIKLMNPQRSTVWY\") + [\n",
    "        str(i) for i in range(1, (df.shape[1] - 20) + 1)\n",
    "    ]\n",
    "    return df\n",
    "\n",
    "feature_data_set.append({\n",
    "    \"name\": \"PCPseAAC\",\n",
    "    \"sp_p\": read_PSE_data(\n",
    "        path_to_csv=Tx_arg[\"bliulab\"]['PC']['sp']['p'],\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "    ),\n",
    "    \"sp_n\": read_PSE_data(\n",
    "        path_to_csv=Tx_arg[\"bliulab\"]['PC']['sp']['n'],\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "    ),\n",
    "    \"nosp_p\": read_PSE_data(\n",
    "        path_to_csv=Tx_arg[\"bliulab\"]['PC']['nosp']['p'],\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "    ),\n",
    "    \"nosp_n\": read_PSE_data(\n",
    "        path_to_csv=Tx_arg[\"bliulab\"]['PC']['nosp']['n'],\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "    )\n",
    "})\n",
    "feature_data_set.append({\n",
    "    \"name\": \"SCPseAAC\",\n",
    "    \"sp_p\": read_PSE_data(\n",
    "        path_to_csv=Tx_arg[\"bliulab\"]['SC']['sp']['p'],\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "    ),\n",
    "    \"sp_n\": read_PSE_data(\n",
    "        path_to_csv=Tx_arg[\"bliulab\"]['SC']['sp']['n'],\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "    ),\n",
    "    \"nosp_p\": read_PSE_data(\n",
    "        path_to_csv=Tx_arg[\"bliulab\"]['SC']['nosp']['p'],\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "    ),\n",
    "    \"nosp_n\": read_PSE_data(\n",
    "        path_to_csv=Tx_arg[\"bliulab\"]['SC']['nosp']['n'],\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pn_dataset(\n",
    "    p_f: pd.DataFrame,\n",
    "    p_l: np.ndarray,\n",
    "    n_f: pd.DataFrame,\n",
    "    n_l: np.ndarray\n",
    "):\n",
    "    t_f = pd.concat([p_f, n_f])\n",
    "    t_l = np.concatenate([p_l, n_l])\n",
    "\n",
    "    return t_f, t_l\n",
    "\n",
    "# 合并feature_selected成数据集\n",
    "data_set_split = {\n",
    "    datatype: pd.concat([\n",
    "        item[datatype] for item in feature_data_set\n",
    "    ], axis=1)\n",
    "    for datatype in [\"sp_p\", \"sp_n\", \"nosp_p\", \"nosp_n\"]\n",
    "}\n",
    "label_set_split = {\n",
    "    datatype: np.ones(\n",
    "        shape=(feature_data_set[0][datatype].shape[0], ))\n",
    "    for datatype in [\"sp_p\", \"nosp_p\",]\n",
    "} | {\n",
    "    datatype: np.zeros(\n",
    "        shape=(feature_data_set[0][datatype].shape[0], ))\n",
    "    for datatype in [\"sp_n\", \"nosp_n\",]\n",
    "}\n",
    "\n",
    "t_f, t_l = merge_pn_dataset(\n",
    "    p_f=data_set_split[\"sp_p\"],\n",
    "    p_l=label_set_split[\"sp_p\"],\n",
    "    n_f=data_set_split[\"sp_n\"],\n",
    "    n_l=label_set_split[\"sp_n\"],\n",
    ")\n",
    "v_f, v_l = merge_pn_dataset(\n",
    "    p_f=data_set_split[\"nosp_p\"],\n",
    "    p_l=label_set_split[\"nosp_p\"],\n",
    "    n_f=data_set_split[\"nosp_n\"],\n",
    "    n_l=label_set_split[\"nosp_n\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'out/libfeatureselection/T2/model/T4EffPred_SP/model//model/'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 丢入model中进行训练\n",
    "model_path = f\"{Tx_arg['model']['path_to_save_dir']}/model/\"\n",
    "os.makedirs(\n",
    "    model_path,\n",
    "    exist_ok=True\n",
    ")\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from libfeatureselection import model, model_space\n",
    "n_jobs = (\n",
    "    (os.cpu_count() - 2)\n",
    "    if \"n_jobs\" not in os.environ or os.environ['n_jobs'] == \"\" else\n",
    "    int(os.environ['n_jobs'])\n",
    ")\n",
    "n_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from datetime import datetime\n",
    "import math\n",
    "import pickle\n",
    "import gzip\n",
    "import itertools\n",
    "import functools\n",
    "\n",
    "from src.libmodel import common, model_optimite\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "mpl.rcParams['svg.fonttype'] = 'none'\n",
    "mpl.rcParams['pdf.use14corefonts'] = False\n",
    "# mpl.rcParams['pdf.usecorefonts'] = True\n",
    "mpl.rcParams['pdf.compression'] = 9\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use(['science', 'nature'])\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_score, accuracy_score, f1_score, matthews_corrcoef, auc\n",
    "\n",
    "def get_evaluation(label: list, pred: list, pro_cutoff: float = None):\n",
    "    pred = np.nan_to_num(\n",
    "        pred, copy=True, nan=0.0\n",
    "    )\n",
    "    fpr, tpr, thresholds = roc_curve(label, pred)\n",
    "    if pro_cutoff is None:\n",
    "        best_one_optimal_idx = np.argmax(tpr - fpr)\n",
    "        pro_cutoff = thresholds[best_one_optimal_idx]\n",
    "    pred_l = [1 if i >= pro_cutoff else 0 for i in pred]\n",
    "    confusion_matrix_1d = confusion_matrix(label, pred_l).ravel()\n",
    "    confusion_dict = {N: n for N, n in zip(['tn', 'fp', 'fn', 'tp'], list(\n",
    "        confusion_matrix_1d * 2 / np.sum(confusion_matrix_1d)))}\n",
    "    evaluation = {\n",
    "        \"accuracy\": accuracy_score(label, pred_l),\n",
    "        \"precision\": precision_score(label, pred_l),\n",
    "        \"f1_score\": f1_score(label, pred_l),\n",
    "        \"mmc\": matthews_corrcoef(label, pred_l),\n",
    "        \"rocAUC\": auc(fpr, tpr),\n",
    "        \"specificity\": confusion_dict['tn'] / (confusion_dict['tn'] + confusion_dict['fp']),\n",
    "        \"sensitivity\": confusion_dict['tp'] / (confusion_dict['tp'] + confusion_dict['fn']),\n",
    "        # \"confusion_matrix\": confusion_dict,\n",
    "        # \"_roc_Data\": {'fpr': list(fpr), 'tpr': list(tpr)},\n",
    "        'pro_cutoff': pro_cutoff\n",
    "    }\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "def plot_roc_curve(target, pred, path_to_: str):\n",
    "    fpr, tpr, thresholds = roc_curve(target, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(19.2 / 4, 10.8 / 4))\n",
    "    plt.axis('square')\n",
    "    plt.plot(\n",
    "        fpr, tpr, color='red', lw=2,\n",
    "        label='ROC curve (area = %0.2f)' % roc_auc\n",
    "    )\n",
    "    plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC) curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.savefig(f\"{path_to_}\", transparent=True)\n",
    "    plt.clf()\n",
    "\n",
    "submodel_choise = None\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "class T4SEXGB_Model(common.Model_Final):\n",
    "\n",
    "    def __init__(self, cv, desc):\n",
    "        super().__init__(cv, desc=desc)\n",
    "        self.model = None\n",
    "\n",
    "        self.side_store = None\n",
    "        pass\n",
    "\n",
    "    def tranmodel(self, f, l):\n",
    "        super().tranmodel(f, l)\n",
    "        self.model = [\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=300, max_features='sqrt', n_jobs=n_jobs),\n",
    "            GaussianNB(),\n",
    "            XGBClassifier(\n",
    "                n_estimators=700, learning_rate=0.1, n_jobs=n_jobs),\n",
    "            LogisticRegression(\n",
    "                multi_class='auto', solver='liblinear', n_jobs=n_jobs),\n",
    "            GradientBoostingClassifier(\n",
    "                n_estimators=300, learning_rate=0.2), SVC(gamma=0.03125, C=4, probability=True),\n",
    "            MLPClassifier(\n",
    "                hidden_layer_sizes=(48, 16), max_iter=1000),\n",
    "            ExtraTreesClassifier(\n",
    "                n_estimators=900, max_features='sqrt', n_jobs=n_jobs),\n",
    "            KNeighborsClassifier(n_neighbors=2, n_jobs=n_jobs)\n",
    "        ]\n",
    "\n",
    "        for i in range(len(self.model)):\n",
    "            self.model[i].fit(f, l)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, f):\n",
    "        super().predict(f)\n",
    "        result = np.stack(\n",
    "            [\n",
    "                self.model[i].predict_proba(f)[:, 1]\n",
    "                for i in range(len(self.model))\n",
    "            ]\n",
    "        ).T\n",
    "        if submodel_choise is None:\n",
    "            result = (result >= 0.5)\n",
    "            return result.sum(axis=1) / len(self.model)\n",
    "        if isinstance(submodel_choise, int) == False or submodel_choise < 0 or submodel_choise >= 8:\n",
    "            raise ValueError(f\"Wrong submodel_choise: {submodel_choise}\")\n",
    "        return result[:, submodel_choise]\n",
    "\n",
    "\n",
    "\n",
    "class T4SEXGB_Trainer:\n",
    "    def __init__(self, ) -> None:\n",
    "        self.classifier_name = \"T4SEXGB\"\n",
    "        self.classifier_class = T4SEXGB_Model\n",
    "        self.classifier_param_dict = {\n",
    "            \"desc\": \"T4SEXGB_SP\",\n",
    "            \"cv\": 5,\n",
    "        }\n",
    "\n",
    "        self.model = None\n",
    "        self.train_best_predicted_pair = None\n",
    "        self.train_best_5C_predicted_pair = None\n",
    "        self.best_predicted_pair = None\n",
    "        self.best_5C_predicted_pair = None\n",
    "        self.start_to_train_time = datetime.now()\n",
    "        self.end_of_train_time = None\n",
    "        pass\n",
    "\n",
    "    def find_best(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        validation: tuple,\n",
    "        merge_validate: bool\n",
    "    ):\n",
    "\n",
    "        self.model = self.classifier_class(\n",
    "            **self.classifier_param_dict\n",
    "        )\n",
    "        self.model.tranmodel(\n",
    "            pd.DataFrame(X,),\n",
    "            y,\n",
    "        )\n",
    "        self.best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                pd.DataFrame(validation[0],),\n",
    "            ), nan=0.0),\n",
    "            validation[1]\n",
    "        ]\n",
    "        self.train_best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                pd.DataFrame(X,),\n",
    "            ), nan=0.0),\n",
    "            y\n",
    "        ]\n",
    "\n",
    "        # 5倍交叉验证\n",
    "        # 合并数据\n",
    "        if merge_validate == True:\n",
    "            full_X = np.concatenate([\n",
    "                X, validation[0]\n",
    "            ])\n",
    "            full_y = np.concatenate([\n",
    "                y, validation[1]\n",
    "            ])\n",
    "        else:\n",
    "            full_X = np.concatenate([\n",
    "                X,\n",
    "            ])\n",
    "            full_y = np.concatenate([\n",
    "                y,\n",
    "            ])\n",
    "\n",
    "        # 跑模型\n",
    "        self.best_5C_predicted_pair = []\n",
    "        self.train_best_5C_predicted_pair = []\n",
    "        for Kfold_id, (train_id, test_id) in enumerate(\n",
    "            StratifiedKFold(\n",
    "                n_splits=5,\n",
    "                shuffle=True,\n",
    "                random_state=42\n",
    "            ).split(full_X, full_y)\n",
    "        ):\n",
    "\n",
    "            # 定义模型并加载参数\n",
    "            fiveC_model = self.classifier_class(\n",
    "                **self.classifier_param_dict,\n",
    "            )\n",
    "\n",
    "            fiveC_model.tranmodel(\n",
    "                pd.DataFrame(full_X[train_id],),\n",
    "                full_y[train_id],\n",
    "            )\n",
    "\n",
    "            # 预测并记录\n",
    "            self.best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    pd.DataFrame(full_X[test_id],),\n",
    "                ), nan=0.0),\n",
    "                full_y[test_id]\n",
    "            ])\n",
    "            self.train_best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    pd.DataFrame(full_X[train_id],),\n",
    "                ), nan=0.0),\n",
    "                full_y[train_id]\n",
    "            ])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_summary(self, path_to_dir: str = None):\n",
    "        os.makedirs(path_to_dir, exist_ok=True)\n",
    "        model_path = \"-\"\n",
    "        if \"SAVE_MODEL\" in os.environ and os.environ['SAVE_MODEL'] == \"1\":\n",
    "\n",
    "            model_path = f\"{path_to_dir}/{self.classifier_name}.pkl\"\n",
    "            if path_to_dir is not None:\n",
    "                with gzip.open(model_path, \"wb\") as f:\n",
    "                    pickle.dump(\n",
    "                        self.grid_search, f\n",
    "                    )\n",
    "\n",
    "        model_score_path = f\"{path_to_dir}/{self.classifier_name}_score.pkl\"\n",
    "        if path_to_dir is not None:\n",
    "            with gzip.open(model_score_path, \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "            with gzip.open(model_score_path + \".train\", \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.train_best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.train_best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "        else:\n",
    "            model_score_path = \"-\"\n",
    "\n",
    "        plot_roc_curve(\n",
    "            target=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "            path_to_=f\"{path_to_dir}/{self.classifier_name}.pdf\"\n",
    "        )\n",
    "\n",
    "        model_information = {\n",
    "            \"Classifier_Name\": self.classifier_name,\n",
    "            \"Optimitied_Param\": dict(),\n",
    "            \"Score\": model_score_path,\n",
    "            \"Model_Path\": model_path,\n",
    "            \"TimeToStartFit\": self.start_to_train_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "\n",
    "        training_testing_performance = get_evaluation(\n",
    "            label=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "        )\n",
    "\n",
    "        # 计算5C中的平均表现\n",
    "        FiveFold_result = {}\n",
    "        for keys in training_testing_performance.keys():\n",
    "            value_list = []\n",
    "            for item in self.best_5C_predicted_pair:\n",
    "\n",
    "                item_performance = get_evaluation(\n",
    "                    label=item[1],\n",
    "                    pred=item[0],\n",
    "                )\n",
    "                value_list.append(item_performance[keys])\n",
    "\n",
    "            if keys == \"pro_cutoff\":\n",
    "                FiveFold_result[keys] = value_list\n",
    "            else:\n",
    "                FiveFold_result[keys] = sum(value_list) / len(value_list)\n",
    "\n",
    "        self.end_of_train_time = datetime.now()\n",
    "        model_information[\"TimeOfSummary\"] = self.end_of_train_time.strftime(\n",
    "            \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "        model_information[\"TimeSpend\"] = str(\n",
    "            self.end_of_train_time - self.start_to_train_time\n",
    "        )\n",
    "\n",
    "        return model_information, training_testing_performance, FiveFold_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 30.\n",
      "  warnings.warn(\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 30.\n",
      "  warnings.warn(\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 30.\n",
      "  warnings.warn(\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 30.\n",
      "  warnings.warn(\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 30.\n",
      "  warnings.warn(\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 30.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Classifier_Name': 'T4SEXGB',\n",
       "  'Optimitied_Param': {},\n",
       "  'Score': 'out/libfeatureselection/T2/T4SEXGB_SP//T4SEXGB_score.pkl',\n",
       "  'Model_Path': '-',\n",
       "  'TimeToStartFit': '2023-07-23 13:46:47',\n",
       "  'TimeOfSummary': '2023-07-23 13:48:12',\n",
       "  'TimeSpend': '0:01:25.504227'},\n",
       " {'accuracy': 0.5454545454545454,\n",
       "  'precision': 0.5294117647058824,\n",
       "  'f1_score': 0.6428571428571428,\n",
       "  'mmc': 0.10846522890932808,\n",
       "  'rocAUC': 0.5041322314049587,\n",
       "  'specificity': 0.2727272727272727,\n",
       "  'sensitivity': 0.8181818181818182,\n",
       "  'pro_cutoff': 0.2222222222222222},\n",
       " {'accuracy': 0.9660130718954247,\n",
       "  'precision': 0.9800000000000001,\n",
       "  'f1_score': 0.96437564499484,\n",
       "  'mmc': 0.9352532698929548,\n",
       "  'rocAUC': 0.9793209876543209,\n",
       "  'specificity': 0.9777777777777779,\n",
       "  'sensitivity': 0.9527777777777778,\n",
       "  'pro_cutoff': [0.8888888888888888,\n",
       "   0.7777777777777778,\n",
       "   0.6666666666666666,\n",
       "   0.6666666666666666,\n",
       "   0.8888888888888888]})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T4SEXGB_Trainer().find_best(\n",
    "    X=t_f.values,\n",
    "    y=t_l,\n",
    "    validation=(\n",
    "        v_f.values,\n",
    "        v_l,\n",
    "    ),\n",
    "    merge_validate=False\n",
    ").get_summary(\n",
    "    path_to_dir=\"out/libfeatureselection/T2/T4SEXGB_SP/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TxSEml_Backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
