{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 11:57:37.075422: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-23 11:57:37.077695: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-07-23 11:57:37.077702: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-23 11:57:37.617111: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-07-23 11:57:37.617124: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-07-23 11:57:37.617135: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (A7LAB): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import libfeatureselection\n",
    "import libpybiofeature\n",
    "from libmodel import t3mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/md0/Users/georgezhao/Source/TxSEml_Addon'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "work_Dir = utils.workdir.workdir(os.getcwd(), 4)\n",
    "work_Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "protype, cter_bool, db_size = 2, False, 'small'\n",
    "Tx_arg = {\n",
    "    \"type\": f'T{protype}',\n",
    "    # 'seq_id': os.path.join(work_Dir, *['data', 'db', f'T{protype}', 'seq_id.json']),\n",
    "    'shufflesplit_index_file': os.path.join(work_Dir, *['data', 'db', f'T{protype}', 'seq_id_shufflesplit.json']),\n",
    "    'fasta': {\n",
    "        'cter': cter_bool,\n",
    "        'sp': {\n",
    "            'p': \"data/T2SE/spT2SE.fasta\",\n",
    "            'n': \"data/T2SE/sp_paired_non_t2se.fasta\"\n",
    "        },\n",
    "        'nosp': {\n",
    "            'p': \"data/T2SE/nospT2SE.fasta\",\n",
    "            'n': \"data/T2SE/nosp_paired_non_t2se.fasta\"\n",
    "        },\n",
    "    },\n",
    "    'possum': {\n",
    "        'index': \"out/libfeatureselection/SP_feature_research/featuredb/possum/possum_index.json\",\n",
    "        'pssm_fdb_pattern': \"out/libfeatureselection/SP_feature_research/featuredb/possum/{zipid}_pssm_features.zip\",\n",
    "        'pssm_rdb_pattern': \"out/libfeatureselection/SP_feature_research/featuredb/possum/{zipid}_pssm_files.zip\"\n",
    "    },\n",
    "    'model': {\n",
    "        'size': db_size,\n",
    "        'cter': cter_bool,\n",
    "        \"path_to_save_dir\": f\"out/libfeatureselection/T2/model/Bastion6_SP/model/\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_id_dict = {\n",
    "    \"sp\": {\n",
    "        \"p\": [ seq.id for seq in SeqIO.parse(Tx_arg['fasta']['sp']['p'], \"fasta\") ],\n",
    "        \"n\": [ seq.id for seq in SeqIO.parse(Tx_arg['fasta']['sp']['n'], \"fasta\") ],\n",
    "    },\n",
    "    \"nosp\": {\n",
    "        \"p\": [ seq.id for seq in SeqIO.parse(Tx_arg['fasta']['nosp']['p'], \"fasta\") ],\n",
    "        \"n\": [ seq.id for seq in SeqIO.parse(Tx_arg['fasta']['nosp']['n'], \"fasta\") ],\n",
    "    },\n",
    "}\n",
    "with open(f\"data/T2SE/seq_id.json\", \"w+\", encoding=\"UTF-8\") as f:\n",
    "    json.dump(\n",
    "        obj=seq_id_dict,\n",
    "        fp=f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_set = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_AAC: 100%|██████████| 44/44 [00:00<00:00, 46863.73it/s]\n",
      "sp_n_AAC: 100%|██████████| 44/44 [00:00<00:00, 65005.06it/s]\n",
      "nosp_p_AAC: 100%|██████████| 11/11 [00:00<00:00, 41490.42it/s]\n",
      "nosp_n_AAC: 100%|██████████| 11/11 [00:00<00:00, 58327.87it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"AAC\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p'\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n'\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p'\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_DAC: 100%|██████████| 44/44 [00:00<00:00, 7120.78it/s]\n",
      "sp_n_DAC: 100%|██████████| 44/44 [00:00<00:00, 8396.62it/s]\n",
      "nosp_p_DAC: 100%|██████████| 11/11 [00:00<00:00, 6962.03it/s]\n",
      "nosp_n_DAC: 100%|██████████| 11/11 [00:00<00:00, 9491.33it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"DAC\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p'\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n'\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p'\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_QSO: 100%|██████████| 44/44 [00:00<00:00, 90.75it/s]\n",
      "sp_n_QSO: 100%|██████████| 44/44 [00:00<00:00, 217.28it/s]\n",
      "nosp_p_QSO: 100%|██████████| 11/11 [00:00<00:00, 75.16it/s]\n",
      "nosp_n_QSO: 100%|██████████| 11/11 [00:00<00:00, 159.81it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"QSO\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_qso_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p',\n",
    "        cter=Tx_arg['model']['cter']\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_qso_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n',\n",
    "        cter=Tx_arg['model']['cter']\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_qso_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p',\n",
    "        cter=Tx_arg['model']['cter']\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_qso_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n',\n",
    "        cter=Tx_arg['model']['cter']\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_CTDC: 100%|██████████| 44/44 [00:00<00:00, 12504.19it/s]\n",
      "sp_n_CTDC: 100%|██████████| 44/44 [00:00<00:00, 17675.45it/s]\n",
      "nosp_p_CTDC: 100%|██████████| 11/11 [00:00<00:00, 11618.57it/s]\n",
      "nosp_n_CTDC: 100%|██████████| 11/11 [00:00<00:00, 18469.71it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"CTDC\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_CTDC_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p'\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_CTDC_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n'\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_CTDC_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p'\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_CTDC_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_CTDT: 100%|██████████| 44/44 [00:00<00:00, 501.49it/s]\n",
      "sp_n_CTDT: 100%|██████████| 44/44 [00:00<00:00, 813.45it/s]\n",
      "nosp_p_CTDT: 100%|██████████| 11/11 [00:00<00:00, 475.68it/s]\n",
      "nosp_n_CTDT: 100%|██████████| 11/11 [00:00<00:00, 955.09it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"CTDT\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_CTDT_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p'\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_CTDT_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n'\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_CTDT_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p'\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_CTDT_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_B62: 100%|██████████| 44/44 [00:00<00:00, 11663.36it/s]\n",
      "sp_n_B62: 100%|██████████| 44/44 [00:00<00:00, 16711.89it/s]\n",
      "nosp_p_B62: 100%|██████████| 11/11 [00:00<00:00, 9388.96it/s]\n",
      "nosp_n_B62: 100%|██████████| 11/11 [00:00<00:00, 16430.68it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"B62\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_b62_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p',\n",
    "        cter=Tx_arg['fasta']['cter']\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_b62_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n',\n",
    "        cter=Tx_arg['fasta']['cter']\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_b62_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p',\n",
    "        cter=Tx_arg['fasta']['cter']\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_b62_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n',\n",
    "        cter=Tx_arg['fasta']['cter']\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "possum_index_dict = None\n",
    "with open(Tx_arg['possum']['index'], 'r', encoding='UTF-8') as f:\n",
    "    possum_index_dict = json.load(f)\n",
    "\n",
    "feature_data_set.append({\n",
    "    \"name\": \"PSSM_feature\",\n",
    "    \"sp_p\": libpybiofeature.libdataloader.pssm_tools.get_all_pssm_feature(\n",
    "        possum_index_list=possum_index_dict['data']['sp_p'],\n",
    "        feature_name_list=['dpc_pssm', 's_fpssm', 'pse_pssm', ],\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        path_to_with_pattern=Tx_arg['possum']['pssm_fdb_pattern']\n",
    "    ).loc[seq_id_dict['sp']['p'], :],\n",
    "    \"sp_n\": libpybiofeature.libdataloader.pssm_tools.get_all_pssm_feature(\n",
    "        possum_index_list=possum_index_dict['data']['sp_n'],\n",
    "        feature_name_list=['dpc_pssm', 's_fpssm', 'pse_pssm', ],\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        path_to_with_pattern=Tx_arg['possum']['pssm_fdb_pattern']\n",
    "    ).loc[seq_id_dict['sp']['n'], :],\n",
    "    \"nosp_p\": libpybiofeature.libdataloader.pssm_tools.get_all_pssm_feature(\n",
    "        possum_index_list=possum_index_dict['data']['nosp_p'],\n",
    "        feature_name_list=['dpc_pssm', 's_fpssm', 'pse_pssm', ],\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        path_to_with_pattern=Tx_arg['possum']['pssm_fdb_pattern']\n",
    "    ).loc[seq_id_dict['nosp']['p'], :],\n",
    "    \"nosp_n\": libpybiofeature.libdataloader.pssm_tools.get_all_pssm_feature(\n",
    "        possum_index_list=possum_index_dict['data']['nosp_n'],\n",
    "        feature_name_list=['dpc_pssm', 's_fpssm', 'pse_pssm', ],\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        path_to_with_pattern=Tx_arg['possum']['pssm_fdb_pattern']\n",
    "    ).loc[seq_id_dict['nosp']['n'], :],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pn_dataset(\n",
    "    p_f: pd.DataFrame,\n",
    "    p_l: np.ndarray,\n",
    "    n_f: pd.DataFrame,\n",
    "    n_l: np.ndarray\n",
    "):\n",
    "    t_f = pd.concat([p_f, n_f])\n",
    "    t_l = np.concatenate([p_l, n_l])\n",
    "\n",
    "    return t_f, t_l\n",
    "\n",
    "# 合并feature_selected成数据集\n",
    "data_set_split = {\n",
    "    datatype: pd.concat([\n",
    "        item[datatype] for item in feature_data_set\n",
    "    ], axis=1)\n",
    "    for datatype in [\"sp_p\", \"sp_n\", \"nosp_p\", \"nosp_n\"]\n",
    "}\n",
    "label_set_split = {\n",
    "    datatype: np.ones(\n",
    "        shape=(feature_data_set[0][datatype].shape[0], ))\n",
    "    for datatype in [\"sp_p\", \"nosp_p\",]\n",
    "} | {\n",
    "    datatype: np.zeros(\n",
    "        shape=(feature_data_set[0][datatype].shape[0], ))\n",
    "    for datatype in [\"sp_n\", \"nosp_n\",]\n",
    "}\n",
    "\n",
    "t_f, t_l = merge_pn_dataset(\n",
    "    p_f=data_set_split[\"sp_p\"],\n",
    "    p_l=label_set_split[\"sp_p\"],\n",
    "    n_f=data_set_split[\"sp_n\"],\n",
    "    n_l=label_set_split[\"sp_n\"],\n",
    ")\n",
    "v_f, v_l = merge_pn_dataset(\n",
    "    p_f=data_set_split[\"nosp_p\"],\n",
    "    p_l=label_set_split[\"nosp_p\"],\n",
    "    n_f=data_set_split[\"nosp_n\"],\n",
    "    n_l=label_set_split[\"nosp_n\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'out/libfeatureselection/T2/model/Bastion6_SP/model//model/'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 丢入model中进行训练\n",
    "model_path = f\"{Tx_arg['model']['path_to_save_dir']}/model/\"\n",
    "os.makedirs(\n",
    "    model_path,\n",
    "    exist_ok=True\n",
    ")\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from libfeatureselection import model, model_space\n",
    "n_jobs = (\n",
    "    (os.cpu_count() - 2)\n",
    "    if \"n_jobs\" not in os.environ or os.environ['n_jobs'] == \"\" else\n",
    "    int(os.environ['n_jobs'])\n",
    ")\n",
    "n_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from datetime import datetime\n",
    "import math\n",
    "import pickle\n",
    "import gzip\n",
    "import itertools\n",
    "\n",
    "from src.libmodel import common, model_optimite\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "mpl.rcParams['svg.fonttype'] = 'none'\n",
    "mpl.rcParams['pdf.use14corefonts'] = False\n",
    "# mpl.rcParams['pdf.usecorefonts'] = True\n",
    "mpl.rcParams['pdf.compression'] = 9\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use(['science', 'nature'])\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_score, accuracy_score, f1_score, matthews_corrcoef, auc\n",
    "\n",
    "def get_evaluation(label: list, pred: list, pro_cutoff: float = None):\n",
    "    pred = np.nan_to_num(\n",
    "        pred, copy=True, nan=0.0\n",
    "    )\n",
    "    fpr, tpr, thresholds = roc_curve(label, pred)\n",
    "    if pro_cutoff is None:\n",
    "        best_one_optimal_idx = np.argmax(tpr - fpr)\n",
    "        pro_cutoff = thresholds[best_one_optimal_idx]\n",
    "    pred_l = [1 if i >= pro_cutoff else 0 for i in pred]\n",
    "    confusion_matrix_1d = confusion_matrix(label, pred_l).ravel()\n",
    "    confusion_dict = {N: n for N, n in zip(['tn', 'fp', 'fn', 'tp'], list(\n",
    "        confusion_matrix_1d * 2 / np.sum(confusion_matrix_1d)))}\n",
    "    evaluation = {\n",
    "        \"accuracy\": accuracy_score(label, pred_l),\n",
    "        \"precision\": precision_score(label, pred_l),\n",
    "        \"f1_score\": f1_score(label, pred_l),\n",
    "        \"mmc\": matthews_corrcoef(label, pred_l),\n",
    "        \"rocAUC\": auc(fpr, tpr),\n",
    "        \"specificity\": confusion_dict['tn'] / (confusion_dict['tn'] + confusion_dict['fp']),\n",
    "        \"sensitivity\": confusion_dict['tp'] / (confusion_dict['tp'] + confusion_dict['fn']),\n",
    "        # \"confusion_matrix\": confusion_dict,\n",
    "        # \"_roc_Data\": {'fpr': list(fpr), 'tpr': list(tpr)},\n",
    "        'pro_cutoff': pro_cutoff\n",
    "    }\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "def plot_roc_curve(target, pred, path_to_: str):\n",
    "    fpr, tpr, thresholds = roc_curve(target, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(19.2 / 4, 10.8 / 4))\n",
    "    plt.axis('square')\n",
    "    plt.plot(\n",
    "        fpr, tpr, color='red', lw=2,\n",
    "        label='ROC curve (area = %0.2f)' % roc_auc\n",
    "    )\n",
    "    plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC) curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.savefig(f\"{path_to_}\", transparent=True)\n",
    "    plt.clf()\n",
    "\n",
    "submodel_choise = None\n",
    "\n",
    "svm_param_o = {\n",
    "    \"gamma\": [2**i for i in range(-6, 6 + 1)],\n",
    "    \"C\": [2**i for i in range(-6, 6 + 1)],\n",
    "}\n",
    "\n",
    "class svm_optim_chiosed(model_optimite.svm_optim):\n",
    "    svm_choised_scale = 0.75\n",
    "\n",
    "    def __init__(self, param_o, cv, default_param={\n",
    "        'verbose': False,\n",
    "        'kernel': 'rbf',\n",
    "        'probability': True\n",
    "    }) -> None:\n",
    "        super().__init__(param_o, cv, default_param=default_param)\n",
    "        self.col_name = None\n",
    "        self.origin_col = None\n",
    "        pass\n",
    "\n",
    "    def _chiose_col_name(self, X: pd.DataFrame, scale: float = svm_choised_scale, force: bool = False):\n",
    "        self.origin_col = X.columns\n",
    "        self.col_name = np.random.choice(\n",
    "            X.columns, size=max(1, math.floor(len(X.columns) * scale)), replace=False)\n",
    "        return self\n",
    "\n",
    "    def _get_col_named(self, X: pd.DataFrame):\n",
    "        if self.origin_col.tolist() != X.columns.tolist():\n",
    "            print(self.origin_col, X.columns)\n",
    "            raise RuntimeError('self.origin_col != X.columns')\n",
    "        return X.loc[:, self.col_name]\n",
    "\n",
    "    def best_fit(self, X, y, verbose, n_jobs):\n",
    "        self._chiose_col_name(X)\n",
    "        return super().best_fit(\n",
    "            X=self._get_col_named(X),\n",
    "            y=y,\n",
    "            verbose=verbose,\n",
    "            n_jobs=n_jobs\n",
    "        )\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # self._chiose_col_name(X)\n",
    "        return super().fit(X, y)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return super().predict_proba(\n",
    "            X=self._get_col_named(X)\n",
    "        )\n",
    "\n",
    "    def find_parm(self, X, y, n_jobs, verbose):\n",
    "        return super().find_parm(X, y, n_jobs, verbose=verbose)\n",
    "\n",
    "\n",
    "class Bastion6_Model(common.Model_Final):\n",
    "\n",
    "    def __init__(self, N, cv, desc):\n",
    "        super().__init__(cv, desc=desc)\n",
    "        self.num_of_clsif = N\n",
    "        self.model_svm_2d_list = None\n",
    "\n",
    "        self.feature_dividend_list = None\n",
    "        pass\n",
    "\n",
    "    def tranmodel(self, f, l, feature_dividend_list=[0, 520, 1198, None]):\n",
    "        super().tranmodel(f, l)\n",
    "\n",
    "        self.feature_dividend_list = feature_dividend_list\n",
    "\n",
    "        numofcls_for_group = math.floor(\n",
    "            self.num_of_clsif / (\n",
    "                len(self.feature_dividend_list) - 1\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.model_svm_2d_list = list()\n",
    "        for feature_group_index in range(\n",
    "            1,\n",
    "            len(self.feature_dividend_list)\n",
    "        ):\n",
    "            model_svm_1d_list = list()\n",
    "            for _ in range(numofcls_for_group):\n",
    "                model_svm_1d_list.append(\n",
    "                    svm_optim_chiosed(param_o=svm_param_o, cv=self.cv).best_fit(\n",
    "                        f.iloc[\n",
    "                            :,\n",
    "                            self.feature_dividend_list[\n",
    "                                feature_group_index - 1\n",
    "                            ]:\n",
    "                            self.feature_dividend_list[\n",
    "                                feature_group_index\n",
    "                            ]\n",
    "                        ],\n",
    "                        l,\n",
    "                        verbose=-1,\n",
    "                        n_jobs=n_jobs\n",
    "                    )\n",
    "                )\n",
    "            self.model_svm_2d_list.append(model_svm_1d_list)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, f):\n",
    "        super().predict(f)\n",
    "        numofcls_for_group = math.floor(\n",
    "            self.num_of_clsif / (\n",
    "                len(self.feature_dividend_list) - 1\n",
    "            )\n",
    "        )\n",
    "        result = np.stack(\n",
    "            list(\n",
    "                itertools.chain(*[\n",
    "                    [\n",
    "                        m.predict_proba(\n",
    "                            f.iloc[\n",
    "                                :,\n",
    "                                self.feature_dividend_list[\n",
    "                                    feature_group_index - 1\n",
    "                                ]:\n",
    "                                self.feature_dividend_list[\n",
    "                                    feature_group_index\n",
    "                                ]\n",
    "                            ]\n",
    "                        )\n",
    "                        for m in self.model_svm_2d_list[feature_group_index - 1]\n",
    "                    ]\n",
    "                    for feature_group_index in range(\n",
    "                        1,\n",
    "                        len(self.feature_dividend_list)\n",
    "                    )\n",
    "                ])\n",
    "            )\n",
    "        ).T\n",
    "        if submodel_choise is None:\n",
    "            return result.sum(axis=1) / self.num_of_clsif\n",
    "        if isinstance(submodel_choise, int) == False or submodel_choise < 0 or submodel_choise >= (len(self.feature_dividend_list) - 1):\n",
    "            raise ValueError(f\"Wrong submodel_choise: {submodel_choise}\")\n",
    "        return result[:, submodel_choise]\n",
    "\n",
    "\n",
    "class Bastion6_Trainer:\n",
    "    def __init__(self, ) -> None:\n",
    "        self.classifier_name = \"Bastion6\"\n",
    "        self.classifier_class = Bastion6_Model\n",
    "        self.classifier_param_dict = {\n",
    "            \"desc\": \"Bastion6_SP\",\n",
    "            \"cv\": 5,\n",
    "            \"N\": 100,\n",
    "        }\n",
    "\n",
    "        self.model = None\n",
    "        self.train_best_predicted_pair = None\n",
    "        self.train_best_5C_predicted_pair = None\n",
    "        self.best_predicted_pair = None\n",
    "        self.best_5C_predicted_pair = None\n",
    "        self.start_to_train_time = datetime.now()\n",
    "        self.end_of_train_time = None\n",
    "        pass\n",
    "\n",
    "    def find_best(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        validation: tuple,\n",
    "        merge_validate: bool\n",
    "    ):\n",
    "\n",
    "        self.model = self.classifier_class(\n",
    "            **self.classifier_param_dict\n",
    "        )\n",
    "        self.model.tranmodel(\n",
    "            pd.DataFrame(X, columns=list(range(2038))),\n",
    "            y,\n",
    "        )\n",
    "        self.best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                pd.DataFrame(validation[0], columns=list(range(2038))),\n",
    "            ), nan=0.0),\n",
    "            validation[1]\n",
    "        ]\n",
    "        self.train_best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                pd.DataFrame(X, columns=list(range(2038))),\n",
    "            ), nan=0.0),\n",
    "            y\n",
    "        ]\n",
    "\n",
    "        # 5倍交叉验证\n",
    "        # 合并数据\n",
    "        if merge_validate == True:\n",
    "            full_X = np.concatenate([\n",
    "                X, validation[0]\n",
    "            ])\n",
    "            full_y = np.concatenate([\n",
    "                y, validation[1]\n",
    "            ])\n",
    "        else:\n",
    "            full_X = np.concatenate([\n",
    "                X,\n",
    "            ])\n",
    "            full_y = np.concatenate([\n",
    "                y,\n",
    "            ])\n",
    "\n",
    "        # 跑模型\n",
    "        self.best_5C_predicted_pair = []\n",
    "        self.train_best_5C_predicted_pair = []\n",
    "        for Kfold_id, (train_id, test_id) in enumerate(\n",
    "            StratifiedKFold(\n",
    "                n_splits=5,\n",
    "                shuffle=True,\n",
    "                random_state=42\n",
    "            ).split(full_X, full_y)\n",
    "        ):\n",
    "\n",
    "            # 定义模型并加载参数\n",
    "            fiveC_model = self.classifier_class(\n",
    "                **self.classifier_param_dict,\n",
    "            )\n",
    "\n",
    "            fiveC_model.tranmodel(\n",
    "                pd.DataFrame(full_X[train_id], columns=list(range(2038))),\n",
    "                full_y[train_id],\n",
    "            )\n",
    "\n",
    "            # 预测并记录\n",
    "            self.best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    pd.DataFrame(full_X[test_id], columns=list(range(2038))),\n",
    "                ), nan=0.0),\n",
    "                full_y[test_id]\n",
    "            ])\n",
    "            self.train_best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    pd.DataFrame(full_X[train_id], columns=list(range(2038))),\n",
    "                ), nan=0.0),\n",
    "                full_y[train_id]\n",
    "            ])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_summary(self, path_to_dir: str = None):\n",
    "        os.makedirs(path_to_dir, exist_ok=True)\n",
    "        model_path = \"-\"\n",
    "        if \"SAVE_MODEL\" in os.environ and os.environ['SAVE_MODEL'] == \"1\":\n",
    "\n",
    "            model_path = f\"{path_to_dir}/{self.classifier_name}.pkl\"\n",
    "            if path_to_dir is not None:\n",
    "                with gzip.open(model_path, \"wb\") as f:\n",
    "                    pickle.dump(\n",
    "                        self.grid_search, f\n",
    "                    )\n",
    "\n",
    "        model_score_path = f\"{path_to_dir}/{self.classifier_name}_score.pkl\"\n",
    "        if path_to_dir is not None:\n",
    "            with gzip.open(model_score_path, \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "            with gzip.open(model_score_path + \".train\", \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.train_best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.train_best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "        else:\n",
    "            model_score_path = \"-\"\n",
    "\n",
    "        plot_roc_curve(\n",
    "            target=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "            path_to_=f\"{path_to_dir}/{self.classifier_name}.pdf\"\n",
    "        )\n",
    "\n",
    "        model_information = {\n",
    "            \"Classifier_Name\": self.classifier_name,\n",
    "            \"Optimitied_Param\": dict(),\n",
    "            \"Score\": model_score_path,\n",
    "            \"Model_Path\": model_path,\n",
    "            \"TimeToStartFit\": self.start_to_train_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "\n",
    "        training_testing_performance = get_evaluation(\n",
    "            label=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "        )\n",
    "\n",
    "        # 计算5C中的平均表现\n",
    "        FiveFold_result = {}\n",
    "        for keys in training_testing_performance.keys():\n",
    "            value_list = []\n",
    "            for item in self.best_5C_predicted_pair:\n",
    "\n",
    "                item_performance = get_evaluation(\n",
    "                    label=item[1],\n",
    "                    pred=item[0],\n",
    "                )\n",
    "                value_list.append(item_performance[keys])\n",
    "\n",
    "            if keys == \"pro_cutoff\":\n",
    "                FiveFold_result[keys] = value_list\n",
    "            else:\n",
    "                FiveFold_result[keys] = sum(value_list) / len(value_list)\n",
    "\n",
    "        self.end_of_train_time = datetime.now()\n",
    "        model_information[\"TimeOfSummary\"] = self.end_of_train_time.strftime(\n",
    "            \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "        model_information[\"TimeSpend\"] = str(\n",
    "            self.end_of_train_time - self.start_to_train_time\n",
    "        )\n",
    "\n",
    "        return model_information, training_testing_performance, FiveFold_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Classifier_Name': 'Bastion6',\n",
       "  'Optimitied_Param': {},\n",
       "  'Score': 'out/libfeatureselection/T2/Bastion6_SP//Bastion6_score.pkl',\n",
       "  'Model_Path': '-',\n",
       "  'TimeToStartFit': '2023-07-23 13:05:03',\n",
       "  'TimeOfSummary': '2023-07-23 13:10:27',\n",
       "  'TimeSpend': '0:05:23.866533'},\n",
       " {'accuracy': 0.7272727272727273,\n",
       "  'precision': 0.6666666666666666,\n",
       "  'f1_score': 0.7692307692307692,\n",
       "  'mmc': 0.48795003647426655,\n",
       "  'rocAUC': 0.6363636363636364,\n",
       "  'specificity': 0.5454545454545454,\n",
       "  'sensitivity': 0.9090909090909091,\n",
       "  'pro_cutoff': 0.3506602011290099},\n",
       " {'accuracy': 0.9431372549019608,\n",
       "  'precision': 0.9377777777777776,\n",
       "  'f1_score': 0.9433918128654971,\n",
       "  'mmc': 0.8894057807415156,\n",
       "  'rocAUC': 0.9589506172839506,\n",
       "  'specificity': 0.9305555555555556,\n",
       "  'sensitivity': 0.9527777777777778,\n",
       "  'pro_cutoff': [0.6187588966407137,\n",
       "   0.5590046834255721,\n",
       "   0.5184827993283286,\n",
       "   0.5270531227586792,\n",
       "   0.5222636096359252]})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Bastion6_Trainer().find_best(\n",
    "    X=t_f.values,\n",
    "    y=t_l,\n",
    "    validation=(\n",
    "        v_f.values,\n",
    "        v_l,\n",
    "    ),\n",
    "    merge_validate=False\n",
    ").get_summary(\n",
    "    path_to_dir=\"out/libfeatureselection/T2/Bastion6_SP/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TxSEml_Backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
