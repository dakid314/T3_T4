{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 14:35:26.488257: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-23 14:35:26.490702: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-07-23 14:35:26.490710: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-23 14:35:27.030909: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-07-23 14:35:27.030922: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-07-23 14:35:27.030937: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (A7LAB): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import libfeatureselection\n",
    "import libpybiofeature\n",
    "from libmodel import t3mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/md0/Users/georgezhao/Source/TxSEml_Addon'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "work_Dir = utils.workdir.workdir(os.getcwd(), 4)\n",
    "work_Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "protype, cter_bool, db_size = 6, False, 'small'\n",
    "Tx_arg = {\n",
    "    \"type\": f'T{protype}',\n",
    "    # 'seq_id': os.path.join(work_Dir, *['data', 'db', f'T{protype}', 'seq_id.json']),\n",
    "    'shufflesplit_index_file': os.path.join(work_Dir, *['data', 'db', f'T{protype}', 'seq_id_shufflesplit.json']),\n",
    "    'fasta': {\n",
    "        'cter': cter_bool,\n",
    "        'sp': {\n",
    "            'p': \"data/T6SE/anti-bacterial-effector_p.fasta\",\n",
    "            'n': \"data/T6SE/anti-bacterial-effector_n.fasta\"\n",
    "        },\n",
    "        'nosp': {\n",
    "            'p': \"data/T6SE/anti-eukaryotic-effector_p.fasta\",\n",
    "            'n': \"data/T6SE/anti-eukaryotic-effector_n.fasta\"\n",
    "        },\n",
    "    },\n",
    "    \"ss\": {\n",
    "        'sp': {\n",
    "            'p': \"out/libfeatureselection/A_feature_research/featuredb/bert/ab_p_ss.pkl\",\n",
    "            'n': \"out/libfeatureselection/A_feature_research/featuredb/bert/ab_n_ss.pkl\",\n",
    "        },\n",
    "        'nosp': {\n",
    "            'p': \"out/libfeatureselection/A_feature_research/featuredb/bert/ae_p_ss.pkl\",\n",
    "            'n': \"out/libfeatureselection/A_feature_research/featuredb/bert/ae_n_ss.pkl\",\n",
    "        },\n",
    "    },\n",
    "    \"sa\": {\n",
    "        'sp': {\n",
    "            'p': \"out/libfeatureselection/A_feature_research/featuredb/bert/ab_p_sa.pkl\",\n",
    "            'n': \"out/libfeatureselection/A_feature_research/featuredb/bert/ab_n_sa.pkl\",\n",
    "        },\n",
    "        'nosp': {\n",
    "            'p': \"out/libfeatureselection/A_feature_research/featuredb/bert/ae_p_sa.pkl\",\n",
    "            'n': \"out/libfeatureselection/A_feature_research/featuredb/bert/ae_n_sa.pkl\",\n",
    "        },\n",
    "    },\n",
    "    'possum': {\n",
    "        'index': \"out/libfeatureselection/A_feature_research/featuredb/possum/possum_index.json\",\n",
    "        'pssm_fdb_pattern': \"out/libfeatureselection/A_feature_research/featuredb/possum/{zipid}_pssm_features.zip\",\n",
    "        'pssm_rdb_pattern': \"out/libfeatureselection/A_feature_research/featuredb/possum/{zipid}_pssm_files.zip\"\n",
    "    },\n",
    "    'model': {\n",
    "        'size': db_size,\n",
    "        'cter': cter_bool,\n",
    "        \"path_to_save_dir\": f\"out/libfeatureselection/T6/model/PyPredT6_AB/model/\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_id_dict = {\n",
    "    \"sp\": {\n",
    "        \"p\": [ seq.id for seq in SeqIO.parse(Tx_arg['fasta']['sp']['p'], \"fasta\") ],\n",
    "        \"n\": [ seq.id for seq in SeqIO.parse(Tx_arg['fasta']['sp']['n'], \"fasta\") ],\n",
    "    },\n",
    "    \"nosp\": {\n",
    "        \"p\": [ seq.id for seq in SeqIO.parse(Tx_arg['fasta']['nosp']['p'], \"fasta\") ],\n",
    "        \"n\": [ seq.id for seq in SeqIO.parse(Tx_arg['fasta']['nosp']['n'], \"fasta\") ],\n",
    "    },\n",
    "}\n",
    "with open(f\"data/T6SE/seq_id.json\", \"w+\", encoding=\"UTF-8\") as f:\n",
    "    json.dump(\n",
    "        obj=seq_id_dict,\n",
    "        fp=f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_set = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_AAC: 100%|██████████| 53/53 [00:00<00:00, 60145.59it/s]\n",
      "sp_n_AAC: 100%|██████████| 53/53 [00:00<00:00, 100315.03it/s]\n",
      "nosp_p_AAC: 100%|██████████| 33/33 [00:00<00:00, 58698.91it/s]\n",
      "nosp_n_AAC: 100%|██████████| 33/33 [00:00<00:00, 73467.11it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"AAC\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p'\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n'\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p'\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_DAC: 100%|██████████| 53/53 [00:00<00:00, 11825.00it/s]\n",
      "sp_n_DAC: 100%|██████████| 53/53 [00:00<00:00, 17718.64it/s]\n",
      "nosp_p_DAC: 100%|██████████| 33/33 [00:00<00:00, 11630.29it/s]\n",
      "nosp_n_DAC: 100%|██████████| 33/33 [00:00<00:00, 18069.46it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"DAC\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p'\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n'\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p'\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_etpp: 100%|██████████| 53/53 [00:00<00:00, 3203.24it/s]\n",
      "sp_n_etpp: 100%|██████████| 53/53 [00:00<00:00, 6209.44it/s]\n",
      "nosp_p_etpp: 100%|██████████| 33/33 [00:00<00:00, 2936.69it/s]\n",
      "nosp_n_etpp: 100%|██████████| 33/33 [00:00<00:00, 7157.15it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"18-PP\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_etpp_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p'\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_etpp_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n'\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_etpp_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p'\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_etpp_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sp_p_CTriad: 100%|██████████| 53/53 [00:00<00:00, 5891.03it/s]\n",
      "sp_n_CTriad: 100%|██████████| 53/53 [00:00<00:00, 10441.43it/s]\n",
      "nosp_p_CTriad: 100%|██████████| 33/33 [00:00<00:00, 5530.95it/s]\n",
      "nosp_n_CTriad: 100%|██████████| 33/33 [00:00<00:00, 11602.99it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"CJ\",\n",
    "    \"sp_p\": libpybiofeature.featurebuilder.build_conjoint_td_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['p'],\n",
    "        seq_id_list=seq_id_dict['sp']['p'],\n",
    "        desc='sp_p'\n",
    "    ),\n",
    "    \"sp_n\": libpybiofeature.featurebuilder.build_conjoint_td_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['sp']['n'],\n",
    "        seq_id_list=seq_id_dict['sp']['n'],\n",
    "        desc='sp_n'\n",
    "    ),\n",
    "    \"nosp_p\": libpybiofeature.featurebuilder.build_conjoint_td_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['p'],\n",
    "        seq_id_list=seq_id_dict['nosp']['p'],\n",
    "        desc='nosp_p'\n",
    "    ),\n",
    "    \"nosp_n\": libpybiofeature.featurebuilder.build_conjoint_td_feature(\n",
    "        path_to_fasta=Tx_arg['fasta']['nosp']['n'],\n",
    "        seq_id_list=seq_id_dict['nosp']['n'],\n",
    "        desc='nosp_n'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_set.append({\n",
    "    \"name\": \"SS-100-Onehot\",\n",
    "    \"sp_p\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['ss']['sp']['p'],\n",
    "        id_list=seq_id_dict['sp']['p'],\n",
    "        dim=3\n",
    "    ),\n",
    "    \"sp_n\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['ss']['sp']['n'],\n",
    "        id_list=seq_id_dict['sp']['n'],\n",
    "        dim=3\n",
    "    ),\n",
    "    \"nosp_p\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['ss']['nosp']['p'],\n",
    "        id_list=seq_id_dict['nosp']['p'],\n",
    "        dim=3\n",
    "    ),\n",
    "    \"nosp_n\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['ss']['nosp']['n'],\n",
    "        id_list=seq_id_dict['nosp']['n'],\n",
    "        dim=3\n",
    "    )\n",
    "})\n",
    "feature_data_set.append({\n",
    "    \"name\": \"SA-100-Onehot\",\n",
    "    \"sp_p\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['sa']['sp']['p'],\n",
    "        id_list=seq_id_dict['sp']['p'],\n",
    "        dim=2\n",
    "    ),\n",
    "    \"sp_n\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['sa']['sp']['n'],\n",
    "        id_list=seq_id_dict['sp']['n'],\n",
    "        dim=2\n",
    "    ),\n",
    "    \"nosp_p\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['sa']['nosp']['p'],\n",
    "        id_list=seq_id_dict['nosp']['p'],\n",
    "        dim=2\n",
    "    ),\n",
    "    \"nosp_n\": libfeatureselection.feature_loader.load_from_bert_onehot(\n",
    "        path=Tx_arg['sa']['nosp']['n'],\n",
    "        id_list=seq_id_dict['nosp']['n'],\n",
    "        dim=2\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pn_dataset(\n",
    "    p_f: pd.DataFrame,\n",
    "    p_l: np.ndarray,\n",
    "    n_f: pd.DataFrame,\n",
    "    n_l: np.ndarray\n",
    "):\n",
    "    t_f = pd.concat([p_f, n_f])\n",
    "    t_l = np.concatenate([p_l, n_l])\n",
    "\n",
    "    return t_f, t_l\n",
    "\n",
    "# 合并feature_selected成数据集\n",
    "data_set_split = {\n",
    "    datatype: pd.concat([\n",
    "        item[datatype] for item in feature_data_set\n",
    "    ], axis=1)\n",
    "    for datatype in [\"sp_p\", \"sp_n\", \"nosp_p\", \"nosp_n\"]\n",
    "}\n",
    "label_set_split = {\n",
    "    datatype: np.ones(\n",
    "        shape=(feature_data_set[0][datatype].shape[0], ))\n",
    "    for datatype in [\"sp_p\", \"nosp_p\",]\n",
    "} | {\n",
    "    datatype: np.zeros(\n",
    "        shape=(feature_data_set[0][datatype].shape[0], ))\n",
    "    for datatype in [\"sp_n\", \"nosp_n\",]\n",
    "}\n",
    "\n",
    "t_f, t_l = merge_pn_dataset(\n",
    "    p_f=data_set_split[\"sp_p\"],\n",
    "    p_l=label_set_split[\"sp_p\"],\n",
    "    n_f=data_set_split[\"sp_n\"],\n",
    "    n_l=label_set_split[\"sp_n\"],\n",
    ")\n",
    "v_f, v_l = merge_pn_dataset(\n",
    "    p_f=data_set_split[\"nosp_p\"],\n",
    "    p_l=label_set_split[\"nosp_p\"],\n",
    "    n_f=data_set_split[\"nosp_n\"],\n",
    "    n_l=label_set_split[\"nosp_n\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'out/libfeatureselection/T6/model/PyPredT6_AB/model//model/'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 丢入model中进行训练\n",
    "model_path = f\"{Tx_arg['model']['path_to_save_dir']}/model/\"\n",
    "os.makedirs(\n",
    "    model_path,\n",
    "    exist_ok=True\n",
    ")\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from libfeatureselection import model, model_space\n",
    "n_jobs = (\n",
    "    (os.cpu_count() - 2)\n",
    "    if \"n_jobs\" not in os.environ or os.environ['n_jobs'] == \"\" else\n",
    "    int(os.environ['n_jobs'])\n",
    ")\n",
    "n_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from datetime import datetime\n",
    "import math\n",
    "import functools\n",
    "import pickle\n",
    "import gzip\n",
    "import itertools\n",
    "\n",
    "from src.libmodel import common, model_optimite\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "mpl.rcParams['svg.fonttype'] = 'none'\n",
    "mpl.rcParams['pdf.use14corefonts'] = False\n",
    "# mpl.rcParams['pdf.usecorefonts'] = True\n",
    "mpl.rcParams['pdf.compression'] = 9\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use(['science', 'nature'])\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_score, accuracy_score, f1_score, matthews_corrcoef, auc\n",
    "\n",
    "def get_evaluation(label: list, pred: list, pro_cutoff: float = None):\n",
    "    pred = np.nan_to_num(\n",
    "        pred, copy=True, nan=0.0\n",
    "    )\n",
    "    fpr, tpr, thresholds = roc_curve(label, pred)\n",
    "    if pro_cutoff is None:\n",
    "        best_one_optimal_idx = np.argmax(tpr - fpr)\n",
    "        pro_cutoff = thresholds[best_one_optimal_idx]\n",
    "    pred_l = [1 if i >= pro_cutoff else 0 for i in pred]\n",
    "    confusion_matrix_1d = confusion_matrix(label, pred_l).ravel()\n",
    "    confusion_dict = {N: n for N, n in zip(['tn', 'fp', 'fn', 'tp'], list(\n",
    "        confusion_matrix_1d * 2 / np.sum(confusion_matrix_1d)))}\n",
    "    evaluation = {\n",
    "        \"accuracy\": accuracy_score(label, pred_l),\n",
    "        \"precision\": precision_score(label, pred_l),\n",
    "        \"f1_score\": f1_score(label, pred_l),\n",
    "        \"mmc\": matthews_corrcoef(label, pred_l),\n",
    "        \"rocAUC\": auc(fpr, tpr),\n",
    "        \"specificity\": confusion_dict['tn'] / (confusion_dict['tn'] + confusion_dict['fp']),\n",
    "        \"sensitivity\": confusion_dict['tp'] / (confusion_dict['tp'] + confusion_dict['fn']),\n",
    "        # \"confusion_matrix\": confusion_dict,\n",
    "        # \"_roc_Data\": {'fpr': list(fpr), 'tpr': list(tpr)},\n",
    "        'pro_cutoff': pro_cutoff\n",
    "    }\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "def plot_roc_curve(target, pred, path_to_: str):\n",
    "    fpr, tpr, thresholds = roc_curve(target, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(19.2 / 4, 10.8 / 4))\n",
    "    plt.axis('square')\n",
    "    plt.plot(\n",
    "        fpr, tpr, color='red', lw=2,\n",
    "        label='ROC curve (area = %0.2f)' % roc_auc\n",
    "    )\n",
    "    plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC) curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.savefig(f\"{path_to_}\", transparent=True)\n",
    "    plt.clf()\n",
    "\n",
    "submodel_choise = None\n",
    "\n",
    "svm_param_o = [{\n",
    "    \"kernel\": [\"linear\", ],\n",
    "    \"C\": [10**i for i in range(-6, 6 + 1)],\n",
    "}, {\n",
    "    \"kernel\": [\"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"gamma\": [10**i for i in range(-6, 6 + 1)],\n",
    "    \"C\": [10**i for i in range(-6, 6 + 1)],\n",
    "}]\n",
    "\n",
    "rf_param_o = {\n",
    "    \"n_estimators\": [2 ** i for i in range(4, 15)],\n",
    "}\n",
    "\n",
    "mlp_param_o = {\n",
    "    \"solver\": ['adam', 'sgd', 'lbfgs'],\n",
    "    \"activation\": ['relu', 'tanh', 'logistic', 'identity'],\n",
    "    'hidden_layer_sizes': [(100,), (50,), (25,), (10,), ],\n",
    "    \"learning_rate\": ['adaptive', 'invscaling', 'constant']\n",
    "}\n",
    "\n",
    "knn_optim_o = {\n",
    "    'n_neighbors': [i for i in range(1, 6)]\n",
    "}\n",
    "\n",
    "rf_optim: model_optimite.rf_optim = functools.partial(\n",
    "    model_optimite.rf_optim,\n",
    "    default_param={\n",
    "        'verbose': 0,\n",
    "        'criterion': 'gini'\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "class PyPredT6_Model(common.Model_Final):\n",
    "    def __init__(self, cv, desc):\n",
    "        super().__init__(cv, desc=desc)\n",
    "        self.model_svm = None\n",
    "        self.model_nb = None\n",
    "        self.model_mlp = None\n",
    "        self.model_knn = None\n",
    "        self.model_rf = None\n",
    "        pass\n",
    "\n",
    "    def tranmodel(self, f, l):\n",
    "        super().tranmodel(f, l)\n",
    "        self.model_svm = model_optimite.svm_optim(\n",
    "            param_o=svm_param_o,\n",
    "            cv=self.cv,\n",
    "        ).best_fit(\n",
    "            f, l, verbose=-1, n_jobs=n_jobs\n",
    "        )\n",
    "\n",
    "        self.model_nb = GaussianNB().fit(\n",
    "            f, l\n",
    "        )\n",
    "\n",
    "        self.model_knn = model_optimite.knn_optim(\n",
    "            param_o=knn_optim_o,\n",
    "            cv=self.cv\n",
    "        ).best_fit(\n",
    "            f, l, verbose=-1, n_jobs=n_jobs\n",
    "        )\n",
    "\n",
    "        self.model_rf = rf_optim(\n",
    "            param_o=rf_param_o,\n",
    "            cv=self.cv,\n",
    "        ).best_fit(\n",
    "            f, l, verbose=-1, n_jobs=n_jobs\n",
    "        )\n",
    "\n",
    "        self.model_mlp = model_optimite.mlp_optim(\n",
    "            param_o=mlp_param_o,\n",
    "            cv=self.cv,\n",
    "        ).best_fit(\n",
    "            f, l, verbose=-1, n_jobs=n_jobs\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, f):\n",
    "        super().predict(f)\n",
    "        result = np.stack([\n",
    "            self.model_svm.predict_proba(f),\n",
    "            self.model_nb.predict_proba(f)[:, 1],\n",
    "            self.model_knn.predict_proba(f),\n",
    "            self.model_rf.predict_proba(f),\n",
    "            self.model_mlp.predict_proba(f),\n",
    "        ]).T\n",
    "        if submodel_choise is None:\n",
    "            result = (result >= 0.5)\n",
    "            return result.sum(axis=1) / 5\n",
    "        if isinstance(submodel_choise, int) == False or submodel_choise < 0 or submodel_choise >= 5:\n",
    "            raise ValueError(f\"Wrong submodel_choise: {submodel_choise}\")\n",
    "        return result[:, submodel_choise]\n",
    "\n",
    "\n",
    "class PyPredT6_Trainer:\n",
    "    def __init__(self, ) -> None:\n",
    "        self.classifier_name = \"PyPredT6\"\n",
    "        self.classifier_class = PyPredT6_Model\n",
    "        self.classifier_param_dict = {\n",
    "            \"desc\": \"PyPredT6_SP\",\n",
    "            \"cv\": 5,\n",
    "        }\n",
    "\n",
    "        self.model = None\n",
    "        self.train_best_predicted_pair = None\n",
    "        self.train_best_5C_predicted_pair = None\n",
    "        self.best_predicted_pair = None\n",
    "        self.best_5C_predicted_pair = None\n",
    "        self.start_to_train_time = datetime.now()\n",
    "        self.end_of_train_time = None\n",
    "        pass\n",
    "\n",
    "    def find_best(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        validation: tuple,\n",
    "        merge_validate: bool\n",
    "    ):\n",
    "\n",
    "        self.model = self.classifier_class(\n",
    "            **self.classifier_param_dict\n",
    "        )\n",
    "        self.model.tranmodel(\n",
    "            pd.DataFrame(X,),\n",
    "            y,\n",
    "        )\n",
    "        self.best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                pd.DataFrame(validation[0],),\n",
    "            ), nan=0.0),\n",
    "            validation[1]\n",
    "        ]\n",
    "        self.train_best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                pd.DataFrame(X,),\n",
    "            ), nan=0.0),\n",
    "            y\n",
    "        ]\n",
    "\n",
    "        # 5倍交叉验证\n",
    "        # 合并数据\n",
    "        if merge_validate == True:\n",
    "            full_X = np.concatenate([\n",
    "                X, validation[0]\n",
    "            ])\n",
    "            full_y = np.concatenate([\n",
    "                y, validation[1]\n",
    "            ])\n",
    "        else:\n",
    "            full_X = np.concatenate([\n",
    "                X,\n",
    "            ])\n",
    "            full_y = np.concatenate([\n",
    "                y,\n",
    "            ])\n",
    "\n",
    "        # 跑模型\n",
    "        self.best_5C_predicted_pair = []\n",
    "        self.train_best_5C_predicted_pair = []\n",
    "        for Kfold_id, (train_id, test_id) in enumerate(\n",
    "            StratifiedKFold(\n",
    "                n_splits=5,\n",
    "                shuffle=True,\n",
    "                random_state=42\n",
    "            ).split(full_X, full_y)\n",
    "        ):\n",
    "\n",
    "            # 定义模型并加载参数\n",
    "            fiveC_model = self.classifier_class(\n",
    "                **self.classifier_param_dict,\n",
    "            )\n",
    "\n",
    "            fiveC_model.tranmodel(\n",
    "                pd.DataFrame(full_X[train_id],),\n",
    "                full_y[train_id],\n",
    "            )\n",
    "\n",
    "            # 预测并记录\n",
    "            self.best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    pd.DataFrame(full_X[test_id],),\n",
    "                ), nan=0.0),\n",
    "                full_y[test_id]\n",
    "            ])\n",
    "            self.train_best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    pd.DataFrame(full_X[train_id],),\n",
    "                ), nan=0.0),\n",
    "                full_y[train_id]\n",
    "            ])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_summary(self, path_to_dir: str = None):\n",
    "        os.makedirs(path_to_dir, exist_ok=True)\n",
    "        model_path = \"-\"\n",
    "        if \"SAVE_MODEL\" in os.environ and os.environ['SAVE_MODEL'] == \"1\":\n",
    "\n",
    "            model_path = f\"{path_to_dir}/{self.classifier_name}.pkl\"\n",
    "            if path_to_dir is not None:\n",
    "                with gzip.open(model_path, \"wb\") as f:\n",
    "                    pickle.dump(\n",
    "                        self.grid_search, f\n",
    "                    )\n",
    "\n",
    "        model_score_path = f\"{path_to_dir}/{self.classifier_name}_score.pkl\"\n",
    "        if path_to_dir is not None:\n",
    "            with gzip.open(model_score_path, \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "            with gzip.open(model_score_path + \".train\", \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.train_best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.train_best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "        else:\n",
    "            model_score_path = \"-\"\n",
    "\n",
    "        plot_roc_curve(\n",
    "            target=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "            path_to_=f\"{path_to_dir}/{self.classifier_name}.pdf\"\n",
    "        )\n",
    "\n",
    "        model_information = {\n",
    "            \"Classifier_Name\": self.classifier_name,\n",
    "            \"Optimitied_Param\": dict(),\n",
    "            \"Score\": model_score_path,\n",
    "            \"Model_Path\": model_path,\n",
    "            \"TimeToStartFit\": self.start_to_train_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "\n",
    "        training_testing_performance = get_evaluation(\n",
    "            label=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "        )\n",
    "\n",
    "        # 计算5C中的平均表现\n",
    "        FiveFold_result = {}\n",
    "        for keys in training_testing_performance.keys():\n",
    "            value_list = []\n",
    "            for item in self.best_5C_predicted_pair:\n",
    "\n",
    "                item_performance = get_evaluation(\n",
    "                    label=item[1],\n",
    "                    pred=item[0],\n",
    "                )\n",
    "                value_list.append(item_performance[keys])\n",
    "\n",
    "            if keys == \"pro_cutoff\":\n",
    "                FiveFold_result[keys] = value_list\n",
    "            else:\n",
    "                FiveFold_result[keys] = sum(value_list) / len(value_list)\n",
    "\n",
    "        self.end_of_train_time = datetime.now()\n",
    "        model_information[\"TimeOfSummary\"] = self.end_of_train_time.strftime(\n",
    "            \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "        model_information[\"TimeSpend\"] = str(\n",
    "            self.end_of_train_time - self.start_to_train_time\n",
    "        )\n",
    "\n",
    "        return model_information, training_testing_performance, FiveFold_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Classifier_Name': 'PyPredT6',\n",
       "  'Optimitied_Param': {},\n",
       "  'Score': 'out/libfeatureselection/T6/PyPredT6_AB//PyPredT6_score.pkl',\n",
       "  'Model_Path': '-',\n",
       "  'TimeToStartFit': '2023-07-23 14:37:46',\n",
       "  'TimeOfSummary': '2023-07-23 14:39:59',\n",
       "  'TimeSpend': '0:02:12.381083'},\n",
       " {'accuracy': 0.7727272727272727,\n",
       "  'precision': 0.78125,\n",
       "  'f1_score': 0.7692307692307692,\n",
       "  'mmc': 0.5457051563317492,\n",
       "  'rocAUC': 0.8521579430670341,\n",
       "  'specificity': 0.7878787878787878,\n",
       "  'sensitivity': 0.7575757575757576,\n",
       "  'pro_cutoff': 0.8},\n",
       " {'accuracy': 0.7744588744588745,\n",
       "  'precision': 0.8305555555555555,\n",
       "  'f1_score': 0.7355555555555555,\n",
       "  'mmc': 0.5588779157661717,\n",
       "  'rocAUC': 0.7849586776859504,\n",
       "  'specificity': 0.8690909090909091,\n",
       "  'sensitivity': 0.6745454545454544,\n",
       "  'pro_cutoff': [0.6, 0.6, 0.8, 0.8, 0.6]})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PyPredT6_Trainer().find_best(\n",
    "    X=t_f.values,\n",
    "    y=t_l,\n",
    "    validation=(\n",
    "        v_f.values,\n",
    "        v_l,\n",
    "    ),\n",
    "    merge_validate=False\n",
    ").get_summary(\n",
    "    path_to_dir=\"out/libfeatureselection/T6/PyPredT6_AB/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Classifier_Name': 'PyPredT6',\n",
       "  'Optimitied_Param': {},\n",
       "  'Score': 'out/libfeatureselection/T6/PyPredT6_AE//PyPredT6_score.pkl',\n",
       "  'Model_Path': '-',\n",
       "  'TimeToStartFit': '2023-07-23 14:39:59',\n",
       "  'TimeOfSummary': '2023-07-23 14:41:41',\n",
       "  'TimeSpend': '0:01:42.216194'},\n",
       " {'accuracy': 0.7547169811320755,\n",
       "  'precision': 0.7647058823529411,\n",
       "  'f1_score': 0.7499999999999999,\n",
       "  'mmc': 0.5097970656333187,\n",
       "  'rocAUC': 0.7988608045567818,\n",
       "  'specificity': 0.7735849056603774,\n",
       "  'sensitivity': 0.7358490566037735,\n",
       "  'pro_cutoff': 0.8},\n",
       " {'accuracy': 0.7417582417582417,\n",
       "  'precision': 0.7666666666666667,\n",
       "  'f1_score': 0.752822966507177,\n",
       "  'mmc': 0.5155594045395453,\n",
       "  'rocAUC': 0.708843537414966,\n",
       "  'specificity': 0.6904761904761905,\n",
       "  'sensitivity': 0.7857142857142858,\n",
       "  'pro_cutoff': [0.6, 0.4, 0.6, 1.0, 0.8]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PyPredT6_Trainer().find_best(\n",
    "    X=v_f.values,\n",
    "    y=v_l,\n",
    "    validation=(\n",
    "        t_f.values,\n",
    "        t_l,\n",
    "    ),\n",
    "    merge_validate=False\n",
    ").get_summary(\n",
    "    path_to_dir=\"out/libfeatureselection/T6/PyPredT6_AE/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TxSEml_Backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
