{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T1SEstacker-RTX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "import os\n",
    "os.environ[\"n_jobs\"] = \"2\"\n",
    "import json\n",
    "\n",
    "import libpybiofeature\n",
    "\n",
    "import utils\n",
    "work_Dir = utils.workdir.workdir(os.getcwd(), 4)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "mpl.rcParams['svg.fonttype'] = 'none'\n",
    "mpl.rcParams['pdf.use14corefonts'] = False\n",
    "# mpl.rcParams['pdf.usecorefonts'] = True\n",
    "mpl.rcParams['pdf.compression'] = 9\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use(['science', 'nature'])\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_score, accuracy_score, f1_score, matthews_corrcoef, auc\n",
    "\n",
    "def get_evaluation(label: list, pred: list, pro_cutoff: float = None):\n",
    "    pred = np.nan_to_num(\n",
    "        pred, copy=True, nan=0.0\n",
    "    )\n",
    "    fpr, tpr, thresholds = roc_curve(label, pred)\n",
    "    if pro_cutoff is None:\n",
    "        best_one_optimal_idx = np.argmax(tpr - fpr)\n",
    "        pro_cutoff = thresholds[best_one_optimal_idx]\n",
    "    pred_l = [1 if i >= pro_cutoff else 0 for i in pred]\n",
    "    confusion_matrix_1d = confusion_matrix(label, pred_l).ravel()\n",
    "    confusion_dict = {N: n for N, n in zip(['tn', 'fp', 'fn', 'tp'], list(\n",
    "        confusion_matrix_1d * 2 / np.sum(confusion_matrix_1d)))}\n",
    "    evaluation = {\n",
    "        \"accuracy\": accuracy_score(label, pred_l),\n",
    "        \"precision\": precision_score(label, pred_l),\n",
    "        \"f1_score\": f1_score(label, pred_l),\n",
    "        \"mmc\": matthews_corrcoef(label, pred_l),\n",
    "        \"rocAUC\": auc(fpr, tpr),\n",
    "        \"specificity\": confusion_dict['tn'] / (confusion_dict['tn'] + confusion_dict['fp']),\n",
    "        \"sensitivity\": confusion_dict['tp'] / (confusion_dict['tp'] + confusion_dict['fn']),\n",
    "        # \"confusion_matrix\": confusion_dict,\n",
    "        # \"_roc_Data\": {'fpr': list(fpr), 'tpr': list(tpr)},\n",
    "        'pro_cutoff': pro_cutoff\n",
    "    }\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "def plot_roc_curve(target, pred, path_to_: str):\n",
    "    fpr, tpr, thresholds = roc_curve(target, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(19.2 / 4, 10.8 / 4))\n",
    "    plt.axis('square')\n",
    "    plt.plot(\n",
    "        fpr, tpr, color='red', lw=2,\n",
    "        label='ROC curve (area = %0.2f)' % roc_auc\n",
    "    )\n",
    "    plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC) curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.savefig(f\"{path_to_}\", transparent=True)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "def load_AAC_feature(TxSE_args: dict):\n",
    "\n",
    "    # Extract Feature\n",
    "    seq_id_dict = None\n",
    "    with open(TxSE_args['seq_id'], 'r', encoding='UTF-8') as f:\n",
    "        seq_id_dict = json.load(f)\n",
    "\n",
    "    # AAC\n",
    "    AAC_feature = {\n",
    "        \"name\": \"AAC\",\n",
    "        \"t_p\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['t']['p'],\n",
    "            seq_id_list=seq_id_dict['t']['p'],\n",
    "            desc='t_p',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"t_n\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['t']['n'],\n",
    "            seq_id_list=seq_id_dict['t']['n'],\n",
    "            desc='t_n',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"v_p\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['v']['p'],\n",
    "            seq_id_list=seq_id_dict['v']['p'],\n",
    "            desc='v_p',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"v_n\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['v']['n'],\n",
    "            seq_id_list=seq_id_dict['v']['n'],\n",
    "            desc='v_n',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    return AAC_feature\n",
    "\n",
    "def load_DAC_feature(TxSE_args: dict):\n",
    "\n",
    "    # Extract Feature\n",
    "    seq_id_dict = None\n",
    "    with open(TxSE_args['seq_id'], 'r', encoding='UTF-8') as f:\n",
    "        seq_id_dict = json.load(f)\n",
    "\n",
    "    # AAC\n",
    "    DAC_feature = {\n",
    "        \"name\": \"DAC\",\n",
    "        \"t_p\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['t']['p'],\n",
    "            seq_id_list=seq_id_dict['t']['p'],\n",
    "            desc='t_p',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"t_n\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['t']['n'],\n",
    "            seq_id_list=seq_id_dict['t']['n'],\n",
    "            desc='t_n',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"v_p\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['v']['p'],\n",
    "            seq_id_list=seq_id_dict['v']['p'],\n",
    "            desc='v_p',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"v_n\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['v']['n'],\n",
    "            seq_id_list=seq_id_dict['v']['n'],\n",
    "            desc='v_n',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    return DAC_feature\n",
    "\n",
    "import tqdm\n",
    "from src.libpybiofeature import AC, oneHot\n",
    "\n",
    "def build_DigitAA_feature(\n",
    "    path_to_fasta: str,\n",
    "    seq_id_list: list,\n",
    "    desc: str = 'undefine',\n",
    "    NCF='C',\n",
    "    terlength: int = 60\n",
    "):\n",
    "    assert NCF == \"C\"\n",
    "    assert terlength == 60\n",
    "\n",
    "    seq_list = list(SeqIO.parse(path_to_fasta, 'fasta'))\n",
    "    df = None\n",
    "    \n",
    "    df = pd.DataFrame([\n",
    "        [\n",
    "            oneHot.default_aa_dict[aa]\n",
    "            for aa in str(seq.seq)[-1 * terlength:]\n",
    "        ]\n",
    "        for seq in tqdm.tqdm(seq_list, desc=f'{desc}_AAC')\n",
    "    ]).fillna(0)\n",
    "\n",
    "    df.columns = list(range(df.shape[1]))\n",
    "    df.index = [seq.id for seq in seq_list]\n",
    "\n",
    "    if seq_id_list is not None:\n",
    "        return df.loc[seq_id_list, :]\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def load_DigitAA_feature(TxSE_args: dict):\n",
    "\n",
    "    # Extract Feature\n",
    "    seq_id_dict = None\n",
    "    with open(TxSE_args['seq_id'], 'r', encoding='UTF-8') as f:\n",
    "        seq_id_dict = json.load(f)\n",
    "\n",
    "    # AAC\n",
    "    DAC_feature = {\n",
    "        \"name\": \"DigitAA\",\n",
    "        \"t_p\": build_DigitAA_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['t']['p'],\n",
    "            seq_id_list=seq_id_dict['t']['p'],\n",
    "            desc='t_p',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"t_n\": build_DigitAA_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['t']['n'],\n",
    "            seq_id_list=seq_id_dict['t']['n'],\n",
    "            desc='t_n',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"v_p\": build_DigitAA_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['v']['p'],\n",
    "            seq_id_list=seq_id_dict['v']['p'],\n",
    "            desc='v_p',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"v_n\": build_DigitAA_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['v']['n'],\n",
    "            seq_id_list=seq_id_dict['v']['n'],\n",
    "            desc='v_n',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    return DAC_feature\n",
    "\n",
    "def load_BPBAac_feature(TxSE_args: dict):\n",
    "\n",
    "    # Extract Feature\n",
    "    seq_id_dict = None\n",
    "    with open(TxSE_args['seq_id'], 'r', encoding='UTF-8') as f:\n",
    "        seq_id_dict = json.load(f)\n",
    "\n",
    "    # BPBaac\n",
    "    BPBaac_seq_data = {\n",
    "        \"t_p\": libpybiofeature.libdataloader.fasta_seq_loader.prepare_data(\n",
    "            path_to_fasta=TxSE_args['fasta']['t']['p'],\n",
    "            seq_id_list=seq_id_dict['t']['p'],\n",
    "        )[0].values.tolist(),\n",
    "        \"t_n\": libpybiofeature.libdataloader.fasta_seq_loader.prepare_data(\n",
    "            path_to_fasta=TxSE_args['fasta']['t']['n'],\n",
    "            seq_id_list=seq_id_dict['t']['n'],\n",
    "        )[0].values.tolist(),\n",
    "        \"v_p\": libpybiofeature.libdataloader.fasta_seq_loader.prepare_data(\n",
    "            path_to_fasta=TxSE_args['fasta']['v']['p'],\n",
    "            seq_id_list=seq_id_dict['v']['p'],\n",
    "        )[0].values.tolist(),\n",
    "        \"v_n\": libpybiofeature.libdataloader.fasta_seq_loader.prepare_data(\n",
    "            path_to_fasta=TxSE_args['fasta']['v']['n'],\n",
    "            seq_id_list=seq_id_dict['v']['n'],\n",
    "        )[0].values.tolist(),\n",
    "    }\n",
    "\n",
    "    BPBaac_profile = {\n",
    "        \"p\": libpybiofeature.BPBaac_psp.mat_constructor(\n",
    "            fasta_db=BPBaac_seq_data['t_p'],\n",
    "            cter=TxSE_args['fasta']['cter'],\n",
    "            terlength=60,\n",
    "            padding_ac='A'\n",
    "        ),\n",
    "        \"n\": libpybiofeature.BPBaac_psp.mat_constructor(\n",
    "            fasta_db=BPBaac_seq_data['t_n'],\n",
    "            cter=TxSE_args['fasta']['cter'],\n",
    "            terlength=60,\n",
    "            padding_ac='A'\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    with open(\"out/libfeatureselection/RTX_feature_research/aac/rtx/BPBaac_profile_C60.json\", \"w+\", encoding='UTF-8') as f:\n",
    "        json.dump(BPBaac_profile, f)\n",
    "\n",
    "    for data_type in BPBaac_seq_data.keys():\n",
    "        BPBaac_seq_data[data_type] = pd.DataFrame(\n",
    "            [\n",
    "                libpybiofeature.BPBaac_psp.mat_mapper(\n",
    "                    seq=str(seq.seq),\n",
    "                    pmat=BPBaac_profile['p'],\n",
    "                    nmat=BPBaac_profile['n'],\n",
    "                    cter=TxSE_args['fasta']['cter'],\n",
    "                    terlength=60,\n",
    "                    padding_ac='A'\n",
    "                ) for seq in BPBaac_seq_data[data_type]\n",
    "            ],\n",
    "            index=seq_id_dict[data_type.split(\"_\")[0]][data_type.split(\"_\")[1]]\n",
    "        )\n",
    "    BPBaac_seq_data['name'] = \"BPBaac\"\n",
    "\n",
    "    return BPBaac_seq_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_type = 1\n",
    "cter_bool = True\n",
    "Tx_arg = {\n",
    "    \"type\": f'T{prot_type}',\n",
    "    'seq_id': \"data/T1SE/seq_id.json\",\n",
    "    'fasta': {\n",
    "        'cter': cter_bool,\n",
    "        't': {\n",
    "            'p': \"data/T1SE/RTX_filted_prot.fasta\",\n",
    "            'n': \"data/T1SE/n_RTX_filted_prot.fasta\"\n",
    "        },\n",
    "        'v': {\n",
    "            'p': \"data/T1SE/non-RTX_filted_prot.fasta\",\n",
    "            'n': \"data/T1SE/n_non-RTX_filted_prot.fasta\"\n",
    "        },\n",
    "    },\n",
    "}\n",
    "save_dir = \"out/libfeatureselection/T1/T1SEstacker-RTX/\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_p_AAC: 100%|██████████| 74/74 [00:00<00:00, 31281.85it/s]\n",
      "t_n_AAC: 100%|██████████| 74/74 [00:00<00:00, 35067.05it/s]\n",
      "v_p_AAC: 100%|██████████| 25/25 [00:00<00:00, 16407.07it/s]\n",
      "v_n_AAC: 100%|██████████| 25/25 [00:00<00:00, 23358.79it/s]\n",
      "t_p_DAC: 100%|██████████| 74/74 [00:00<00:00, 9125.56it/s]\n",
      "t_n_DAC: 100%|██████████| 74/74 [00:00<00:00, 8621.86it/s]\n",
      "v_p_DAC: 100%|██████████| 25/25 [00:00<00:00, 8217.68it/s]\n",
      "v_n_DAC: 100%|██████████| 25/25 [00:00<00:00, 7337.83it/s]\n",
      "t_p_AAC: 100%|██████████| 74/74 [00:00<00:00, 55743.26it/s]\n",
      "t_n_AAC: 100%|██████████| 74/74 [00:00<00:00, 5754.89it/s]\n",
      "v_p_AAC: 100%|██████████| 25/25 [00:00<00:00, 12908.73it/s]\n",
      "v_n_AAC: 100%|██████████| 25/25 [00:00<00:00, 32963.72it/s]\n"
     ]
    }
   ],
   "source": [
    "aac_data = load_AAC_feature(\n",
    "    TxSE_args=Tx_arg\n",
    ")\n",
    "dac_data = load_DAC_feature(\n",
    "    TxSE_args=Tx_arg\n",
    ")\n",
    "ac_data = {\n",
    "    datatype: pd.concat([\n",
    "        item[datatype] for item in [aac_data, dac_data]\n",
    "    ], axis=1)\n",
    "    for datatype in [\"t_p\", \"t_n\", \"v_p\", \"v_n\"]\n",
    "}\n",
    "bpb_data = load_BPBAac_feature(\n",
    "    TxSE_args=Tx_arg\n",
    ")\n",
    "digitaa_data = load_DigitAA_feature(\n",
    "    TxSE_args=Tx_arg\n",
    ")\n",
    "aa_type = list(aac_data['t_p'].columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-22 13:44:23.737370: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-22 13:44:23.752725: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-07-22 13:44:23.752837: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import typing\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.base import ClassifierMixin\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection._search import BaseSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AAC / DAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-22 13:44:29.437256: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-07-22 13:44:29.437475: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-07-22 13:44:29.437586: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (A7LAB): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from libfeatureselection import model, model_space\n",
    "n_jobs = (\n",
    "    (os.cpu_count() - 2)\n",
    "    if \"n_jobs\" not in os.environ or os.environ['n_jobs'] == \"\" else\n",
    "    int(os.environ['n_jobs'])\n",
    ")\n",
    "n_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:14<00:00,  1.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_result_in_a_scheme_df = pd.DataFrame()\n",
    "for model_index in tqdm.tqdm(range(len(model_space.find_space))):\n",
    "    if model_space.find_space[model_index]['name'] not in [\n",
    "        'SVC',\n",
    "        'GaussianNB',\n",
    "        'RandomForestClassifier',\n",
    "        'DecisionTreeClassifier'\n",
    "    ]:\n",
    "        continue\n",
    "    model_information_summary, searched_result_performance_summary, searched_result_5C_performance_summary = model.MyOptimitzer(\n",
    "        classifier_name=model_space.find_space[model_index]['name'],\n",
    "        classifier_class=model_space.find_space[model_index]['class'],\n",
    "        classifier_param_dict=model_space.find_space[model_index]['param'],\n",
    "    ).find_best(\n",
    "        X=pd.concat([ac_data['t_p'], ac_data['t_n']]).values,\n",
    "        y=np.concatenate([np.ones((ac_data['t_p'].shape[0], )), np.zeros((ac_data['t_n'].shape[0], ))]),\n",
    "        validation=(\n",
    "            pd.concat([ac_data['v_p'], ac_data['v_n']]).values,\n",
    "            np.concatenate([np.ones((ac_data['v_p'].shape[0], )), np.zeros((ac_data['v_n'].shape[0], ))]),\n",
    "        ),\n",
    "        search_method=(\n",
    "            \"BayesSearchCV\"\n",
    "            if \"Bayes\" not in model_space.find_space[model_index]\n",
    "            or model_space.find_space[model_index]['Bayes'] == True\n",
    "            else \"GridSearchCV\"\n",
    "        ),\n",
    "        n_jobs=n_jobs\n",
    "    ).get_summary(\n",
    "        path_to_dir=f\"out/libfeatureselection/T1/T1SEstacker-RTX/model/ac/\"\n",
    "    )\n",
    "\n",
    "    # 记录结果，插入到 search_result_in_a_scheme_df\n",
    "    result_series = pd.concat([\n",
    "        pd.Series(model_information_summary),\n",
    "        pd.Series(searched_result_performance_summary),\n",
    "        pd.Series(searched_result_5C_performance_summary),\n",
    "    ], keys=[\n",
    "        \"Model_Information\",\n",
    "        \"Best_Performance\",\n",
    "        \"5FoldCV_Performance\",\n",
    "    ])\n",
    "\n",
    "    result_series.name = model_index\n",
    "\n",
    "    search_result_in_a_scheme_df = pd.concat([\n",
    "        search_result_in_a_scheme_df,\n",
    "        result_series.to_frame().T\n",
    "    ], axis=0, ignore_index=False)\n",
    "\n",
    "    search_result_in_a_scheme_df.index = search_result_in_a_scheme_df.index.set_names(\n",
    "        [\"Model_Type\",]\n",
    "    )\n",
    "\n",
    "    local_xlsx_path = f\"out/libfeatureselection/T1/T1SEstacker-RTX/model/ac/searched_result.xlsx\"\n",
    "\n",
    "    # 缓存 search_result_in_a_scheme_df\n",
    "    search_result_in_a_scheme_df.to_excel(\n",
    "        local_xlsx_path,\n",
    "        \"T1SEstacker-RTX\",\n",
    "        freeze_panes=(2, 1)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPBAac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 15/15 [00:02<00:00,  6.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_result_in_a_scheme_df = pd.DataFrame()\n",
    "for model_index in tqdm.tqdm(range(len(model_space.find_space))):\n",
    "    if model_space.find_space[model_index]['name'] not in [\n",
    "        'SVC',\n",
    "    ]:\n",
    "        continue\n",
    "    model_information_summary, searched_result_performance_summary, searched_result_5C_performance_summary = model.MyOptimitzer(\n",
    "        classifier_name=model_space.find_space[model_index]['name'],\n",
    "        classifier_class=model_space.find_space[model_index]['class'],\n",
    "        classifier_param_dict=model_space.find_space[model_index]['param'],\n",
    "    ).find_best(\n",
    "        X=pd.concat([ac_data['t_p'], ac_data['t_n']]).values,\n",
    "        y=np.concatenate([np.ones((ac_data['t_p'].shape[0], )), np.zeros((ac_data['t_n'].shape[0], ))]),\n",
    "        validation=(\n",
    "            pd.concat([ac_data['v_p'], ac_data['v_n']]).values,\n",
    "            np.concatenate([np.ones((ac_data['v_p'].shape[0], )), np.zeros((ac_data['v_n'].shape[0], ))]),\n",
    "        ),\n",
    "        search_method=(\n",
    "            \"BayesSearchCV\"\n",
    "            if \"Bayes\" not in model_space.find_space[model_index]\n",
    "            or model_space.find_space[model_index]['Bayes'] == True\n",
    "            else \"GridSearchCV\"\n",
    "        ),\n",
    "        n_jobs=n_jobs\n",
    "    ).get_summary(\n",
    "        path_to_dir=f\"out/libfeatureselection/T1/T1SEstacker-RTX/model/bpb\"\n",
    "    )\n",
    "\n",
    "    # 记录结果，插入到 search_result_in_a_scheme_df\n",
    "    result_series = pd.concat([\n",
    "        pd.Series(model_information_summary),\n",
    "        pd.Series(searched_result_performance_summary),\n",
    "        pd.Series(searched_result_5C_performance_summary),\n",
    "    ], keys=[\n",
    "        \"Model_Information\",\n",
    "        \"Best_Performance\",\n",
    "        \"5FoldCV_Performance\",\n",
    "    ])\n",
    "\n",
    "    result_series.name = model_index\n",
    "\n",
    "    search_result_in_a_scheme_df = pd.concat([\n",
    "        search_result_in_a_scheme_df,\n",
    "        result_series.to_frame().T\n",
    "    ], axis=0, ignore_index=False)\n",
    "\n",
    "    search_result_in_a_scheme_df.index = search_result_in_a_scheme_df.index.set_names(\n",
    "        [\"Model_Type\",]\n",
    "    )\n",
    "\n",
    "    local_xlsx_path = f\"out/libfeatureselection/T1/T1SEstacker-RTX/model/bpb/searched_result.xlsx\"\n",
    "\n",
    "    # 缓存 search_result_in_a_scheme_df\n",
    "    search_result_in_a_scheme_df.to_excel(\n",
    "        local_xlsx_path,\n",
    "        \"T1SEstacker-RTX\",\n",
    "        freeze_panes=(2, 1)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DNN_model(seq_length: int, sizeof_ac_dict: int):\n",
    "    input1 = tf.keras.layers.Input(shape=(seq_length,), name='Input_Layer')\n",
    "    embedding1 = tf.keras.layers.Embedding(\n",
    "        input_dim=sizeof_ac_dict, output_dim=sizeof_ac_dict, name=\"AC_EMBEDED\")(input1)\n",
    "    flatten_layer = tf.keras.layers.Flatten()(embedding1)\n",
    "    dense3 = tf.keras.layers.Dense(\n",
    "        1, activation=tf.keras.activations.sigmoid)(flatten_layer)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=input1, outputs=dense3, name='simple')\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "        loss=tf.keras.losses.binary_crossentropy,\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(),\n",
    "            tf.keras.metrics.AUC(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.TruePositives(),\n",
    "            tf.keras.metrics.TrueNegatives(),\n",
    "            tf.keras.metrics.FalsePositives(),\n",
    "            tf.keras.metrics.FalseNegatives()\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "class DNN_Trainer:\n",
    "    def __init__(self, ) -> None:\n",
    "        self.classifier_name = \"DNN\"\n",
    "        self.classifier_class = get_DNN_model\n",
    "        self.classifier_param_dict = {\n",
    "            \"seq_length\": 60,\n",
    "            \"sizeof_ac_dict\": 20\n",
    "        }\n",
    "\n",
    "        self.model = None\n",
    "        self.train_best_predicted_pair = None\n",
    "        self.train_best_5C_predicted_pair = None\n",
    "        self.best_predicted_pair = None\n",
    "        self.best_5C_predicted_pair = None\n",
    "        self.start_to_train_time = datetime.now()\n",
    "        self.end_of_train_time = None\n",
    "        pass\n",
    "\n",
    "    def find_best(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        validation: tuple,\n",
    "    ):\n",
    "\n",
    "        self.model = self.classifier_class(\n",
    "            **self.classifier_param_dict\n",
    "        )\n",
    "        self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            epochs=10,\n",
    "            use_multiprocessing=True,\n",
    "            steps_per_epoch=None,\n",
    "            verbose=2\n",
    "        )\n",
    "        self.best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                validation[0]\n",
    "            ), nan=0.0),\n",
    "            validation[1]\n",
    "        ]\n",
    "        self.train_best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                X\n",
    "            ), nan=0.0),\n",
    "            y\n",
    "        ]\n",
    "\n",
    "        # 5倍交叉验证\n",
    "        # 合并数据\n",
    "        full_X = np.concatenate([\n",
    "            X, validation[0]\n",
    "        ])\n",
    "        full_y = np.concatenate([\n",
    "            y, validation[1]\n",
    "        ])\n",
    "\n",
    "        # 跑模型\n",
    "        self.best_5C_predicted_pair = []\n",
    "        self.train_best_5C_predicted_pair = []\n",
    "        for Kfold_id, (train_id, test_id) in enumerate(\n",
    "            StratifiedKFold(\n",
    "                n_splits=5,\n",
    "                shuffle=True,\n",
    "                random_state=42\n",
    "            ).split(full_X, full_y)\n",
    "        ):\n",
    "\n",
    "            # 定义模型并加载参数\n",
    "            fiveC_model = self.classifier_class(\n",
    "                **self.classifier_param_dict,\n",
    "            )\n",
    "\n",
    "            fiveC_model.fit(\n",
    "                full_X[train_id],\n",
    "                full_y[train_id],\n",
    "                epochs=10,\n",
    "                use_multiprocessing=True,\n",
    "                steps_per_epoch=None,\n",
    "                verbose=2\n",
    "            )\n",
    "\n",
    "            # 预测并记录\n",
    "            self.best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    full_X[test_id]\n",
    "                ), nan=0.0),\n",
    "                full_y[test_id]\n",
    "            ])\n",
    "            self.train_best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    full_X[train_id]\n",
    "                ), nan=0.0),\n",
    "                full_y[train_id]\n",
    "            ])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_summary(self, path_to_dir: str = None):\n",
    "        os.makedirs(path_to_dir, exist_ok=True)\n",
    "        model_path = \"-\"\n",
    "        if \"SAVE_MODEL\" in os.environ and os.environ['SAVE_MODEL'] == \"1\":\n",
    "\n",
    "            model_path = f\"{path_to_dir}/{self.classifier_name}.pkl\"\n",
    "            if path_to_dir is not None:\n",
    "                with gzip.open(model_path, \"wb\") as f:\n",
    "                    pickle.dump(\n",
    "                        self.grid_search, f\n",
    "                    )\n",
    "\n",
    "        model_score_path = f\"{path_to_dir}/{self.classifier_name}_score.pkl\"\n",
    "        if path_to_dir is not None:\n",
    "            with gzip.open(model_score_path, \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "            with gzip.open(model_score_path + \".train\", \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.train_best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.train_best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "        else:\n",
    "            model_score_path = \"-\"\n",
    "\n",
    "        plot_roc_curve(\n",
    "            target=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "            path_to_=f\"{path_to_dir}/{self.classifier_name}.pdf\"\n",
    "        )\n",
    "\n",
    "        model_information = {\n",
    "            \"Classifier_Name\": self.classifier_name,\n",
    "            \"Optimitied_Param\": dict(),\n",
    "            \"Score\": model_score_path,\n",
    "            \"Model_Path\": model_path,\n",
    "            \"TimeToStartFit\": self.start_to_train_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "\n",
    "        training_testing_performance = get_evaluation(\n",
    "            label=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "        )\n",
    "\n",
    "        # 计算5C中的平均表现\n",
    "        FiveFold_result = {}\n",
    "        for keys in training_testing_performance.keys():\n",
    "            value_list = []\n",
    "            for item in self.best_5C_predicted_pair:\n",
    "\n",
    "                item_performance = get_evaluation(\n",
    "                    label=item[1],\n",
    "                    pred=item[0],\n",
    "                )\n",
    "                value_list.append(item_performance[keys])\n",
    "\n",
    "            if keys == \"pro_cutoff\":\n",
    "                FiveFold_result[keys] = value_list\n",
    "            else:\n",
    "                FiveFold_result[keys] = sum(value_list) / len(value_list)\n",
    "\n",
    "        self.end_of_train_time = datetime.now()\n",
    "        model_information[\"TimeOfSummary\"] = self.end_of_train_time.strftime(\n",
    "            \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "        model_information[\"TimeSpend\"] = str(\n",
    "            self.end_of_train_time - self.start_to_train_time\n",
    "        )\n",
    "\n",
    "        return model_information, training_testing_performance, FiveFold_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-22 13:46:07.601818: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 - 6s - loss: 0.6800 - binary_accuracy: 0.6351 - auc: 0.6902 - precision: 0.6786 - true_positives: 38.0000 - true_negatives: 56.0000 - false_positives: 18.0000 - false_negatives: 36.0000 - 6s/epoch - 1s/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.5499 - binary_accuracy: 0.9392 - auc: 0.9947 - precision: 0.9012 - true_positives: 73.0000 - true_negatives: 66.0000 - false_positives: 8.0000 - false_negatives: 1.0000 - 58ms/epoch - 12ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.3737 - binary_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - true_positives: 74.0000 - true_negatives: 74.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - 82ms/epoch - 16ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.2021 - binary_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - true_positives: 74.0000 - true_negatives: 74.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - 57ms/epoch - 11ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.1004 - binary_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - true_positives: 74.0000 - true_negatives: 74.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - 34ms/epoch - 7ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.0436 - binary_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - true_positives: 74.0000 - true_negatives: 74.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - 40ms/epoch - 8ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.0214 - binary_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - true_positives: 74.0000 - true_negatives: 74.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - 40ms/epoch - 8ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.0115 - binary_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - true_positives: 74.0000 - true_negatives: 74.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - 42ms/epoch - 8ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.0069 - binary_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - true_positives: 74.0000 - true_negatives: 74.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - 39ms/epoch - 8ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.0047 - binary_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - true_positives: 74.0000 - true_negatives: 74.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - 48ms/epoch - 10ms/step\n",
      "2/2 [==============================] - 0s 24ms/step\n",
      "5/5 [==============================] - 0s 12ms/step\n",
      "Epoch 1/10\n",
      "5/5 - 10s - loss: 0.6790 - binary_accuracy: 0.5506 - auc_1: 0.6840 - precision_1: 0.5370 - true_positives_1: 58.0000 - true_negatives_1: 29.0000 - false_positives_1: 50.0000 - false_negatives_1: 21.0000 - 10s/epoch - 2s/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.5540 - binary_accuracy: 0.9177 - auc_1: 0.9839 - precision_1: 0.8929 - true_positives_1: 75.0000 - true_negatives_1: 70.0000 - false_positives_1: 9.0000 - false_negatives_1: 4.0000 - 35ms/epoch - 7ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.3888 - binary_accuracy: 0.9620 - auc_1: 0.9872 - precision_1: 1.0000 - true_positives_1: 73.0000 - true_negatives_1: 79.0000 - false_positives_1: 0.0000e+00 - false_negatives_1: 6.0000 - 40ms/epoch - 8ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.2380 - binary_accuracy: 0.9810 - auc_1: 0.9958 - precision_1: 1.0000 - true_positives_1: 76.0000 - true_negatives_1: 79.0000 - false_positives_1: 0.0000e+00 - false_negatives_1: 3.0000 - 36ms/epoch - 7ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.1367 - binary_accuracy: 0.9873 - auc_1: 0.9986 - precision_1: 1.0000 - true_positives_1: 77.0000 - true_negatives_1: 79.0000 - false_positives_1: 0.0000e+00 - false_negatives_1: 2.0000 - 36ms/epoch - 7ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.0794 - binary_accuracy: 0.9937 - auc_1: 1.0000 - precision_1: 1.0000 - true_positives_1: 78.0000 - true_negatives_1: 79.0000 - false_positives_1: 0.0000e+00 - false_negatives_1: 1.0000 - 54ms/epoch - 11ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.0414 - binary_accuracy: 1.0000 - auc_1: 1.0000 - precision_1: 1.0000 - true_positives_1: 79.0000 - true_negatives_1: 79.0000 - false_positives_1: 0.0000e+00 - false_negatives_1: 0.0000e+00 - 38ms/epoch - 8ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.0235 - binary_accuracy: 1.0000 - auc_1: 1.0000 - precision_1: 1.0000 - true_positives_1: 79.0000 - true_negatives_1: 79.0000 - false_positives_1: 0.0000e+00 - false_negatives_1: 0.0000e+00 - 45ms/epoch - 9ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.0144 - binary_accuracy: 1.0000 - auc_1: 1.0000 - precision_1: 1.0000 - true_positives_1: 79.0000 - true_negatives_1: 79.0000 - false_positives_1: 0.0000e+00 - false_negatives_1: 0.0000e+00 - 53ms/epoch - 11ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.0094 - binary_accuracy: 1.0000 - auc_1: 1.0000 - precision_1: 1.0000 - true_positives_1: 79.0000 - true_negatives_1: 79.0000 - false_positives_1: 0.0000e+00 - false_negatives_1: 0.0000e+00 - 49ms/epoch - 10ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "5/5 [==============================] - 0s 8ms/step\n",
      "Epoch 1/10\n",
      "5/5 - 6s - loss: 0.6828 - binary_accuracy: 0.6392 - auc_2: 0.6732 - precision_2: 0.6310 - true_positives_2: 53.0000 - true_negatives_2: 48.0000 - false_positives_2: 31.0000 - false_negatives_2: 26.0000 - 6s/epoch - 1s/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.5694 - binary_accuracy: 0.9367 - auc_2: 0.9905 - precision_2: 0.9157 - true_positives_2: 76.0000 - true_negatives_2: 72.0000 - false_positives_2: 7.0000 - false_negatives_2: 3.0000 - 51ms/epoch - 10ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.4079 - binary_accuracy: 0.9684 - auc_2: 0.9955 - precision_2: 0.9744 - true_positives_2: 76.0000 - true_negatives_2: 77.0000 - false_positives_2: 2.0000 - false_negatives_2: 3.0000 - 37ms/epoch - 7ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.2453 - binary_accuracy: 0.9747 - auc_2: 0.9986 - precision_2: 0.9870 - true_positives_2: 76.0000 - true_negatives_2: 78.0000 - false_positives_2: 1.0000 - false_negatives_2: 3.0000 - 39ms/epoch - 8ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.1310 - binary_accuracy: 0.9937 - auc_2: 1.0000 - precision_2: 1.0000 - true_positives_2: 78.0000 - true_negatives_2: 79.0000 - false_positives_2: 0.0000e+00 - false_negatives_2: 1.0000 - 41ms/epoch - 8ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.0669 - binary_accuracy: 0.9937 - auc_2: 1.0000 - precision_2: 1.0000 - true_positives_2: 78.0000 - true_negatives_2: 79.0000 - false_positives_2: 0.0000e+00 - false_negatives_2: 1.0000 - 38ms/epoch - 8ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.0328 - binary_accuracy: 1.0000 - auc_2: 1.0000 - precision_2: 1.0000 - true_positives_2: 79.0000 - true_negatives_2: 79.0000 - false_positives_2: 0.0000e+00 - false_negatives_2: 0.0000e+00 - 36ms/epoch - 7ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.0170 - binary_accuracy: 1.0000 - auc_2: 1.0000 - precision_2: 1.0000 - true_positives_2: 79.0000 - true_negatives_2: 79.0000 - false_positives_2: 0.0000e+00 - false_negatives_2: 0.0000e+00 - 36ms/epoch - 7ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.0099 - binary_accuracy: 1.0000 - auc_2: 1.0000 - precision_2: 1.0000 - true_positives_2: 79.0000 - true_negatives_2: 79.0000 - false_positives_2: 0.0000e+00 - false_negatives_2: 0.0000e+00 - 41ms/epoch - 8ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.0064 - binary_accuracy: 1.0000 - auc_2: 1.0000 - precision_2: 1.0000 - true_positives_2: 79.0000 - true_negatives_2: 79.0000 - false_positives_2: 0.0000e+00 - false_negatives_2: 0.0000e+00 - 37ms/epoch - 7ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "5/5 [==============================] - 0s 8ms/step\n",
      "Epoch 1/10\n",
      "5/5 - 6s - loss: 0.6736 - binary_accuracy: 0.6899 - auc_3: 0.7722 - precision_3: 0.6875 - true_positives_3: 55.0000 - true_negatives_3: 54.0000 - false_positives_3: 25.0000 - false_negatives_3: 24.0000 - 6s/epoch - 1s/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.5456 - binary_accuracy: 0.9684 - auc_3: 0.9918 - precision_3: 0.9744 - true_positives_3: 76.0000 - true_negatives_3: 77.0000 - false_positives_3: 2.0000 - false_negatives_3: 3.0000 - 56ms/epoch - 11ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.3711 - binary_accuracy: 0.9747 - auc_3: 0.9974 - precision_3: 0.9870 - true_positives_3: 76.0000 - true_negatives_3: 78.0000 - false_positives_3: 1.0000 - false_negatives_3: 3.0000 - 72ms/epoch - 14ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.2169 - binary_accuracy: 0.9747 - auc_3: 0.9989 - precision_3: 0.9870 - true_positives_3: 76.0000 - true_negatives_3: 78.0000 - false_positives_3: 1.0000 - false_negatives_3: 3.0000 - 51ms/epoch - 10ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.1171 - binary_accuracy: 0.9937 - auc_3: 1.0000 - precision_3: 1.0000 - true_positives_3: 78.0000 - true_negatives_3: 79.0000 - false_positives_3: 0.0000e+00 - false_negatives_3: 1.0000 - 52ms/epoch - 10ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.0594 - binary_accuracy: 1.0000 - auc_3: 1.0000 - precision_3: 1.0000 - true_positives_3: 79.0000 - true_negatives_3: 79.0000 - false_positives_3: 0.0000e+00 - false_negatives_3: 0.0000e+00 - 53ms/epoch - 11ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.0283 - binary_accuracy: 1.0000 - auc_3: 1.0000 - precision_3: 1.0000 - true_positives_3: 79.0000 - true_negatives_3: 79.0000 - false_positives_3: 0.0000e+00 - false_negatives_3: 0.0000e+00 - 53ms/epoch - 11ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.0171 - binary_accuracy: 1.0000 - auc_3: 1.0000 - precision_3: 1.0000 - true_positives_3: 79.0000 - true_negatives_3: 79.0000 - false_positives_3: 0.0000e+00 - false_negatives_3: 0.0000e+00 - 71ms/epoch - 14ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.0096 - binary_accuracy: 1.0000 - auc_3: 1.0000 - precision_3: 1.0000 - true_positives_3: 79.0000 - true_negatives_3: 79.0000 - false_positives_3: 0.0000e+00 - false_negatives_3: 0.0000e+00 - 54ms/epoch - 11ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.0066 - binary_accuracy: 1.0000 - auc_3: 1.0000 - precision_3: 1.0000 - true_positives_3: 79.0000 - true_negatives_3: 79.0000 - false_positives_3: 0.0000e+00 - false_negatives_3: 0.0000e+00 - 61ms/epoch - 12ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "Epoch 1/10\n",
      "5/5 - 4s - loss: 0.6799 - binary_accuracy: 0.6352 - auc_4: 0.7002 - precision_4: 0.6129 - true_positives_4: 57.0000 - true_negatives_4: 44.0000 - false_positives_4: 36.0000 - false_negatives_4: 22.0000 - 4s/epoch - 784ms/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.5666 - binary_accuracy: 0.9497 - auc_4: 0.9877 - precision_4: 0.9610 - true_positives_4: 74.0000 - true_negatives_4: 77.0000 - false_positives_4: 3.0000 - false_negatives_4: 5.0000 - 36ms/epoch - 7ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.4118 - binary_accuracy: 0.9560 - auc_4: 0.9947 - precision_4: 0.9865 - true_positives_4: 73.0000 - true_negatives_4: 79.0000 - false_positives_4: 1.0000 - false_negatives_4: 6.0000 - 38ms/epoch - 8ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.2512 - binary_accuracy: 0.9748 - auc_4: 0.9980 - precision_4: 0.9870 - true_positives_4: 76.0000 - true_negatives_4: 79.0000 - false_positives_4: 1.0000 - false_negatives_4: 3.0000 - 38ms/epoch - 8ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.1370 - binary_accuracy: 0.9811 - auc_4: 0.9995 - precision_4: 0.9872 - true_positives_4: 77.0000 - true_negatives_4: 79.0000 - false_positives_4: 1.0000 - false_negatives_4: 2.0000 - 38ms/epoch - 8ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.0722 - binary_accuracy: 0.9937 - auc_4: 1.0000 - precision_4: 1.0000 - true_positives_4: 78.0000 - true_negatives_4: 80.0000 - false_positives_4: 0.0000e+00 - false_negatives_4: 1.0000 - 37ms/epoch - 7ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.0345 - binary_accuracy: 1.0000 - auc_4: 1.0000 - precision_4: 1.0000 - true_positives_4: 79.0000 - true_negatives_4: 80.0000 - false_positives_4: 0.0000e+00 - false_negatives_4: 0.0000e+00 - 38ms/epoch - 8ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.0183 - binary_accuracy: 1.0000 - auc_4: 1.0000 - precision_4: 1.0000 - true_positives_4: 79.0000 - true_negatives_4: 80.0000 - false_positives_4: 0.0000e+00 - false_negatives_4: 0.0000e+00 - 38ms/epoch - 8ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.0110 - binary_accuracy: 1.0000 - auc_4: 1.0000 - precision_4: 1.0000 - true_positives_4: 79.0000 - true_negatives_4: 80.0000 - false_positives_4: 0.0000e+00 - false_negatives_4: 0.0000e+00 - 57ms/epoch - 11ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.0072 - binary_accuracy: 1.0000 - auc_4: 1.0000 - precision_4: 1.0000 - true_positives_4: 79.0000 - true_negatives_4: 80.0000 - false_positives_4: 0.0000e+00 - false_negatives_4: 0.0000e+00 - 51ms/epoch - 10ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "Epoch 1/10\n",
      "5/5 - 9s - loss: 0.6856 - binary_accuracy: 0.5723 - auc_5: 0.6087 - precision_5: 0.5625 - true_positives_5: 54.0000 - true_negatives_5: 37.0000 - false_positives_5: 42.0000 - false_negatives_5: 26.0000 - 9s/epoch - 2s/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.5858 - binary_accuracy: 0.8994 - auc_5: 0.9787 - precision_5: 0.8556 - true_positives_5: 77.0000 - true_negatives_5: 66.0000 - false_positives_5: 13.0000 - false_negatives_5: 3.0000 - 57ms/epoch - 11ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.4432 - binary_accuracy: 0.9560 - auc_5: 0.9935 - precision_5: 0.9506 - true_positives_5: 77.0000 - true_negatives_5: 75.0000 - false_positives_5: 4.0000 - false_negatives_5: 3.0000 - 55ms/epoch - 11ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.2908 - binary_accuracy: 0.9748 - auc_5: 0.9981 - precision_5: 0.9872 - true_positives_5: 77.0000 - true_negatives_5: 78.0000 - false_positives_5: 1.0000 - false_negatives_5: 3.0000 - 52ms/epoch - 10ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.1692 - binary_accuracy: 0.9811 - auc_5: 0.9995 - precision_5: 0.9873 - true_positives_5: 78.0000 - true_negatives_5: 78.0000 - false_positives_5: 1.0000 - false_negatives_5: 2.0000 - 56ms/epoch - 11ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.0933 - binary_accuracy: 1.0000 - auc_5: 1.0000 - precision_5: 1.0000 - true_positives_5: 80.0000 - true_negatives_5: 79.0000 - false_positives_5: 0.0000e+00 - false_negatives_5: 0.0000e+00 - 63ms/epoch - 13ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.0501 - binary_accuracy: 1.0000 - auc_5: 1.0000 - precision_5: 1.0000 - true_positives_5: 80.0000 - true_negatives_5: 79.0000 - false_positives_5: 0.0000e+00 - false_negatives_5: 0.0000e+00 - 56ms/epoch - 11ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.0263 - binary_accuracy: 1.0000 - auc_5: 1.0000 - precision_5: 1.0000 - true_positives_5: 80.0000 - true_negatives_5: 79.0000 - false_positives_5: 0.0000e+00 - false_negatives_5: 0.0000e+00 - 57ms/epoch - 11ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.0149 - binary_accuracy: 1.0000 - auc_5: 1.0000 - precision_5: 1.0000 - true_positives_5: 80.0000 - true_negatives_5: 79.0000 - false_positives_5: 0.0000e+00 - false_negatives_5: 0.0000e+00 - 53ms/epoch - 11ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.0095 - binary_accuracy: 1.0000 - auc_5: 1.0000 - precision_5: 1.0000 - true_positives_5: 80.0000 - true_negatives_5: 79.0000 - false_positives_5: 0.0000e+00 - false_negatives_5: 0.0000e+00 - 67ms/epoch - 13ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "5/5 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Classifier_Name': 'DNN',\n",
       "  'Optimitied_Param': {},\n",
       "  'Score': 'out/libfeatureselection/T1/T1SEstacker-RTX//DNN_score.pkl',\n",
       "  'Model_Path': '-',\n",
       "  'TimeToStartFit': '2023-07-22 13:46:07',\n",
       "  'TimeOfSummary': '2023-07-22 13:47:03',\n",
       "  'TimeSpend': '0:00:55.723758'},\n",
       " {'accuracy': 0.76,\n",
       "  'precision': 0.8421052631578947,\n",
       "  'f1_score': 0.7272727272727272,\n",
       "  'mmc': 0.5356556682297139,\n",
       "  'rocAUC': 0.8,\n",
       "  'specificity': 0.88,\n",
       "  'sensitivity': 0.64,\n",
       "  'pro_cutoff': 0.23253872},\n",
       " {'accuracy': 0.8987179487179487,\n",
       "  'precision': 0.9251082251082252,\n",
       "  'f1_score': 0.893901674919005,\n",
       "  'mmc': 0.8060895619300334,\n",
       "  'rocAUC': 0.9421315789473684,\n",
       "  'specificity': 0.9184210526315789,\n",
       "  'sensitivity': 0.8768421052631579,\n",
       "  'pro_cutoff': [0.69159526, 0.07496858, 0.5368884, 0.6837912, 0.8814933]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DNN_Trainer().find_best(\n",
    "    X=pd.concat([digitaa_data['t_p'], digitaa_data['t_n']]),\n",
    "    y=np.concatenate([np.ones((digitaa_data['t_p'].shape[0], )), np.zeros((digitaa_data['t_n'].shape[0], ))]),\n",
    "    validation=(\n",
    "        pd.concat([digitaa_data['v_p'], digitaa_data['v_n']]),\n",
    "        np.concatenate([np.ones((digitaa_data['v_p'].shape[0], )), np.zeros((digitaa_data['v_n'].shape[0], ))]),\n",
    "    )\n",
    ").get_summary(\n",
    "    path_to_dir=\"out/libfeatureselection/T1/T1SEstacker-RTX/\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RNN_model(seq_length: int, sizeof_ac_dict: int):\n",
    "    input1 = tf.keras.layers.Input(shape=(seq_length,), name='Input_Layer')\n",
    "    embedding1 = tf.keras.layers.Embedding(\n",
    "        input_dim=sizeof_ac_dict, output_dim=sizeof_ac_dict, name=\"AC_EMBEDED\")(input1)\n",
    "\n",
    "    conv1 = tf.keras.layers.LSTM(10)(embedding1)\n",
    "\n",
    "    flatten_layer = tf.keras.layers.Flatten()(conv1)\n",
    "\n",
    "    dense3 = tf.keras.layers.Dense(\n",
    "        1, activation=tf.keras.activations.sigmoid)(flatten_layer)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=input1, outputs=dense3, name='simple_WithRNN')\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "        loss=tf.keras.losses.binary_crossentropy,\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(),\n",
    "            tf.keras.metrics.AUC(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.TruePositives(),\n",
    "            tf.keras.metrics.TrueNegatives(),\n",
    "            tf.keras.metrics.FalsePositives(),\n",
    "            tf.keras.metrics.FalseNegatives()\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "class RNN_Trainer:\n",
    "    def __init__(self, ) -> None:\n",
    "        self.classifier_name = \"RNN\"\n",
    "        self.classifier_class = get_RNN_model\n",
    "        self.classifier_param_dict = {\n",
    "            \"seq_length\": 60,\n",
    "            \"sizeof_ac_dict\": 20\n",
    "        }\n",
    "\n",
    "        self.model = None\n",
    "        self.train_best_predicted_pair = None\n",
    "        self.train_best_5C_predicted_pair = None\n",
    "        self.best_predicted_pair = None\n",
    "        self.best_5C_predicted_pair = None\n",
    "        self.start_to_train_time = datetime.now()\n",
    "        self.end_of_train_time = None\n",
    "        pass\n",
    "\n",
    "    def find_best(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        validation: tuple,\n",
    "    ):\n",
    "\n",
    "        self.model = self.classifier_class(\n",
    "            **self.classifier_param_dict\n",
    "        )\n",
    "        self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            epochs=10,\n",
    "            use_multiprocessing=True,\n",
    "            steps_per_epoch=None,\n",
    "            verbose=2\n",
    "        )\n",
    "        self.best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                validation[0]\n",
    "            ), nan=0.0),\n",
    "            validation[1]\n",
    "        ]\n",
    "        self.train_best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                X\n",
    "            ), nan=0.0),\n",
    "            y\n",
    "        ]\n",
    "\n",
    "        # 5倍交叉验证\n",
    "        # 合并数据\n",
    "        full_X = np.concatenate([\n",
    "            X, validation[0]\n",
    "        ])\n",
    "        full_y = np.concatenate([\n",
    "            y, validation[1]\n",
    "        ])\n",
    "\n",
    "        # 跑模型\n",
    "        self.best_5C_predicted_pair = []\n",
    "        self.train_best_5C_predicted_pair = []\n",
    "        for Kfold_id, (train_id, test_id) in enumerate(\n",
    "            StratifiedKFold(\n",
    "                n_splits=5,\n",
    "                shuffle=True,\n",
    "                random_state=42\n",
    "            ).split(full_X, full_y)\n",
    "        ):\n",
    "\n",
    "            # 定义模型并加载参数\n",
    "            fiveC_model = self.classifier_class(\n",
    "                **self.classifier_param_dict,\n",
    "            )\n",
    "\n",
    "            fiveC_model.fit(\n",
    "                full_X[train_id],\n",
    "                full_y[train_id],\n",
    "                epochs=10,\n",
    "                use_multiprocessing=True,\n",
    "                steps_per_epoch=None,\n",
    "                verbose=2\n",
    "            )\n",
    "\n",
    "            # 预测并记录\n",
    "            self.best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    full_X[test_id]\n",
    "                ), nan=0.0),\n",
    "                full_y[test_id]\n",
    "            ])\n",
    "            self.train_best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    full_X[train_id]\n",
    "                ), nan=0.0),\n",
    "                full_y[train_id]\n",
    "            ])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_summary(self, path_to_dir: str = None):\n",
    "        os.makedirs(path_to_dir, exist_ok=True)\n",
    "        model_path = \"-\"\n",
    "        if \"SAVE_MODEL\" in os.environ and os.environ['SAVE_MODEL'] == \"1\":\n",
    "\n",
    "            model_path = f\"{path_to_dir}/{self.classifier_name}.pkl\"\n",
    "            if path_to_dir is not None:\n",
    "                with gzip.open(model_path, \"wb\") as f:\n",
    "                    pickle.dump(\n",
    "                        self.grid_search, f\n",
    "                    )\n",
    "\n",
    "        model_score_path = f\"{path_to_dir}/{self.classifier_name}_score.pkl\"\n",
    "        if path_to_dir is not None:\n",
    "            with gzip.open(model_score_path, \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "            with gzip.open(model_score_path + \".train\", \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.train_best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.train_best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "        else:\n",
    "            model_score_path = \"-\"\n",
    "\n",
    "        plot_roc_curve(\n",
    "            target=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "            path_to_=f\"{path_to_dir}/{self.classifier_name}.pdf\"\n",
    "        )\n",
    "\n",
    "        model_information = {\n",
    "            \"Classifier_Name\": self.classifier_name,\n",
    "            \"Optimitied_Param\": dict(),\n",
    "            \"Score\": model_score_path,\n",
    "            \"Model_Path\": model_path,\n",
    "            \"TimeToStartFit\": self.start_to_train_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "\n",
    "        training_testing_performance = get_evaluation(\n",
    "            label=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "        )\n",
    "\n",
    "        # 计算5C中的平均表现\n",
    "        FiveFold_result = {}\n",
    "        for keys in training_testing_performance.keys():\n",
    "            value_list = []\n",
    "            for item in self.best_5C_predicted_pair:\n",
    "\n",
    "                item_performance = get_evaluation(\n",
    "                    label=item[1],\n",
    "                    pred=item[0],\n",
    "                )\n",
    "                value_list.append(item_performance[keys])\n",
    "\n",
    "            if keys == \"pro_cutoff\":\n",
    "                FiveFold_result[keys] = value_list\n",
    "            else:\n",
    "                FiveFold_result[keys] = sum(value_list) / len(value_list)\n",
    "\n",
    "        self.end_of_train_time = datetime.now()\n",
    "        model_information[\"TimeOfSummary\"] = self.end_of_train_time.strftime(\n",
    "            \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "        model_information[\"TimeSpend\"] = str(\n",
    "            self.end_of_train_time - self.start_to_train_time\n",
    "        )\n",
    "\n",
    "        return model_information, training_testing_performance, FiveFold_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 - 12s - loss: 0.6872 - binary_accuracy: 0.5405 - auc_6: 0.5957 - precision_6: 0.5214 - true_positives_6: 73.0000 - true_negatives_6: 7.0000 - false_positives_6: 67.0000 - false_negatives_6: 1.0000 - 12s/epoch - 2s/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.6143 - binary_accuracy: 0.7838 - auc_6: 0.9410 - precision_6: 0.7059 - true_positives_6: 72.0000 - true_negatives_6: 44.0000 - false_positives_6: 30.0000 - false_negatives_6: 2.0000 - 337ms/epoch - 67ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.4014 - binary_accuracy: 0.9054 - auc_6: 0.9505 - precision_6: 0.8846 - true_positives_6: 69.0000 - true_negatives_6: 65.0000 - false_positives_6: 9.0000 - false_negatives_6: 5.0000 - 351ms/epoch - 70ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.3737 - binary_accuracy: 0.8378 - auc_6: 0.9317 - precision_6: 0.8378 - true_positives_6: 62.0000 - true_negatives_6: 62.0000 - false_positives_6: 12.0000 - false_negatives_6: 12.0000 - 283ms/epoch - 57ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.2986 - binary_accuracy: 0.8784 - auc_6: 0.9677 - precision_6: 0.8684 - true_positives_6: 66.0000 - true_negatives_6: 64.0000 - false_positives_6: 10.0000 - false_negatives_6: 8.0000 - 262ms/epoch - 52ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.2559 - binary_accuracy: 0.9122 - auc_6: 0.9774 - precision_6: 0.8861 - true_positives_6: 70.0000 - true_negatives_6: 65.0000 - false_positives_6: 9.0000 - false_negatives_6: 4.0000 - 281ms/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.1905 - binary_accuracy: 0.9257 - auc_6: 0.9827 - precision_6: 0.9315 - true_positives_6: 68.0000 - true_negatives_6: 69.0000 - false_positives_6: 5.0000 - false_negatives_6: 6.0000 - 266ms/epoch - 53ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.2367 - binary_accuracy: 0.9189 - auc_6: 0.9671 - precision_6: 0.9079 - true_positives_6: 69.0000 - true_negatives_6: 67.0000 - false_positives_6: 7.0000 - false_negatives_6: 5.0000 - 289ms/epoch - 58ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.1945 - binary_accuracy: 0.9324 - auc_6: 0.9846 - precision_6: 0.9103 - true_positives_6: 71.0000 - true_negatives_6: 67.0000 - false_positives_6: 7.0000 - false_negatives_6: 3.0000 - 329ms/epoch - 66ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.1608 - binary_accuracy: 0.9595 - auc_6: 0.9869 - precision_6: 1.0000 - true_positives_6: 68.0000 - true_negatives_6: 74.0000 - false_positives_6: 0.0000e+00 - false_negatives_6: 6.0000 - 336ms/epoch - 67ms/step\n",
      "2/2 [==============================] - 3s 32ms/step\n",
      "5/5 [==============================] - 2s 21ms/step\n",
      "Epoch 1/10\n",
      "5/5 - 22s - loss: 0.6835 - binary_accuracy: 0.5443 - auc_7: 0.6646 - precision_7: 0.5315 - true_positives_7: 59.0000 - true_negatives_7: 27.0000 - false_positives_7: 52.0000 - false_negatives_7: 20.0000 - 22s/epoch - 4s/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.6283 - binary_accuracy: 0.7595 - auc_7: 0.8328 - precision_7: 0.7470 - true_positives_7: 62.0000 - true_negatives_7: 58.0000 - false_positives_7: 21.0000 - false_negatives_7: 17.0000 - 340ms/epoch - 68ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.5169 - binary_accuracy: 0.7975 - auc_7: 0.8751 - precision_7: 0.7765 - true_positives_7: 66.0000 - true_negatives_7: 60.0000 - false_positives_7: 19.0000 - false_negatives_7: 13.0000 - 312ms/epoch - 62ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.5768 - binary_accuracy: 0.7152 - auc_7: 0.8042 - precision_7: 0.6932 - true_positives_7: 61.0000 - true_negatives_7: 52.0000 - false_positives_7: 27.0000 - false_negatives_7: 18.0000 - 295ms/epoch - 59ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.4898 - binary_accuracy: 0.7532 - auc_7: 0.8965 - precision_7: 0.9348 - true_positives_7: 43.0000 - true_negatives_7: 76.0000 - false_positives_7: 3.0000 - false_negatives_7: 36.0000 - 298ms/epoch - 60ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.4543 - binary_accuracy: 0.7911 - auc_7: 0.8805 - precision_7: 0.7805 - true_positives_7: 64.0000 - true_negatives_7: 61.0000 - false_positives_7: 18.0000 - false_negatives_7: 15.0000 - 355ms/epoch - 71ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.4331 - binary_accuracy: 0.8038 - auc_7: 0.8902 - precision_7: 0.7927 - true_positives_7: 65.0000 - true_negatives_7: 62.0000 - false_positives_7: 17.0000 - false_negatives_7: 14.0000 - 335ms/epoch - 67ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.4274 - binary_accuracy: 0.8101 - auc_7: 0.9022 - precision_7: 0.8769 - true_positives_7: 57.0000 - true_negatives_7: 71.0000 - false_positives_7: 8.0000 - false_negatives_7: 22.0000 - 341ms/epoch - 68ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.3928 - binary_accuracy: 0.8165 - auc_7: 0.9122 - precision_7: 0.8289 - true_positives_7: 63.0000 - true_negatives_7: 66.0000 - false_positives_7: 13.0000 - false_negatives_7: 16.0000 - 316ms/epoch - 63ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.3855 - binary_accuracy: 0.8291 - auc_7: 0.9128 - precision_7: 0.8095 - true_positives_7: 68.0000 - true_negatives_7: 63.0000 - false_positives_7: 16.0000 - false_negatives_7: 11.0000 - 292ms/epoch - 58ms/step\n",
      "2/2 [==============================] - 2s 30ms/step\n",
      "5/5 [==============================] - 0s 20ms/step\n",
      "Epoch 1/10\n",
      "5/5 - 12s - loss: 0.6845 - binary_accuracy: 0.6013 - auc_8: 0.6501 - precision_8: 0.7353 - true_positives_8: 25.0000 - true_negatives_8: 70.0000 - false_positives_8: 9.0000 - false_negatives_8: 54.0000 - 12s/epoch - 2s/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.6061 - binary_accuracy: 0.7975 - auc_8: 0.8349 - precision_8: 0.8310 - true_positives_8: 59.0000 - true_negatives_8: 67.0000 - false_positives_8: 12.0000 - false_negatives_8: 20.0000 - 278ms/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.4945 - binary_accuracy: 0.8165 - auc_8: 0.8968 - precision_8: 0.8049 - true_positives_8: 66.0000 - true_negatives_8: 63.0000 - false_positives_8: 16.0000 - false_negatives_8: 13.0000 - 311ms/epoch - 62ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.5789 - binary_accuracy: 0.7722 - auc_8: 0.8361 - precision_8: 0.8909 - true_positives_8: 49.0000 - true_negatives_8: 73.0000 - false_positives_8: 6.0000 - false_negatives_8: 30.0000 - 310ms/epoch - 62ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.5185 - binary_accuracy: 0.7342 - auc_8: 0.8518 - precision_8: 0.7079 - true_positives_8: 63.0000 - true_negatives_8: 53.0000 - false_positives_8: 26.0000 - false_negatives_8: 16.0000 - 306ms/epoch - 61ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.5640 - binary_accuracy: 0.6962 - auc_8: 0.8847 - precision_8: 0.6325 - true_positives_8: 74.0000 - true_negatives_8: 36.0000 - false_positives_8: 43.0000 - false_negatives_8: 5.0000 - 311ms/epoch - 62ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.4743 - binary_accuracy: 0.8165 - auc_8: 0.8742 - precision_8: 0.8049 - true_positives_8: 66.0000 - true_negatives_8: 63.0000 - false_positives_8: 16.0000 - false_negatives_8: 13.0000 - 324ms/epoch - 65ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.4601 - binary_accuracy: 0.8291 - auc_8: 0.8977 - precision_8: 0.9643 - true_positives_8: 54.0000 - true_negatives_8: 77.0000 - false_positives_8: 2.0000 - false_negatives_8: 25.0000 - 373ms/epoch - 75ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.3939 - binary_accuracy: 0.8418 - auc_8: 0.9170 - precision_8: 0.9091 - true_positives_8: 60.0000 - true_negatives_8: 73.0000 - false_positives_8: 6.0000 - false_negatives_8: 19.0000 - 234ms/epoch - 47ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.3602 - binary_accuracy: 0.8734 - auc_8: 0.9319 - precision_8: 0.8391 - true_positives_8: 73.0000 - true_negatives_8: 65.0000 - false_positives_8: 14.0000 - false_negatives_8: 6.0000 - 235ms/epoch - 47ms/step\n",
      "2/2 [==============================] - 2s 20ms/step\n",
      "5/5 [==============================] - 0s 21ms/step\n",
      "Epoch 1/10\n",
      "5/5 - 19s - loss: 0.6924 - binary_accuracy: 0.4557 - auc_9: 0.5427 - precision_9: 0.4752 - true_positives_9: 67.0000 - true_negatives_9: 5.0000 - false_positives_9: 74.0000 - false_negatives_9: 12.0000 - 19s/epoch - 4s/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.6564 - binary_accuracy: 0.7278 - auc_9: 0.8644 - precision_9: 0.6667 - true_positives_9: 72.0000 - true_negatives_9: 43.0000 - false_positives_9: 36.0000 - false_negatives_9: 7.0000 - 154ms/epoch - 31ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.5618 - binary_accuracy: 0.7595 - auc_9: 0.8901 - precision_9: 0.7113 - true_positives_9: 69.0000 - true_negatives_9: 51.0000 - false_positives_9: 28.0000 - false_negatives_9: 10.0000 - 293ms/epoch - 59ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.4757 - binary_accuracy: 0.8101 - auc_9: 0.8922 - precision_9: 0.7882 - true_positives_9: 67.0000 - true_negatives_9: 61.0000 - false_positives_9: 18.0000 - false_negatives_9: 12.0000 - 351ms/epoch - 70ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.5598 - binary_accuracy: 0.7089 - auc_9: 0.8576 - precision_9: 0.9459 - true_positives_9: 35.0000 - true_negatives_9: 77.0000 - false_positives_9: 2.0000 - false_negatives_9: 44.0000 - 360ms/epoch - 72ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.4623 - binary_accuracy: 0.7975 - auc_9: 0.8652 - precision_9: 0.8983 - true_positives_9: 53.0000 - true_negatives_9: 73.0000 - false_positives_9: 6.0000 - false_negatives_9: 26.0000 - 345ms/epoch - 69ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.4364 - binary_accuracy: 0.7975 - auc_9: 0.9168 - precision_9: 0.7640 - true_positives_9: 68.0000 - true_negatives_9: 58.0000 - false_positives_9: 21.0000 - false_negatives_9: 11.0000 - 378ms/epoch - 76ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.4114 - binary_accuracy: 0.8165 - auc_9: 0.9073 - precision_9: 0.8049 - true_positives_9: 66.0000 - true_negatives_9: 63.0000 - false_positives_9: 16.0000 - false_negatives_9: 13.0000 - 363ms/epoch - 73ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.3705 - binary_accuracy: 0.8544 - auc_9: 0.9183 - precision_9: 0.8889 - true_positives_9: 64.0000 - true_negatives_9: 71.0000 - false_positives_9: 8.0000 - false_negatives_9: 15.0000 - 353ms/epoch - 71ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.5305 - binary_accuracy: 0.8101 - auc_9: 0.9237 - precision_9: 0.7426 - true_positives_9: 75.0000 - true_negatives_9: 53.0000 - false_positives_9: 26.0000 - false_negatives_9: 4.0000 - 351ms/epoch - 70ms/step\n",
      "2/2 [==============================] - 3s 30ms/step\n",
      "5/5 [==============================] - 0s 19ms/step\n",
      "Epoch 1/10\n",
      "5/5 - 12s - loss: 0.6863 - binary_accuracy: 0.6038 - auc_10: 0.6842 - precision_10: 0.5870 - true_positives_10: 54.0000 - true_negatives_10: 42.0000 - false_positives_10: 38.0000 - false_negatives_10: 25.0000 - 12s/epoch - 2s/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.6407 - binary_accuracy: 0.7925 - auc_10: 0.8573 - precision_10: 0.7674 - true_positives_10: 66.0000 - true_negatives_10: 60.0000 - false_positives_10: 20.0000 - false_negatives_10: 13.0000 - 326ms/epoch - 65ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.5140 - binary_accuracy: 0.8302 - auc_10: 0.9066 - precision_10: 0.8171 - true_positives_10: 67.0000 - true_negatives_10: 65.0000 - false_positives_10: 15.0000 - false_negatives_10: 12.0000 - 331ms/epoch - 66ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.3913 - binary_accuracy: 0.8176 - auc_10: 0.9196 - precision_10: 0.8125 - true_positives_10: 65.0000 - true_negatives_10: 65.0000 - false_positives_10: 15.0000 - false_negatives_10: 14.0000 - 336ms/epoch - 67ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.3782 - binary_accuracy: 0.8302 - auc_10: 0.9206 - precision_10: 0.8514 - true_positives_10: 63.0000 - true_negatives_10: 69.0000 - false_positives_10: 11.0000 - false_negatives_10: 16.0000 - 357ms/epoch - 71ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.3633 - binary_accuracy: 0.8428 - auc_10: 0.9253 - precision_10: 0.8375 - true_positives_10: 67.0000 - true_negatives_10: 67.0000 - false_positives_10: 13.0000 - false_negatives_10: 12.0000 - 343ms/epoch - 69ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.3084 - binary_accuracy: 0.8868 - auc_10: 0.9491 - precision_10: 0.9296 - true_positives_10: 66.0000 - true_negatives_10: 75.0000 - false_positives_10: 5.0000 - false_negatives_10: 13.0000 - 354ms/epoch - 71ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.2988 - binary_accuracy: 0.8742 - auc_10: 0.9480 - precision_10: 0.8831 - true_positives_10: 68.0000 - true_negatives_10: 71.0000 - false_positives_10: 9.0000 - false_negatives_10: 11.0000 - 352ms/epoch - 70ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.2487 - binary_accuracy: 0.9119 - auc_10: 0.9557 - precision_10: 0.9221 - true_positives_10: 71.0000 - true_negatives_10: 74.0000 - false_positives_10: 6.0000 - false_negatives_10: 8.0000 - 334ms/epoch - 67ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.2212 - binary_accuracy: 0.9245 - auc_10: 0.9614 - precision_10: 0.9589 - true_positives_10: 70.0000 - true_negatives_10: 77.0000 - false_positives_10: 3.0000 - false_negatives_10: 9.0000 - 336ms/epoch - 67ms/step\n",
      "2/2 [==============================] - 2s 24ms/step\n",
      "5/5 [==============================] - 0s 23ms/step\n",
      "Epoch 1/10\n",
      "5/5 - 17s - loss: 0.6896 - binary_accuracy: 0.5031 - auc_11: 0.5845 - precision_11: 0.6667 - true_positives_11: 2.0000 - true_negatives_11: 78.0000 - false_positives_11: 1.0000 - false_negatives_11: 78.0000 - 17s/epoch - 3s/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.6539 - binary_accuracy: 0.6918 - auc_11: 0.7851 - precision_11: 0.6867 - true_positives_11: 57.0000 - true_negatives_11: 53.0000 - false_positives_11: 26.0000 - false_negatives_11: 23.0000 - 352ms/epoch - 70ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.5643 - binary_accuracy: 0.7799 - auc_11: 0.8694 - precision_11: 0.8261 - true_positives_11: 57.0000 - true_negatives_11: 67.0000 - false_positives_11: 12.0000 - false_negatives_11: 23.0000 - 338ms/epoch - 68ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.4791 - binary_accuracy: 0.7987 - auc_11: 0.9047 - precision_11: 0.7449 - true_positives_11: 73.0000 - true_negatives_11: 54.0000 - false_positives_11: 25.0000 - false_negatives_11: 7.0000 - 413ms/epoch - 83ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.4098 - binary_accuracy: 0.8239 - auc_11: 0.9320 - precision_11: 0.8824 - true_positives_11: 60.0000 - true_negatives_11: 71.0000 - false_positives_11: 8.0000 - false_negatives_11: 20.0000 - 349ms/epoch - 70ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.3930 - binary_accuracy: 0.8365 - auc_11: 0.9189 - precision_11: 0.8214 - true_positives_11: 69.0000 - true_negatives_11: 64.0000 - false_positives_11: 15.0000 - false_negatives_11: 11.0000 - 333ms/epoch - 67ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.3725 - binary_accuracy: 0.8365 - auc_11: 0.9260 - precision_11: 0.8553 - true_positives_11: 65.0000 - true_negatives_11: 68.0000 - false_positives_11: 11.0000 - false_negatives_11: 15.0000 - 271ms/epoch - 54ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.3742 - binary_accuracy: 0.8553 - auc_11: 0.9396 - precision_11: 0.9130 - true_positives_11: 63.0000 - true_negatives_11: 73.0000 - false_positives_11: 6.0000 - false_negatives_11: 17.0000 - 328ms/epoch - 66ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.3737 - binary_accuracy: 0.8365 - auc_11: 0.9464 - precision_11: 0.7812 - true_positives_11: 75.0000 - true_negatives_11: 58.0000 - false_positives_11: 21.0000 - false_negatives_11: 5.0000 - 351ms/epoch - 70ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.3498 - binary_accuracy: 0.8553 - auc_11: 0.9370 - precision_11: 0.9254 - true_positives_11: 62.0000 - true_negatives_11: 74.0000 - false_positives_11: 5.0000 - false_negatives_11: 18.0000 - 358ms/epoch - 72ms/step\n",
      "2/2 [==============================] - 3s 42ms/step\n",
      "5/5 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Classifier_Name': 'RNN',\n",
       "  'Optimitied_Param': {},\n",
       "  'Score': 'out/libfeatureselection/T1/T1SEstacker-RTX//RNN_score.pkl',\n",
       "  'Model_Path': '-',\n",
       "  'TimeToStartFit': '2023-07-22 13:47:21',\n",
       "  'TimeOfSummary': '2023-07-22 13:49:58',\n",
       "  'TimeSpend': '0:02:37.164119'},\n",
       " {'accuracy': 0.62,\n",
       "  'precision': 0.6666666666666666,\n",
       "  'f1_score': 0.5581395348837209,\n",
       "  'mmc': 0.25,\n",
       "  'rocAUC': 0.6144,\n",
       "  'specificity': 0.76,\n",
       "  'sensitivity': 0.48,\n",
       "  'pro_cutoff': 0.10723479},\n",
       " {'accuracy': 0.857948717948718,\n",
       "  'precision': 0.9579260651629072,\n",
       "  'f1_score': 0.8333145716072545,\n",
       "  'mmc': 0.7418831510145412,\n",
       "  'rocAUC': 0.8758947368421055,\n",
       "  'specificity': 0.96,\n",
       "  'sensitivity': 0.7557894736842105,\n",
       "  'pro_cutoff': [0.4490599, 0.7960867, 0.9003739, 0.9451657, 0.8054305]})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RNN_Trainer().find_best(\n",
    "    X=pd.concat([digitaa_data['t_p'], digitaa_data['t_n']]),\n",
    "    y=np.concatenate([np.ones((digitaa_data['t_p'].shape[0], )), np.zeros((digitaa_data['t_n'].shape[0], ))]),\n",
    "    validation=(\n",
    "        pd.concat([digitaa_data['v_p'], digitaa_data['v_n']]),\n",
    "        np.concatenate([np.ones((digitaa_data['v_p'].shape[0], )), np.zeros((digitaa_data['v_n'].shape[0], ))]),\n",
    "    )\n",
    ").get_summary(\n",
    "    path_to_dir=\"out/libfeatureselection/T1/T1SEstacker-RTX/\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SA_model(seq_length: int, sizeof_ac_dict: int):\n",
    "    input1 = tf.keras.layers.Input(shape=(seq_length,), name='Input_Layer')\n",
    "    embedding1 = tf.keras.layers.Embedding(\n",
    "        input_dim=sizeof_ac_dict, output_dim=sizeof_ac_dict, name=\"AC_EMBEDED\")(input1)\n",
    "    flatten_layer = tf.keras.layers.Flatten()(embedding1)\n",
    "    Q = tf.keras.layers.Dense(\n",
    "        20, activation=tf.keras.activations.sigmoid)(flatten_layer)\n",
    "    K = tf.keras.layers.Dense(\n",
    "        20, activation=tf.keras.activations.sigmoid)(flatten_layer)\n",
    "    V = tf.keras.layers.Dense(\n",
    "        20, activation=tf.keras.activations.sigmoid)(flatten_layer)\n",
    "\n",
    "    Attention = tf.keras.layers.Multiply()([Q, K])\n",
    "    softmax_Attention = tf.keras.activations.softmax(Attention)\n",
    "    Self_Attention = tf.keras.layers.Multiply()([V, softmax_Attention])\n",
    "\n",
    "    d = tf.keras.layers.Dense(\n",
    "        1, activation=tf.keras.activations.sigmoid)(Self_Attention)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=input1, outputs=d, name='SelfAttantion')\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "        loss=tf.keras.losses.binary_crossentropy,\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(),\n",
    "            tf.keras.metrics.AUC(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.TruePositives(),\n",
    "            tf.keras.metrics.TrueNegatives(),\n",
    "            tf.keras.metrics.FalsePositives(),\n",
    "            tf.keras.metrics.FalseNegatives()\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "class SA_Trainer:\n",
    "    def __init__(self, ) -> None:\n",
    "        self.classifier_name = \"SA\"\n",
    "        self.classifier_class = get_SA_model\n",
    "        self.classifier_param_dict = {\n",
    "            \"seq_length\": 60,\n",
    "            \"sizeof_ac_dict\": 20\n",
    "        }\n",
    "\n",
    "        self.model = None\n",
    "        self.train_best_predicted_pair = None\n",
    "        self.train_best_5C_predicted_pair = None\n",
    "        self.best_predicted_pair = None\n",
    "        self.best_5C_predicted_pair = None\n",
    "        self.start_to_train_time = datetime.now()\n",
    "        self.end_of_train_time = None\n",
    "        pass\n",
    "\n",
    "    def find_best(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        validation: tuple,\n",
    "    ):\n",
    "\n",
    "        self.model = self.classifier_class(\n",
    "            **self.classifier_param_dict\n",
    "        )\n",
    "        self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            epochs=10,\n",
    "            use_multiprocessing=True,\n",
    "            steps_per_epoch=None,\n",
    "            verbose=2\n",
    "        )\n",
    "        self.best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                validation[0]\n",
    "            ), nan=0.0),\n",
    "            validation[1]\n",
    "        ]\n",
    "        self.train_best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                X\n",
    "            ), nan=0.0),\n",
    "            y\n",
    "        ]\n",
    "\n",
    "        # 5倍交叉验证\n",
    "        # 合并数据\n",
    "        full_X = np.concatenate([\n",
    "            X, validation[0]\n",
    "        ])\n",
    "        full_y = np.concatenate([\n",
    "            y, validation[1]\n",
    "        ])\n",
    "\n",
    "        # 跑模型\n",
    "        self.best_5C_predicted_pair = []\n",
    "        self.train_best_5C_predicted_pair = []\n",
    "        for Kfold_id, (train_id, test_id) in enumerate(\n",
    "            StratifiedKFold(\n",
    "                n_splits=5,\n",
    "                shuffle=True,\n",
    "                random_state=42\n",
    "            ).split(full_X, full_y)\n",
    "        ):\n",
    "\n",
    "            # 定义模型并加载参数\n",
    "            fiveC_model = self.classifier_class(\n",
    "                **self.classifier_param_dict,\n",
    "            )\n",
    "\n",
    "            fiveC_model.fit(\n",
    "                full_X[train_id],\n",
    "                full_y[train_id],\n",
    "                epochs=10,\n",
    "                use_multiprocessing=True,\n",
    "                steps_per_epoch=None,\n",
    "                verbose=2\n",
    "            )\n",
    "\n",
    "            # 预测并记录\n",
    "            self.best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    full_X[test_id]\n",
    "                ), nan=0.0),\n",
    "                full_y[test_id]\n",
    "            ])\n",
    "            self.train_best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    full_X[train_id]\n",
    "                ), nan=0.0),\n",
    "                full_y[train_id]\n",
    "            ])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_summary(self, path_to_dir: str = None):\n",
    "        os.makedirs(path_to_dir, exist_ok=True)\n",
    "        model_path = \"-\"\n",
    "        if \"SAVE_MODEL\" in os.environ and os.environ['SAVE_MODEL'] == \"1\":\n",
    "\n",
    "            model_path = f\"{path_to_dir}/{self.classifier_name}.pkl\"\n",
    "            if path_to_dir is not None:\n",
    "                with gzip.open(model_path, \"wb\") as f:\n",
    "                    pickle.dump(\n",
    "                        self.grid_search, f\n",
    "                    )\n",
    "\n",
    "        model_score_path = f\"{path_to_dir}/{self.classifier_name}_score.pkl\"\n",
    "        if path_to_dir is not None:\n",
    "            with gzip.open(model_score_path, \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "            with gzip.open(model_score_path + \".train\", \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.train_best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.train_best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "        else:\n",
    "            model_score_path = \"-\"\n",
    "\n",
    "        plot_roc_curve(\n",
    "            target=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "            path_to_=f\"{path_to_dir}/{self.classifier_name}.pdf\"\n",
    "        )\n",
    "\n",
    "        model_information = {\n",
    "            \"Classifier_Name\": self.classifier_name,\n",
    "            \"Optimitied_Param\": dict(),\n",
    "            \"Score\": model_score_path,\n",
    "            \"Model_Path\": model_path,\n",
    "            \"TimeToStartFit\": self.start_to_train_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "\n",
    "        training_testing_performance = get_evaluation(\n",
    "            label=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "        )\n",
    "\n",
    "        # 计算5C中的平均表现\n",
    "        FiveFold_result = {}\n",
    "        for keys in training_testing_performance.keys():\n",
    "            value_list = []\n",
    "            for item in self.best_5C_predicted_pair:\n",
    "\n",
    "                item_performance = get_evaluation(\n",
    "                    label=item[1],\n",
    "                    pred=item[0],\n",
    "                )\n",
    "                value_list.append(item_performance[keys])\n",
    "\n",
    "            if keys == \"pro_cutoff\":\n",
    "                FiveFold_result[keys] = value_list\n",
    "            else:\n",
    "                FiveFold_result[keys] = sum(value_list) / len(value_list)\n",
    "\n",
    "        self.end_of_train_time = datetime.now()\n",
    "        model_information[\"TimeOfSummary\"] = self.end_of_train_time.strftime(\n",
    "            \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "        model_information[\"TimeSpend\"] = str(\n",
    "            self.end_of_train_time - self.start_to_train_time\n",
    "        )\n",
    "\n",
    "        return model_information, training_testing_performance, FiveFold_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 - 8s - loss: 0.6929 - binary_accuracy: 0.5000 - auc_12: 0.5330 - precision_12: 0.5000 - true_positives_12: 74.0000 - true_negatives_12: 0.0000e+00 - false_positives_12: 74.0000 - false_negatives_12: 0.0000e+00 - 8s/epoch - 2s/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.6804 - binary_accuracy: 0.6689 - auc_12: 0.9825 - precision_12: 0.6016 - true_positives_12: 74.0000 - true_negatives_12: 25.0000 - false_positives_12: 49.0000 - false_negatives_12: 0.0000e+00 - 65ms/epoch - 13ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.6524 - binary_accuracy: 0.9797 - auc_12: 0.9990 - precision_12: 0.9610 - true_positives_12: 74.0000 - true_negatives_12: 71.0000 - false_positives_12: 3.0000 - false_negatives_12: 0.0000e+00 - 76ms/epoch - 15ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.6138 - binary_accuracy: 0.9730 - auc_12: 0.9961 - precision_12: 1.0000 - true_positives_12: 70.0000 - true_negatives_12: 74.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 4.0000 - 69ms/epoch - 14ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.5786 - binary_accuracy: 0.9797 - auc_12: 0.9995 - precision_12: 1.0000 - true_positives_12: 71.0000 - true_negatives_12: 74.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 3.0000 - 67ms/epoch - 13ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.5536 - binary_accuracy: 0.9865 - auc_12: 1.0000 - precision_12: 1.0000 - true_positives_12: 72.0000 - true_negatives_12: 74.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 2.0000 - 66ms/epoch - 13ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.5294 - binary_accuracy: 1.0000 - auc_12: 1.0000 - precision_12: 1.0000 - true_positives_12: 74.0000 - true_negatives_12: 74.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 0.0000e+00 - 64ms/epoch - 13ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.5101 - binary_accuracy: 1.0000 - auc_12: 1.0000 - precision_12: 1.0000 - true_positives_12: 74.0000 - true_negatives_12: 74.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 0.0000e+00 - 73ms/epoch - 15ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.4927 - binary_accuracy: 1.0000 - auc_12: 1.0000 - precision_12: 1.0000 - true_positives_12: 74.0000 - true_negatives_12: 74.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 0.0000e+00 - 59ms/epoch - 12ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.4764 - binary_accuracy: 1.0000 - auc_12: 1.0000 - precision_12: 1.0000 - true_positives_12: 74.0000 - true_negatives_12: 74.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 0.0000e+00 - 61ms/epoch - 12ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "5/5 [==============================] - 0s 10ms/step\n",
      "Epoch 1/10\n",
      "5/5 - 4s - loss: 0.6933 - binary_accuracy: 0.5000 - auc_13: 0.5202 - precision_13: 0.5000 - true_positives_13: 79.0000 - true_negatives_13: 0.0000e+00 - false_positives_13: 79.0000 - false_negatives_13: 0.0000e+00 - 4s/epoch - 879ms/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.6827 - binary_accuracy: 0.5316 - auc_13: 0.9753 - precision_13: 0.5163 - true_positives_13: 79.0000 - true_negatives_13: 5.0000 - false_positives_13: 74.0000 - false_negatives_13: 0.0000e+00 - 47ms/epoch - 9ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.6601 - binary_accuracy: 0.9114 - auc_13: 0.9832 - precision_13: 0.8571 - true_positives_13: 78.0000 - true_negatives_13: 66.0000 - false_positives_13: 13.0000 - false_negatives_13: 1.0000 - 49ms/epoch - 10ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.6233 - binary_accuracy: 0.9747 - auc_13: 0.9938 - precision_13: 0.9747 - true_positives_13: 77.0000 - true_negatives_13: 77.0000 - false_positives_13: 2.0000 - false_negatives_13: 2.0000 - 50ms/epoch - 10ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.5872 - binary_accuracy: 0.9747 - auc_13: 0.9901 - precision_13: 0.9747 - true_positives_13: 77.0000 - true_negatives_13: 77.0000 - false_positives_13: 2.0000 - false_negatives_13: 2.0000 - 58ms/epoch - 12ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.5572 - binary_accuracy: 0.9810 - auc_13: 0.9970 - precision_13: 0.9872 - true_positives_13: 77.0000 - true_negatives_13: 78.0000 - false_positives_13: 1.0000 - false_negatives_13: 2.0000 - 62ms/epoch - 12ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.5317 - binary_accuracy: 0.9937 - auc_13: 0.9955 - precision_13: 1.0000 - true_positives_13: 78.0000 - true_negatives_13: 79.0000 - false_positives_13: 0.0000e+00 - false_negatives_13: 1.0000 - 77ms/epoch - 15ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.5104 - binary_accuracy: 0.9937 - auc_13: 0.9920 - precision_13: 1.0000 - true_positives_13: 78.0000 - true_negatives_13: 79.0000 - false_positives_13: 0.0000e+00 - false_negatives_13: 1.0000 - 60ms/epoch - 12ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.4922 - binary_accuracy: 0.9937 - auc_13: 0.9974 - precision_13: 1.0000 - true_positives_13: 78.0000 - true_negatives_13: 79.0000 - false_positives_13: 0.0000e+00 - false_negatives_13: 1.0000 - 64ms/epoch - 13ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.4758 - binary_accuracy: 0.9937 - auc_13: 0.9982 - precision_13: 1.0000 - true_positives_13: 78.0000 - true_negatives_13: 79.0000 - false_positives_13: 0.0000e+00 - false_negatives_13: 1.0000 - 62ms/epoch - 12ms/step\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "5/5 [==============================] - 0s 11ms/step\n",
      "Epoch 1/10\n",
      "5/5 - 9s - loss: 0.6923 - binary_accuracy: 0.5063 - auc_14: 0.5757 - precision_14: 0.5041 - true_positives_14: 61.0000 - true_negatives_14: 19.0000 - false_positives_14: 60.0000 - false_negatives_14: 18.0000 - 9s/epoch - 2s/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.6805 - binary_accuracy: 0.6329 - auc_14: 0.9506 - precision_14: 0.5766 - true_positives_14: 79.0000 - true_negatives_14: 21.0000 - false_positives_14: 58.0000 - false_negatives_14: 0.0000e+00 - 62ms/epoch - 12ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.6501 - binary_accuracy: 0.8797 - auc_14: 0.9954 - precision_14: 0.8061 - true_positives_14: 79.0000 - true_negatives_14: 60.0000 - false_positives_14: 19.0000 - false_negatives_14: 0.0000e+00 - 64ms/epoch - 13ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.6066 - binary_accuracy: 0.9747 - auc_14: 0.9961 - precision_14: 0.9747 - true_positives_14: 77.0000 - true_negatives_14: 77.0000 - false_positives_14: 2.0000 - false_negatives_14: 2.0000 - 62ms/epoch - 12ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.5691 - binary_accuracy: 0.9684 - auc_14: 0.9968 - precision_14: 0.9868 - true_positives_14: 75.0000 - true_negatives_14: 78.0000 - false_positives_14: 1.0000 - false_negatives_14: 4.0000 - 78ms/epoch - 16ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.5369 - binary_accuracy: 0.9873 - auc_14: 0.9996 - precision_14: 0.9873 - true_positives_14: 78.0000 - true_negatives_14: 78.0000 - false_positives_14: 1.0000 - false_negatives_14: 1.0000 - 66ms/epoch - 13ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.5118 - binary_accuracy: 0.9937 - auc_14: 1.0000 - precision_14: 0.9875 - true_positives_14: 79.0000 - true_negatives_14: 78.0000 - false_positives_14: 1.0000 - false_negatives_14: 0.0000e+00 - 61ms/epoch - 12ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.4911 - binary_accuracy: 1.0000 - auc_14: 1.0000 - precision_14: 1.0000 - true_positives_14: 79.0000 - true_negatives_14: 79.0000 - false_positives_14: 0.0000e+00 - false_negatives_14: 0.0000e+00 - 63ms/epoch - 13ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.4723 - binary_accuracy: 1.0000 - auc_14: 1.0000 - precision_14: 1.0000 - true_positives_14: 79.0000 - true_negatives_14: 79.0000 - false_positives_14: 0.0000e+00 - false_negatives_14: 0.0000e+00 - 61ms/epoch - 12ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.4560 - binary_accuracy: 1.0000 - auc_14: 1.0000 - precision_14: 1.0000 - true_positives_14: 79.0000 - true_negatives_14: 79.0000 - false_positives_14: 0.0000e+00 - false_negatives_14: 0.0000e+00 - 61ms/epoch - 12ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "5/5 [==============================] - 0s 13ms/step\n",
      "Epoch 1/10\n",
      "5/5 - 5s - loss: 0.6928 - binary_accuracy: 0.5000 - auc_15: 0.5757 - precision_15: 0.5000 - true_positives_15: 79.0000 - true_negatives_15: 0.0000e+00 - false_positives_15: 79.0000 - false_negatives_15: 0.0000e+00 - 5s/epoch - 917ms/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.6817 - binary_accuracy: 0.7532 - auc_15: 0.9623 - precision_15: 0.6695 - true_positives_15: 79.0000 - true_negatives_15: 40.0000 - false_positives_15: 39.0000 - false_negatives_15: 0.0000e+00 - 57ms/epoch - 11ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.6563 - binary_accuracy: 0.9367 - auc_15: 0.9917 - precision_15: 0.9059 - true_positives_15: 77.0000 - true_negatives_15: 71.0000 - false_positives_15: 8.0000 - false_negatives_15: 2.0000 - 74ms/epoch - 15ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.6206 - binary_accuracy: 0.9684 - auc_15: 0.9946 - precision_15: 0.9744 - true_positives_15: 76.0000 - true_negatives_15: 77.0000 - false_positives_15: 2.0000 - false_negatives_15: 3.0000 - 64ms/epoch - 13ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.5882 - binary_accuracy: 0.9684 - auc_15: 0.9975 - precision_15: 0.9868 - true_positives_15: 75.0000 - true_negatives_15: 78.0000 - false_positives_15: 1.0000 - false_negatives_15: 4.0000 - 59ms/epoch - 12ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.5611 - binary_accuracy: 0.9873 - auc_15: 0.9997 - precision_15: 1.0000 - true_positives_15: 77.0000 - true_negatives_15: 79.0000 - false_positives_15: 0.0000e+00 - false_negatives_15: 2.0000 - 58ms/epoch - 12ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.5359 - binary_accuracy: 1.0000 - auc_15: 1.0000 - precision_15: 1.0000 - true_positives_15: 79.0000 - true_negatives_15: 79.0000 - false_positives_15: 0.0000e+00 - false_negatives_15: 0.0000e+00 - 48ms/epoch - 10ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.5139 - binary_accuracy: 1.0000 - auc_15: 1.0000 - precision_15: 1.0000 - true_positives_15: 79.0000 - true_negatives_15: 79.0000 - false_positives_15: 0.0000e+00 - false_negatives_15: 0.0000e+00 - 43ms/epoch - 9ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.4945 - binary_accuracy: 1.0000 - auc_15: 1.0000 - precision_15: 1.0000 - true_positives_15: 79.0000 - true_negatives_15: 79.0000 - false_positives_15: 0.0000e+00 - false_negatives_15: 0.0000e+00 - 47ms/epoch - 9ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.4774 - binary_accuracy: 1.0000 - auc_15: 1.0000 - precision_15: 1.0000 - true_positives_15: 79.0000 - true_negatives_15: 79.0000 - false_positives_15: 0.0000e+00 - false_negatives_15: 0.0000e+00 - 49ms/epoch - 10ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n",
      "5/5 [==============================] - 0s 11ms/step\n",
      "Epoch 1/10\n",
      "5/5 - 15s - loss: 0.6933 - binary_accuracy: 0.4969 - auc_16: 0.5183 - precision_16: 0.4969 - true_positives_16: 79.0000 - true_negatives_16: 0.0000e+00 - false_positives_16: 80.0000 - false_negatives_16: 0.0000e+00 - 15s/epoch - 3s/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.6820 - binary_accuracy: 0.6352 - auc_16: 0.9260 - precision_16: 0.5766 - true_positives_16: 79.0000 - true_negatives_16: 22.0000 - false_positives_16: 58.0000 - false_negatives_16: 0.0000e+00 - 71ms/epoch - 14ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.6543 - binary_accuracy: 0.9560 - auc_16: 0.9918 - precision_16: 0.9615 - true_positives_16: 75.0000 - true_negatives_16: 77.0000 - false_positives_16: 3.0000 - false_negatives_16: 4.0000 - 64ms/epoch - 13ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.6155 - binary_accuracy: 0.9497 - auc_16: 0.9869 - precision_16: 0.9733 - true_positives_16: 73.0000 - true_negatives_16: 78.0000 - false_positives_16: 2.0000 - false_negatives_16: 6.0000 - 70ms/epoch - 14ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.5820 - binary_accuracy: 0.9434 - auc_16: 0.9905 - precision_16: 0.9487 - true_positives_16: 74.0000 - true_negatives_16: 76.0000 - false_positives_16: 4.0000 - false_negatives_16: 5.0000 - 62ms/epoch - 12ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.5547 - binary_accuracy: 0.9686 - auc_16: 0.9960 - precision_16: 0.9868 - true_positives_16: 75.0000 - true_negatives_16: 79.0000 - false_positives_16: 1.0000 - false_negatives_16: 4.0000 - 63ms/epoch - 13ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.5315 - binary_accuracy: 0.9748 - auc_16: 0.9990 - precision_16: 0.9870 - true_positives_16: 76.0000 - true_negatives_16: 79.0000 - false_positives_16: 1.0000 - false_negatives_16: 3.0000 - 77ms/epoch - 15ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.5101 - binary_accuracy: 0.9937 - auc_16: 0.9998 - precision_16: 1.0000 - true_positives_16: 78.0000 - true_negatives_16: 80.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 1.0000 - 67ms/epoch - 13ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.4904 - binary_accuracy: 0.9937 - auc_16: 1.0000 - precision_16: 1.0000 - true_positives_16: 78.0000 - true_negatives_16: 80.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 1.0000 - 67ms/epoch - 13ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.4726 - binary_accuracy: 1.0000 - auc_16: 1.0000 - precision_16: 1.0000 - true_positives_16: 79.0000 - true_negatives_16: 80.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 0.0000e+00 - 77ms/epoch - 15ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "5/5 [==============================] - 0s 11ms/step\n",
      "Epoch 1/10\n",
      "5/5 - 8s - loss: 0.6937 - binary_accuracy: 0.4654 - auc_17: 0.4499 - precision_17: 0.4691 - true_positives_17: 38.0000 - true_negatives_17: 36.0000 - false_positives_17: 43.0000 - false_negatives_17: 42.0000 - 8s/epoch - 2s/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.6803 - binary_accuracy: 0.8365 - auc_17: 0.9612 - precision_17: 0.7700 - true_positives_17: 77.0000 - true_negatives_17: 56.0000 - false_positives_17: 23.0000 - false_negatives_17: 3.0000 - 78ms/epoch - 16ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.6533 - binary_accuracy: 0.9245 - auc_17: 0.9833 - precision_17: 0.9146 - true_positives_17: 75.0000 - true_negatives_17: 72.0000 - false_positives_17: 7.0000 - false_negatives_17: 5.0000 - 57ms/epoch - 11ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.6174 - binary_accuracy: 0.9182 - auc_17: 0.9827 - precision_17: 0.9136 - true_positives_17: 74.0000 - true_negatives_17: 72.0000 - false_positives_17: 7.0000 - false_negatives_17: 6.0000 - 73ms/epoch - 15ms/step\n",
      "Epoch 5/10\n",
      "5/5 - 0s - loss: 0.5891 - binary_accuracy: 0.9119 - auc_17: 0.9856 - precision_17: 0.9231 - true_positives_17: 72.0000 - true_negatives_17: 73.0000 - false_positives_17: 6.0000 - false_negatives_17: 8.0000 - 64ms/epoch - 13ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.5615 - binary_accuracy: 0.9686 - auc_17: 0.9960 - precision_17: 0.9747 - true_positives_17: 77.0000 - true_negatives_17: 77.0000 - false_positives_17: 2.0000 - false_negatives_17: 3.0000 - 73ms/epoch - 15ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.5360 - binary_accuracy: 0.9874 - auc_17: 0.9998 - precision_17: 0.9875 - true_positives_17: 79.0000 - true_negatives_17: 78.0000 - false_positives_17: 1.0000 - false_negatives_17: 1.0000 - 64ms/epoch - 13ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.5148 - binary_accuracy: 1.0000 - auc_17: 1.0000 - precision_17: 1.0000 - true_positives_17: 80.0000 - true_negatives_17: 79.0000 - false_positives_17: 0.0000e+00 - false_negatives_17: 0.0000e+00 - 59ms/epoch - 12ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.4951 - binary_accuracy: 1.0000 - auc_17: 1.0000 - precision_17: 1.0000 - true_positives_17: 80.0000 - true_negatives_17: 79.0000 - false_positives_17: 0.0000e+00 - false_negatives_17: 0.0000e+00 - 59ms/epoch - 12ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.4775 - binary_accuracy: 1.0000 - auc_17: 1.0000 - precision_17: 1.0000 - true_positives_17: 80.0000 - true_negatives_17: 79.0000 - false_positives_17: 0.0000e+00 - false_negatives_17: 0.0000e+00 - 59ms/epoch - 12ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "5/5 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Classifier_Name': 'SA',\n",
       "  'Optimitied_Param': {},\n",
       "  'Score': 'out/libfeatureselection/T1/T1SEstacker-RTX//SA_score.pkl',\n",
       "  'Model_Path': '-',\n",
       "  'TimeToStartFit': '2023-07-22 13:50:05',\n",
       "  'TimeOfSummary': '2023-07-22 13:51:14',\n",
       "  'TimeSpend': '0:01:09.007109'},\n",
       " {'accuracy': 0.72,\n",
       "  'precision': 0.7619047619047619,\n",
       "  'f1_score': 0.6956521739130435,\n",
       "  'mmc': 0.4457424941602093,\n",
       "  'rocAUC': 0.776,\n",
       "  'specificity': 0.8,\n",
       "  'sensitivity': 0.64,\n",
       "  'pro_cutoff': 0.44693962},\n",
       " {'accuracy': 0.8938461538461538,\n",
       "  'precision': 0.9428571428571428,\n",
       "  'f1_score': 0.8885998890876939,\n",
       "  'mmc': 0.7994379249629955,\n",
       "  'rocAUC': 0.9428157894736842,\n",
       "  'specificity': 0.9400000000000001,\n",
       "  'sensitivity': 0.8494736842105264,\n",
       "  'pro_cutoff': [0.5304556, 0.59257233, 0.5537683, 0.62785786, 0.5536931]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SA_Trainer().find_best(\n",
    "    X=pd.concat([digitaa_data['t_p'], digitaa_data['t_n']]),\n",
    "    y=np.concatenate([np.ones((digitaa_data['t_p'].shape[0], )), np.zeros((digitaa_data['t_n'].shape[0], ))]),\n",
    "    validation=(\n",
    "        pd.concat([digitaa_data['v_p'], digitaa_data['v_n']]),\n",
    "        np.concatenate([np.ones((digitaa_data['v_p'].shape[0], )), np.zeros((digitaa_data['v_n'].shape[0], ))]),\n",
    "    )\n",
    ").get_summary(\n",
    "    path_to_dir=\"out/libfeatureselection/T1/T1SEstacker-RTX/\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_type = 1\n",
    "job_name = \"T1-RTX-rStacker\"\n",
    "path_to_score_dir = \"out/libfeatureselection/T1/T1SEstacker-RTX/model/\"\n",
    "path_to_dnnscore_dir = \"out/libfeatureselection/T1/T1SEstacker-RTX/\"\n",
    "path_to_model_score_path = \"out/libfeatureselection/T1/T1SEstacker-RTX/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from libfeatureselection import model_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allname_list = [\n",
    "    item['name']\n",
    "    for item in model_space.find_space\n",
    "]\n",
    "model_list_dict = { item['name']:item for item in model_space.find_space }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "def get_optimal_threshold(target: np.ndarray, predict: np.ndarray, multi_dim: int):\n",
    "    \n",
    "    if multi_dim is not None:\n",
    "        predict = predict[:, multi_dim]\n",
    "\n",
    "    predict = np.nan_to_num(\n",
    "        predict, copy=True, nan=0.0\n",
    "    )\n",
    "    fpr, tpr, thresholds = roc_curve(target, predict)\n",
    "    best_one_optimal_idx = np.argmax(tpr - fpr)\n",
    "    pro_cutoff = thresholds[best_one_optimal_idx]\n",
    "    predict_l = [1 if i >= pro_cutoff else 0 for i in predict]\n",
    "\n",
    "    return pro_cutoff\n",
    "\n",
    "def get_threshold_for_dict(_score_dict: dict, multi_dim: int = None):\n",
    "    # best_predicted_pair\n",
    "    _score_dict['best_predicted_pair_pro_cutoff'] = get_optimal_threshold(\n",
    "        target=_score_dict['best_predicted_pair'][1],\n",
    "        predict=_score_dict['best_predicted_pair'][0],\n",
    "        multi_dim=multi_dim\n",
    "    )\n",
    "    _score_dict['best_predicted_binary'] = (\n",
    "        _score_dict['best_predicted_pair'][0] >= _score_dict['best_predicted_pair_pro_cutoff']\n",
    "    ).astype(int)\n",
    "\n",
    "    if multi_dim is not None:\n",
    "        _score_dict['best_predicted_binary'] = _score_dict['best_predicted_binary'][:, multi_dim]\n",
    "\n",
    "    # best_5C_predicted_pair\n",
    "    _score_dict['best_5C_predicted_pair_pro_cutoff'] = [\n",
    "        get_optimal_threshold(\n",
    "            target=fold_item[1],\n",
    "            predict=fold_item[0],\n",
    "            multi_dim=multi_dim\n",
    "        )\n",
    "        for fold_item in _score_dict['best_5C_predicted_pair']\n",
    "    ]\n",
    "    _score_dict['best_5C_predicted_binary'] = [\n",
    "        (\n",
    "            _score_dict['best_5C_predicted_pair'][fold_id][0] >= _score_dict['best_5C_predicted_pair_pro_cutoff'][fold_id]\n",
    "        ).astype(int) \n",
    "        for fold_id in range(len(_score_dict['best_5C_predicted_pair']))\n",
    "    ]\n",
    "    _score_dict['best_5C_predicted_binary'] = [\n",
    "        _score_dict['best_5C_predicted_binary'][fold_id] if multi_dim is None else _score_dict['best_5C_predicted_binary'][fold_id][:, multi_dim]\n",
    "        for fold_id in range(len(_score_dict['best_5C_predicted_pair']))\n",
    "    ]\n",
    "\n",
    "    return _score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_dict = {\n",
    "    model_name: get_threshold_for_dict(\n",
    "        pickle.load(\n",
    "            gzip.open(f\"{path_to_score_dir}/ac/{model_name}_score.pkl.train\", \"rb\")\n",
    "        ),\n",
    "        multi_dim=1\n",
    "    )\n",
    "    for model_name in [\n",
    "        'SVC',\n",
    "        'GaussianNB',\n",
    "        'RandomForestClassifier',\n",
    "        'DecisionTreeClassifier'\n",
    "    ]\n",
    "} | {\n",
    "    \"BPBAac\": get_threshold_for_dict(\n",
    "        pickle.load(\n",
    "            gzip.open(f\"{path_to_score_dir}/bpb/SVC_score.pkl.train\", \"rb\")\n",
    "        ),\n",
    "        multi_dim=1\n",
    "    )\n",
    "} | {\n",
    "    model_name: get_threshold_for_dict(\n",
    "        pickle.load(\n",
    "            gzip.open(f\"{path_to_dnnscore_dir}/{model_name}_score.pkl.train\", \"rb\")\n",
    "        ),\n",
    "        multi_dim=0\n",
    "    )\n",
    "    for model_name in [\n",
    "        'DNN',\n",
    "        'RNN',\n",
    "        'SA',\n",
    "    ]\n",
    "}\n",
    "score_dict = {\n",
    "    model_name: get_threshold_for_dict(\n",
    "        pickle.load(\n",
    "            gzip.open(f\"{path_to_score_dir}/ac/{model_name}_score.pkl\", \"rb\")\n",
    "        ),\n",
    "        multi_dim=1\n",
    "    )\n",
    "    for model_name in [\n",
    "        'SVC',\n",
    "        'GaussianNB',\n",
    "        'RandomForestClassifier',\n",
    "        'DecisionTreeClassifier'\n",
    "    ]\n",
    "} | {\n",
    "    \"BPBAac\": get_threshold_for_dict(\n",
    "        pickle.load(\n",
    "            gzip.open(f\"{path_to_score_dir}/bpb/SVC_score.pkl\", \"rb\")\n",
    "        ),\n",
    "        multi_dim=1\n",
    "    )\n",
    "} | {\n",
    "    model_name: get_threshold_for_dict(\n",
    "        pickle.load(\n",
    "            gzip.open(f\"{path_to_dnnscore_dir}/{model_name}_score.pkl\", \"rb\")\n",
    "        ),\n",
    "        multi_dim=0\n",
    "    )\n",
    "    for model_name in [\n",
    "        'DNN',\n",
    "        'RNN',\n",
    "        'SA',\n",
    "    ]\n",
    "}\n",
    "voting_model_name_list = [\n",
    "    'SVC',\n",
    "    'GaussianNB',\n",
    "    'RandomForestClassifier',\n",
    "    'DecisionTreeClassifier',\n",
    "    \"BPBAac\",\n",
    "    'DNN',\n",
    "    'RNN',\n",
    "    'SA',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "train_tt_voting_score_pair = [\n",
    "    np.stack([\n",
    "        train_score_dict[model_name]['best_predicted_binary'] for model_name in voting_model_name_list\n",
    "    ], axis=1),\n",
    "    next(iter(train_score_dict.items()))[1]['best_predicted_pair'][1],\n",
    "]\n",
    "tt_voting_score_pair = [\n",
    "    np.stack([\n",
    "        score_dict[model_name]['best_predicted_binary'] for model_name in voting_model_name_list\n",
    "    ], axis=1),\n",
    "    next(iter(score_dict.items()))[1]['best_predicted_pair'][1],\n",
    "]\n",
    "\n",
    "tt_voting_score_pair[0] = SVC(probability=True).fit(\n",
    "    train_tt_voting_score_pair[0],\n",
    "    train_tt_voting_score_pair[1],\n",
    ").predict_proba(tt_voting_score_pair[0])\n",
    "\n",
    "train_cv_voting_score_pair_list = [\n",
    "    [\n",
    "        np.stack([\n",
    "            score_dict[model_name]['best_5C_predicted_binary'][fold_id] for model_name in voting_model_name_list\n",
    "        ], axis=1),\n",
    "        next(iter(score_dict.items()))[1]['best_5C_predicted_pair'][fold_id][1],\n",
    "    ]\n",
    "    for fold_id in range(len(next(iter(score_dict.items()))[1]['best_5C_predicted_pair']))\n",
    "]\n",
    "cv_voting_score_pair_list = [\n",
    "    [\n",
    "        np.stack([\n",
    "            score_dict[model_name]['best_5C_predicted_binary'][fold_id] for model_name in voting_model_name_list\n",
    "        ], axis=1),\n",
    "        next(iter(score_dict.items()))[1]['best_5C_predicted_pair'][fold_id][1],\n",
    "    ]\n",
    "    for fold_id in range(len(next(iter(score_dict.items()))[1]['best_5C_predicted_pair']))\n",
    "]\n",
    "for fold_id in range(len(next(iter(score_dict.items()))[1]['best_5C_predicted_pair'])):\n",
    "    cv_voting_score_pair_list[fold_id][0] = SVC(probability=True).fit(\n",
    "        train_cv_voting_score_pair_list[fold_id][0],\n",
    "        train_cv_voting_score_pair_list[fold_id][1],\n",
    "    ).predict_proba(cv_voting_score_pair_list[fold_id][0])\n",
    "\n",
    "os.makedirs(path_to_model_score_path, exist_ok=True)\n",
    "with gzip.open(f\"{path_to_model_score_path}/{job_name}_score.pkl\", \"wb\") as f:\n",
    "    pickle.dump(\n",
    "        {\n",
    "            \"best_predicted_pair\": tt_voting_score_pair,\n",
    "            \"best_5C_predicted_pair\": cv_voting_score_pair_list,\n",
    "        }, f\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TxSEml_Backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
