{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T1SEstacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "import os\n",
    "os.environ[\"n_jobs\"] = \"2\"\n",
    "import json\n",
    "\n",
    "import libpybiofeature\n",
    "\n",
    "import utils\n",
    "work_Dir = utils.workdir.workdir(os.getcwd(), 4)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "mpl.rcParams['svg.fonttype'] = 'none'\n",
    "mpl.rcParams['pdf.use14corefonts'] = False\n",
    "# mpl.rcParams['pdf.usecorefonts'] = True\n",
    "mpl.rcParams['pdf.compression'] = 9\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use(['science', 'nature'])\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_score, accuracy_score, f1_score, matthews_corrcoef, auc\n",
    "\n",
    "def get_evaluation(label: list, pred: list, pro_cutoff: float = None):\n",
    "    pred = np.nan_to_num(\n",
    "        pred, copy=True, nan=0.0\n",
    "    )\n",
    "    fpr, tpr, thresholds = roc_curve(label, pred)\n",
    "    if pro_cutoff is None:\n",
    "        best_one_optimal_idx = np.argmax(tpr - fpr)\n",
    "        pro_cutoff = thresholds[best_one_optimal_idx]\n",
    "    pred_l = [1 if i >= pro_cutoff else 0 for i in pred]\n",
    "    confusion_matrix_1d = confusion_matrix(label, pred_l).ravel()\n",
    "    confusion_dict = {N: n for N, n in zip(['tn', 'fp', 'fn', 'tp'], list(\n",
    "        confusion_matrix_1d * 2 / np.sum(confusion_matrix_1d)))}\n",
    "    evaluation = {\n",
    "        \"accuracy\": accuracy_score(label, pred_l),\n",
    "        \"precision\": precision_score(label, pred_l),\n",
    "        \"f1_score\": f1_score(label, pred_l),\n",
    "        \"mmc\": matthews_corrcoef(label, pred_l),\n",
    "        \"rocAUC\": auc(fpr, tpr),\n",
    "        \"specificity\": confusion_dict['tn'] / (confusion_dict['tn'] + confusion_dict['fp']),\n",
    "        \"sensitivity\": confusion_dict['tp'] / (confusion_dict['tp'] + confusion_dict['fn']),\n",
    "        # \"confusion_matrix\": confusion_dict,\n",
    "        # \"_roc_Data\": {'fpr': list(fpr), 'tpr': list(tpr)},\n",
    "        'pro_cutoff': pro_cutoff\n",
    "    }\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "def plot_roc_curve(target, pred, path_to_: str):\n",
    "    fpr, tpr, thresholds = roc_curve(target, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(19.2 / 4, 10.8 / 4))\n",
    "    plt.axis('square')\n",
    "    plt.plot(\n",
    "        fpr, tpr, color='red', lw=2,\n",
    "        label='ROC curve (area = %0.2f)' % roc_auc\n",
    "    )\n",
    "    plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC) curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.savefig(f\"{path_to_}\", transparent=True)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "def load_AAC_feature(TxSE_args: dict):\n",
    "\n",
    "    # Extract Feature\n",
    "    seq_id_dict = None\n",
    "    with open(TxSE_args['seq_id'], 'r', encoding='UTF-8') as f:\n",
    "        seq_id_dict = json.load(f)\n",
    "\n",
    "    # AAC\n",
    "    AAC_feature = {\n",
    "        \"name\": \"AAC\",\n",
    "        \"t_p\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['t']['p'],\n",
    "            seq_id_list=seq_id_dict['t']['p'],\n",
    "            desc='t_p',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"t_n\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['t']['n'],\n",
    "            seq_id_list=seq_id_dict['t']['n'],\n",
    "            desc='t_n',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"v_p\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['v']['p'],\n",
    "            seq_id_list=seq_id_dict['v']['p'],\n",
    "            desc='v_p',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"v_n\": libpybiofeature.featurebuilder.build_acc_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['v']['n'],\n",
    "            seq_id_list=seq_id_dict['v']['n'],\n",
    "            desc='v_n',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    return AAC_feature\n",
    "\n",
    "def load_DAC_feature(TxSE_args: dict):\n",
    "\n",
    "    # Extract Feature\n",
    "    seq_id_dict = None\n",
    "    with open(TxSE_args['seq_id'], 'r', encoding='UTF-8') as f:\n",
    "        seq_id_dict = json.load(f)\n",
    "\n",
    "    # AAC\n",
    "    DAC_feature = {\n",
    "        \"name\": \"DAC\",\n",
    "        \"t_p\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['t']['p'],\n",
    "            seq_id_list=seq_id_dict['t']['p'],\n",
    "            desc='t_p',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"t_n\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['t']['n'],\n",
    "            seq_id_list=seq_id_dict['t']['n'],\n",
    "            desc='t_n',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"v_p\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['v']['p'],\n",
    "            seq_id_list=seq_id_dict['v']['p'],\n",
    "            desc='v_p',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"v_n\": libpybiofeature.featurebuilder.build_dac_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['v']['n'],\n",
    "            seq_id_list=seq_id_dict['v']['n'],\n",
    "            desc='v_n',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    return DAC_feature\n",
    "\n",
    "import tqdm\n",
    "from src.libpybiofeature import AC, oneHot\n",
    "\n",
    "def build_DigitAA_feature(\n",
    "    path_to_fasta: str,\n",
    "    seq_id_list: list,\n",
    "    desc: str = 'undefine',\n",
    "    NCF='C',\n",
    "    terlength: int = 60\n",
    "):\n",
    "    assert NCF == \"C\"\n",
    "    assert terlength == 60\n",
    "\n",
    "    seq_list = list(SeqIO.parse(path_to_fasta, 'fasta'))\n",
    "    df = None\n",
    "    \n",
    "    df = pd.DataFrame([\n",
    "        [\n",
    "            oneHot.default_aa_dict[aa]\n",
    "            for aa in str(seq.seq)[-1 * terlength:]\n",
    "        ]\n",
    "        for seq in tqdm.tqdm(seq_list, desc=f'{desc}_AAC')\n",
    "    ]).fillna(0)\n",
    "\n",
    "    df.columns = list(range(df.shape[1]))\n",
    "    df.index = [seq.id for seq in seq_list]\n",
    "\n",
    "    if seq_id_list is not None:\n",
    "        return df.loc[seq_id_list, :]\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def load_DigitAA_feature(TxSE_args: dict):\n",
    "\n",
    "    # Extract Feature\n",
    "    seq_id_dict = None\n",
    "    with open(TxSE_args['seq_id'], 'r', encoding='UTF-8') as f:\n",
    "        seq_id_dict = json.load(f)\n",
    "\n",
    "    # AAC\n",
    "    DAC_feature = {\n",
    "        \"name\": \"DigitAA\",\n",
    "        \"t_p\": build_DigitAA_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['t']['p'],\n",
    "            seq_id_list=seq_id_dict['t']['p'],\n",
    "            desc='t_p',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"t_n\": build_DigitAA_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['t']['n'],\n",
    "            seq_id_list=seq_id_dict['t']['n'],\n",
    "            desc='t_n',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"v_p\": build_DigitAA_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['v']['p'],\n",
    "            seq_id_list=seq_id_dict['v']['p'],\n",
    "            desc='v_p',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "        \"v_n\": build_DigitAA_feature(\n",
    "            path_to_fasta=TxSE_args['fasta']['v']['n'],\n",
    "            seq_id_list=seq_id_dict['v']['n'],\n",
    "            desc='v_n',\n",
    "            NCF=\"C\",\n",
    "            terlength=60\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    return DAC_feature\n",
    "\n",
    "def load_BPBAac_feature(TxSE_args: dict):\n",
    "\n",
    "    # Extract Feature\n",
    "    seq_id_dict = None\n",
    "    with open(TxSE_args['seq_id'], 'r', encoding='UTF-8') as f:\n",
    "        seq_id_dict = json.load(f)\n",
    "\n",
    "    # BPBaac\n",
    "    BPBaac_seq_data = {\n",
    "        \"t_p\": libpybiofeature.libdataloader.fasta_seq_loader.prepare_data(\n",
    "            path_to_fasta=TxSE_args['fasta']['t']['p'],\n",
    "            seq_id_list=seq_id_dict['t']['p'],\n",
    "        )[0].values.tolist(),\n",
    "        \"t_n\": libpybiofeature.libdataloader.fasta_seq_loader.prepare_data(\n",
    "            path_to_fasta=TxSE_args['fasta']['t']['n'],\n",
    "            seq_id_list=seq_id_dict['t']['n'],\n",
    "        )[0].values.tolist(),\n",
    "        \"v_p\": libpybiofeature.libdataloader.fasta_seq_loader.prepare_data(\n",
    "            path_to_fasta=TxSE_args['fasta']['v']['p'],\n",
    "            seq_id_list=seq_id_dict['v']['p'],\n",
    "        )[0].values.tolist(),\n",
    "        \"v_n\": libpybiofeature.libdataloader.fasta_seq_loader.prepare_data(\n",
    "            path_to_fasta=TxSE_args['fasta']['v']['n'],\n",
    "            seq_id_list=seq_id_dict['v']['n'],\n",
    "        )[0].values.tolist(),\n",
    "    }\n",
    "\n",
    "    BPBaac_profile = {\n",
    "        \"p\": libpybiofeature.BPBaac_psp.mat_constructor(\n",
    "            fasta_db=BPBaac_seq_data['t_p'],\n",
    "            cter=TxSE_args['fasta']['cter'],\n",
    "            terlength=60,\n",
    "            padding_ac='A'\n",
    "        ),\n",
    "        \"n\": libpybiofeature.BPBaac_psp.mat_constructor(\n",
    "            fasta_db=BPBaac_seq_data['t_n'],\n",
    "            cter=TxSE_args['fasta']['cter'],\n",
    "            terlength=60,\n",
    "            padding_ac='A'\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    with open(\"out/libfeatureselection/T1/model/BPBaac_profile_C60.json\", \"w+\", encoding='UTF-8') as f:\n",
    "        json.dump(BPBaac_profile, f)\n",
    "\n",
    "    for data_type in BPBaac_seq_data.keys():\n",
    "        BPBaac_seq_data[data_type] = pd.DataFrame(\n",
    "            [\n",
    "                libpybiofeature.BPBaac_psp.mat_mapper(\n",
    "                    seq=str(seq.seq),\n",
    "                    pmat=BPBaac_profile['p'],\n",
    "                    nmat=BPBaac_profile['n'],\n",
    "                    cter=TxSE_args['fasta']['cter'],\n",
    "                    terlength=60,\n",
    "                    padding_ac='A'\n",
    "                ) for seq in BPBaac_seq_data[data_type]\n",
    "            ],\n",
    "            index=seq_id_dict[data_type.split(\"_\")[0]][data_type.split(\"_\")[1]]\n",
    "        )\n",
    "    BPBaac_seq_data['name'] = \"BPBaac\"\n",
    "\n",
    "    return BPBaac_seq_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_type = 1\n",
    "cter_bool = True\n",
    "Tx_arg = {\n",
    "    \"type\": f'T{prot_type}',\n",
    "    'seq_id': os.path.join(work_Dir, *['data', 'db', f'T{prot_type}', 'seq_id.json']),\n",
    "    'fasta': {\n",
    "        'cter': cter_bool,\n",
    "        't': {\n",
    "            'p': os.path.join(work_Dir, *['data', 'db', f'T{prot_type}', 't_p.fasta']),\n",
    "            'n': os.path.join(work_Dir, *['data', 'db', f'T{prot_type}', 't_n.fasta'])\n",
    "        },\n",
    "        'v': {\n",
    "            'p': os.path.join(work_Dir, *['data', 'db', f'T{prot_type}', 'v_p.fasta']),\n",
    "            'n': os.path.join(work_Dir, *['data', 'db', f'T{prot_type}', 'v_n.fasta'])\n",
    "        },\n",
    "    },\n",
    "}\n",
    "save_dir = \"out/libfeatureselection/T1/T1SEstacker/\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_p_AAC: 100%|██████████| 29/29 [00:00<00:00, 7512.50it/s]\n",
      "t_n_AAC: 100%|██████████| 29/29 [00:00<00:00, 34555.35it/s]\n",
      "v_p_AAC: 100%|██████████| 20/20 [00:00<00:00, 3648.65it/s]\n",
      "v_n_AAC: 100%|██████████| 20/20 [00:00<00:00, 23399.19it/s]\n",
      "t_p_DAC: 100%|██████████| 29/29 [00:00<00:00, 9667.37it/s]\n",
      "t_n_DAC: 100%|██████████| 29/29 [00:00<00:00, 9120.79it/s]\n",
      "v_p_DAC: 100%|██████████| 20/20 [00:00<00:00, 8648.94it/s]\n",
      "v_n_DAC: 100%|██████████| 20/20 [00:00<00:00, 10462.22it/s]\n",
      "t_p_AAC: 100%|██████████| 29/29 [00:00<00:00, 29775.96it/s]\n",
      "t_n_AAC: 100%|██████████| 29/29 [00:00<00:00, 34080.92it/s]\n",
      "v_p_AAC: 100%|██████████| 20/20 [00:00<00:00, 1433.51it/s]\n",
      "v_n_AAC: 100%|██████████| 20/20 [00:00<00:00, 1846.94it/s]\n"
     ]
    }
   ],
   "source": [
    "aac_data = load_AAC_feature(\n",
    "    TxSE_args=Tx_arg\n",
    ")\n",
    "dac_data = load_DAC_feature(\n",
    "    TxSE_args=Tx_arg\n",
    ")\n",
    "ac_data = {\n",
    "    datatype: pd.concat([\n",
    "        item[datatype] for item in [aac_data, dac_data]\n",
    "    ], axis=1)\n",
    "    for datatype in [\"t_p\", \"t_n\", \"v_p\", \"v_n\"]\n",
    "}\n",
    "bpb_data = load_BPBAac_feature(\n",
    "    TxSE_args=Tx_arg\n",
    ")\n",
    "digitaa_data = load_DigitAA_feature(\n",
    "    TxSE_args=Tx_arg\n",
    ")\n",
    "aa_type = list(aac_data['t_p'].columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-22 01:58:32.048870: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-22 01:58:32.057061: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-07-22 01:58:32.057144: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import typing\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.base import ClassifierMixin\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection._search import BaseSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AAC / DAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-22 01:58:35.685678: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-07-22 01:58:35.685852: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-07-22 01:58:35.685921: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (A7LAB): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from libfeatureselection import model, model_space\n",
    "n_jobs = (\n",
    "    (os.cpu_count() - 2)\n",
    "    if \"n_jobs\" not in os.environ or os.environ['n_jobs'] == \"\" else\n",
    "    int(os.environ['n_jobs'])\n",
    ")\n",
    "n_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 47%|████▋     | 7/15 [00:03<00:04,  1.71it/s]/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_result_in_a_scheme_df = pd.DataFrame()\n",
    "for model_index in tqdm.tqdm(range(len(model_space.find_space))):\n",
    "    if model_space.find_space[model_index]['name'] not in [\n",
    "        'SVC',\n",
    "        'GaussianNB',\n",
    "        'RandomForestClassifier',\n",
    "        'DecisionTreeClassifier'\n",
    "    ]:\n",
    "        continue\n",
    "    model_information_summary, searched_result_performance_summary, searched_result_5C_performance_summary = model.MyOptimitzer(\n",
    "        classifier_name=model_space.find_space[model_index]['name'],\n",
    "        classifier_class=model_space.find_space[model_index]['class'],\n",
    "        classifier_param_dict=model_space.find_space[model_index]['param'],\n",
    "    ).find_best(\n",
    "        X=pd.concat([ac_data['t_p'], ac_data['t_n']]).values,\n",
    "        y=np.concatenate([np.ones((ac_data['t_p'].shape[0], )), np.zeros((ac_data['t_n'].shape[0], ))]),\n",
    "        validation=(\n",
    "            pd.concat([ac_data['v_p'], ac_data['v_n']]).values,\n",
    "            np.concatenate([np.ones((ac_data['v_p'].shape[0], )), np.zeros((ac_data['v_n'].shape[0], ))]),\n",
    "        ),\n",
    "        search_method=(\n",
    "            \"BayesSearchCV\"\n",
    "            if \"Bayes\" not in model_space.find_space[model_index]\n",
    "            or model_space.find_space[model_index]['Bayes'] == True\n",
    "            else \"GridSearchCV\"\n",
    "        ),\n",
    "        n_jobs=n_jobs\n",
    "    ).get_summary(\n",
    "        path_to_dir=f\"out/libfeatureselection/T1/T1SEstacker/model/ac/\"\n",
    "    )\n",
    "\n",
    "    # 记录结果，插入到 search_result_in_a_scheme_df\n",
    "    result_series = pd.concat([\n",
    "        pd.Series(model_information_summary),\n",
    "        pd.Series(searched_result_performance_summary),\n",
    "        pd.Series(searched_result_5C_performance_summary),\n",
    "    ], keys=[\n",
    "        \"Model_Information\",\n",
    "        \"Best_Performance\",\n",
    "        \"5FoldCV_Performance\",\n",
    "    ])\n",
    "\n",
    "    result_series.name = model_index\n",
    "\n",
    "    search_result_in_a_scheme_df = pd.concat([\n",
    "        search_result_in_a_scheme_df,\n",
    "        result_series.to_frame().T\n",
    "    ], axis=0, ignore_index=False)\n",
    "\n",
    "    search_result_in_a_scheme_df.index = search_result_in_a_scheme_df.index.set_names(\n",
    "        [\"Model_Type\",]\n",
    "    )\n",
    "\n",
    "    local_xlsx_path = f\"out/libfeatureselection/T1/T1SEstacker/model/ac/searched_result.xlsx\"\n",
    "\n",
    "    # 缓存 search_result_in_a_scheme_df\n",
    "    search_result_in_a_scheme_df.to_excel(\n",
    "        local_xlsx_path,\n",
    "        \"T1SEstacker\",\n",
    "        freeze_panes=(2, 1)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPBAac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]/home/georgezhao/.pyvirtualenvs/TxSEml_Backend/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 15/15 [00:01<00:00, 14.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_result_in_a_scheme_df = pd.DataFrame()\n",
    "for model_index in tqdm.tqdm(range(len(model_space.find_space))):\n",
    "    if model_space.find_space[model_index]['name'] not in [\n",
    "        'SVC',\n",
    "    ]:\n",
    "        continue\n",
    "    model_information_summary, searched_result_performance_summary, searched_result_5C_performance_summary = model.MyOptimitzer(\n",
    "        classifier_name=model_space.find_space[model_index]['name'],\n",
    "        classifier_class=model_space.find_space[model_index]['class'],\n",
    "        classifier_param_dict=model_space.find_space[model_index]['param'],\n",
    "    ).find_best(\n",
    "        X=pd.concat([ac_data['t_p'], ac_data['t_n']]).values,\n",
    "        y=np.concatenate([np.ones((ac_data['t_p'].shape[0], )), np.zeros((ac_data['t_n'].shape[0], ))]),\n",
    "        validation=(\n",
    "            pd.concat([ac_data['v_p'], ac_data['v_n']]).values,\n",
    "            np.concatenate([np.ones((ac_data['v_p'].shape[0], )), np.zeros((ac_data['v_n'].shape[0], ))]),\n",
    "        ),\n",
    "        search_method=(\n",
    "            \"BayesSearchCV\"\n",
    "            if \"Bayes\" not in model_space.find_space[model_index]\n",
    "            or model_space.find_space[model_index]['Bayes'] == True\n",
    "            else \"GridSearchCV\"\n",
    "        ),\n",
    "        n_jobs=n_jobs\n",
    "    ).get_summary(\n",
    "        path_to_dir=f\"out/libfeatureselection/T1/T1SEstacker/model/bpb\"\n",
    "    )\n",
    "\n",
    "    # 记录结果，插入到 search_result_in_a_scheme_df\n",
    "    result_series = pd.concat([\n",
    "        pd.Series(model_information_summary),\n",
    "        pd.Series(searched_result_performance_summary),\n",
    "        pd.Series(searched_result_5C_performance_summary),\n",
    "    ], keys=[\n",
    "        \"Model_Information\",\n",
    "        \"Best_Performance\",\n",
    "        \"5FoldCV_Performance\",\n",
    "    ])\n",
    "\n",
    "    result_series.name = model_index\n",
    "\n",
    "    search_result_in_a_scheme_df = pd.concat([\n",
    "        search_result_in_a_scheme_df,\n",
    "        result_series.to_frame().T\n",
    "    ], axis=0, ignore_index=False)\n",
    "\n",
    "    search_result_in_a_scheme_df.index = search_result_in_a_scheme_df.index.set_names(\n",
    "        [\"Model_Type\",]\n",
    "    )\n",
    "\n",
    "    local_xlsx_path = f\"out/libfeatureselection/T1/T1SEstacker/model/bpb/searched_result.xlsx\"\n",
    "\n",
    "    # 缓存 search_result_in_a_scheme_df\n",
    "    search_result_in_a_scheme_df.to_excel(\n",
    "        local_xlsx_path,\n",
    "        \"T1SEstacker\",\n",
    "        freeze_panes=(2, 1)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DNN_model(seq_length: int, sizeof_ac_dict: int):\n",
    "    input1 = tf.keras.layers.Input(shape=(seq_length,), name='Input_Layer')\n",
    "    embedding1 = tf.keras.layers.Embedding(\n",
    "        input_dim=sizeof_ac_dict, output_dim=sizeof_ac_dict, name=\"AC_EMBEDED\")(input1)\n",
    "    flatten_layer = tf.keras.layers.Flatten()(embedding1)\n",
    "    dense3 = tf.keras.layers.Dense(\n",
    "        1, activation=tf.keras.activations.sigmoid)(flatten_layer)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=input1, outputs=dense3, name='simple')\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "        loss=tf.keras.losses.binary_crossentropy,\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(),\n",
    "            tf.keras.metrics.AUC(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.TruePositives(),\n",
    "            tf.keras.metrics.TrueNegatives(),\n",
    "            tf.keras.metrics.FalsePositives(),\n",
    "            tf.keras.metrics.FalseNegatives()\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "class DNN_Trainer:\n",
    "    def __init__(self, ) -> None:\n",
    "        self.classifier_name = \"DNN\"\n",
    "        self.classifier_class = get_DNN_model\n",
    "        self.classifier_param_dict = {\n",
    "            \"seq_length\": 60,\n",
    "            \"sizeof_ac_dict\": 20\n",
    "        }\n",
    "\n",
    "        self.model = None\n",
    "        self.train_best_predicted_pair = None\n",
    "        self.train_best_5C_predicted_pair = None\n",
    "        self.best_predicted_pair = None\n",
    "        self.best_5C_predicted_pair = None\n",
    "        self.start_to_train_time = datetime.now()\n",
    "        self.end_of_train_time = None\n",
    "        pass\n",
    "\n",
    "    def find_best(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        validation: tuple,\n",
    "    ):\n",
    "\n",
    "        self.model = self.classifier_class(\n",
    "            **self.classifier_param_dict\n",
    "        )\n",
    "        self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            epochs=10,\n",
    "            use_multiprocessing=True,\n",
    "            steps_per_epoch=None,\n",
    "            verbose=2\n",
    "        )\n",
    "        self.best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                validation[0]\n",
    "            ), nan=0.0),\n",
    "            validation[1]\n",
    "        ]\n",
    "        self.train_best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                X\n",
    "            ), nan=0.0),\n",
    "            y\n",
    "        ]\n",
    "\n",
    "        # 5倍交叉验证\n",
    "        # 合并数据\n",
    "        full_X = np.concatenate([\n",
    "            X, validation[0]\n",
    "        ])\n",
    "        full_y = np.concatenate([\n",
    "            y, validation[1]\n",
    "        ])\n",
    "\n",
    "        # 跑模型\n",
    "        self.best_5C_predicted_pair = []\n",
    "        self.train_best_5C_predicted_pair = []\n",
    "        for Kfold_id, (train_id, test_id) in enumerate(\n",
    "            StratifiedKFold(\n",
    "                n_splits=5,\n",
    "                shuffle=True,\n",
    "                random_state=42\n",
    "            ).split(full_X, full_y)\n",
    "        ):\n",
    "\n",
    "            # 定义模型并加载参数\n",
    "            fiveC_model = self.classifier_class(\n",
    "                **self.classifier_param_dict,\n",
    "            )\n",
    "\n",
    "            fiveC_model.fit(\n",
    "                full_X[train_id],\n",
    "                full_y[train_id],\n",
    "                epochs=10,\n",
    "                use_multiprocessing=True,\n",
    "                steps_per_epoch=None,\n",
    "                verbose=2\n",
    "            )\n",
    "\n",
    "            # 预测并记录\n",
    "            self.best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    full_X[test_id]\n",
    "                ), nan=0.0),\n",
    "                full_y[test_id]\n",
    "            ])\n",
    "            self.train_best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    full_X[train_id]\n",
    "                ), nan=0.0),\n",
    "                full_y[train_id]\n",
    "            ])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_summary(self, path_to_dir: str = None):\n",
    "        os.makedirs(path_to_dir, exist_ok=True)\n",
    "        model_path = \"-\"\n",
    "        if \"SAVE_MODEL\" in os.environ and os.environ['SAVE_MODEL'] == \"1\":\n",
    "\n",
    "            model_path = f\"{path_to_dir}/{self.classifier_name}.pkl\"\n",
    "            if path_to_dir is not None:\n",
    "                with gzip.open(model_path, \"wb\") as f:\n",
    "                    pickle.dump(\n",
    "                        self.grid_search, f\n",
    "                    )\n",
    "\n",
    "        model_score_path = f\"{path_to_dir}/{self.classifier_name}_score.pkl\"\n",
    "        if path_to_dir is not None:\n",
    "            with gzip.open(model_score_path, \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "            with gzip.open(model_score_path + \".train\", \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.train_best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.train_best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "        else:\n",
    "            model_score_path = \"-\"\n",
    "\n",
    "        plot_roc_curve(\n",
    "            target=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "            path_to_=f\"{path_to_dir}/{self.classifier_name}.pdf\"\n",
    "        )\n",
    "\n",
    "        model_information = {\n",
    "            \"Classifier_Name\": self.classifier_name,\n",
    "            \"Optimitied_Param\": dict(),\n",
    "            \"Score\": model_score_path,\n",
    "            \"Model_Path\": model_path,\n",
    "            \"TimeToStartFit\": self.start_to_train_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "\n",
    "        training_testing_performance = get_evaluation(\n",
    "            label=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "        )\n",
    "\n",
    "        # 计算5C中的平均表现\n",
    "        FiveFold_result = {}\n",
    "        for keys in training_testing_performance.keys():\n",
    "            value_list = []\n",
    "            for item in self.best_5C_predicted_pair:\n",
    "\n",
    "                item_performance = get_evaluation(\n",
    "                    label=item[1],\n",
    "                    pred=item[0],\n",
    "                )\n",
    "                value_list.append(item_performance[keys])\n",
    "\n",
    "            if keys == \"pro_cutoff\":\n",
    "                FiveFold_result[keys] = value_list\n",
    "            else:\n",
    "                FiveFold_result[keys] = sum(value_list) / len(value_list)\n",
    "\n",
    "        self.end_of_train_time = datetime.now()\n",
    "        model_information[\"TimeOfSummary\"] = self.end_of_train_time.strftime(\n",
    "            \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "        model_information[\"TimeSpend\"] = str(\n",
    "            self.end_of_train_time - self.start_to_train_time\n",
    "        )\n",
    "\n",
    "        return model_information, training_testing_performance, FiveFold_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 - 2s - loss: 0.6969 - binary_accuracy: 0.3966 - auc_2: 0.4055 - precision_2: 0.4167 - true_positives_2: 15.0000 - true_negatives_2: 8.0000 - false_positives_2: 21.0000 - false_negatives_2: 14.0000 - 2s/epoch - 1s/step\n",
      "Epoch 2/10\n",
      "2/2 - 0s - loss: 0.6332 - binary_accuracy: 0.9483 - auc_2: 0.9964 - precision_2: 0.9062 - true_positives_2: 29.0000 - true_negatives_2: 26.0000 - false_positives_2: 3.0000 - false_negatives_2: 0.0000e+00 - 24ms/epoch - 12ms/step\n",
      "Epoch 3/10\n",
      "2/2 - 0s - loss: 0.5686 - binary_accuracy: 1.0000 - auc_2: 1.0000 - precision_2: 1.0000 - true_positives_2: 29.0000 - true_negatives_2: 29.0000 - false_positives_2: 0.0000e+00 - false_negatives_2: 0.0000e+00 - 9ms/epoch - 4ms/step\n",
      "Epoch 4/10\n",
      "2/2 - 0s - loss: 0.4855 - binary_accuracy: 1.0000 - auc_2: 1.0000 - precision_2: 1.0000 - true_positives_2: 29.0000 - true_negatives_2: 29.0000 - false_positives_2: 0.0000e+00 - false_negatives_2: 0.0000e+00 - 10ms/epoch - 5ms/step\n",
      "Epoch 5/10\n",
      "2/2 - 0s - loss: 0.3897 - binary_accuracy: 1.0000 - auc_2: 1.0000 - precision_2: 1.0000 - true_positives_2: 29.0000 - true_negatives_2: 29.0000 - false_positives_2: 0.0000e+00 - false_negatives_2: 0.0000e+00 - 23ms/epoch - 12ms/step\n",
      "Epoch 6/10\n",
      "2/2 - 0s - loss: 0.2916 - binary_accuracy: 1.0000 - auc_2: 1.0000 - precision_2: 1.0000 - true_positives_2: 29.0000 - true_negatives_2: 29.0000 - false_positives_2: 0.0000e+00 - false_negatives_2: 0.0000e+00 - 10ms/epoch - 5ms/step\n",
      "Epoch 7/10\n",
      "2/2 - 0s - loss: 0.2035 - binary_accuracy: 1.0000 - auc_2: 1.0000 - precision_2: 1.0000 - true_positives_2: 29.0000 - true_negatives_2: 29.0000 - false_positives_2: 0.0000e+00 - false_negatives_2: 0.0000e+00 - 23ms/epoch - 12ms/step\n",
      "Epoch 8/10\n",
      "2/2 - 0s - loss: 0.1334 - binary_accuracy: 1.0000 - auc_2: 1.0000 - precision_2: 1.0000 - true_positives_2: 29.0000 - true_negatives_2: 29.0000 - false_positives_2: 0.0000e+00 - false_negatives_2: 0.0000e+00 - 30ms/epoch - 15ms/step\n",
      "Epoch 9/10\n",
      "2/2 - 0s - loss: 0.0818 - binary_accuracy: 1.0000 - auc_2: 1.0000 - precision_2: 1.0000 - true_positives_2: 29.0000 - true_negatives_2: 29.0000 - false_positives_2: 0.0000e+00 - false_negatives_2: 0.0000e+00 - 13ms/epoch - 6ms/step\n",
      "Epoch 10/10\n",
      "2/2 - 0s - loss: 0.0492 - binary_accuracy: 1.0000 - auc_2: 1.0000 - precision_2: 1.0000 - true_positives_2: 29.0000 - true_negatives_2: 29.0000 - false_positives_2: 0.0000e+00 - false_negatives_2: 0.0000e+00 - 20ms/epoch - 10ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 1/10\n",
      "3/3 - 2s - loss: 0.6825 - binary_accuracy: 0.6667 - auc_3: 0.7183 - precision_3: 0.6383 - true_positives_3: 30.0000 - true_negatives_3: 22.0000 - false_positives_3: 17.0000 - false_negatives_3: 9.0000 - 2s/epoch - 616ms/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.5999 - binary_accuracy: 0.9359 - auc_3: 0.9947 - precision_3: 0.9250 - true_positives_3: 37.0000 - true_negatives_3: 36.0000 - false_positives_3: 3.0000 - false_negatives_3: 2.0000 - 15ms/epoch - 5ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.5011 - binary_accuracy: 0.9744 - auc_3: 0.9987 - precision_3: 0.9744 - true_positives_3: 38.0000 - true_negatives_3: 38.0000 - false_positives_3: 1.0000 - false_negatives_3: 1.0000 - 15ms/epoch - 5ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.3851 - binary_accuracy: 0.9744 - auc_3: 0.9990 - precision_3: 0.9744 - true_positives_3: 38.0000 - true_negatives_3: 38.0000 - false_positives_3: 1.0000 - false_negatives_3: 1.0000 - 32ms/epoch - 11ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.2735 - binary_accuracy: 0.9872 - auc_3: 0.9993 - precision_3: 1.0000 - true_positives_3: 38.0000 - true_negatives_3: 39.0000 - false_positives_3: 0.0000e+00 - false_negatives_3: 1.0000 - 36ms/epoch - 12ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.1785 - binary_accuracy: 0.9872 - auc_3: 0.9993 - precision_3: 1.0000 - true_positives_3: 38.0000 - true_negatives_3: 39.0000 - false_positives_3: 0.0000e+00 - false_negatives_3: 1.0000 - 19ms/epoch - 6ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.1129 - binary_accuracy: 0.9872 - auc_3: 1.0000 - precision_3: 1.0000 - true_positives_3: 38.0000 - true_negatives_3: 39.0000 - false_positives_3: 0.0000e+00 - false_negatives_3: 1.0000 - 17ms/epoch - 6ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.0688 - binary_accuracy: 1.0000 - auc_3: 1.0000 - precision_3: 1.0000 - true_positives_3: 39.0000 - true_negatives_3: 39.0000 - false_positives_3: 0.0000e+00 - false_negatives_3: 0.0000e+00 - 17ms/epoch - 6ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.0402 - binary_accuracy: 1.0000 - auc_3: 1.0000 - precision_3: 1.0000 - true_positives_3: 39.0000 - true_negatives_3: 39.0000 - false_positives_3: 0.0000e+00 - false_negatives_3: 0.0000e+00 - 17ms/epoch - 6ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.0244 - binary_accuracy: 1.0000 - auc_3: 1.0000 - precision_3: 1.0000 - true_positives_3: 39.0000 - true_negatives_3: 39.0000 - false_positives_3: 0.0000e+00 - false_negatives_3: 0.0000e+00 - 19ms/epoch - 6ms/step\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb461043f40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "Epoch 1/10\n",
      "3/3 - 2s - loss: 0.6924 - binary_accuracy: 0.4872 - auc_4: 0.5260 - precision_4: 0.4828 - true_positives_4: 14.0000 - true_negatives_4: 24.0000 - false_positives_4: 15.0000 - false_negatives_4: 25.0000 - 2s/epoch - 743ms/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.6201 - binary_accuracy: 0.9744 - auc_4: 0.9980 - precision_4: 1.0000 - true_positives_4: 37.0000 - true_negatives_4: 39.0000 - false_positives_4: 0.0000e+00 - false_negatives_4: 2.0000 - 8ms/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.5310 - binary_accuracy: 0.9872 - auc_4: 0.9997 - precision_4: 1.0000 - true_positives_4: 38.0000 - true_negatives_4: 39.0000 - false_positives_4: 0.0000e+00 - false_negatives_4: 1.0000 - 21ms/epoch - 7ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.4198 - binary_accuracy: 1.0000 - auc_4: 1.0000 - precision_4: 1.0000 - true_positives_4: 39.0000 - true_negatives_4: 39.0000 - false_positives_4: 0.0000e+00 - false_negatives_4: 0.0000e+00 - 8ms/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.2964 - binary_accuracy: 1.0000 - auc_4: 1.0000 - precision_4: 1.0000 - true_positives_4: 39.0000 - true_negatives_4: 39.0000 - false_positives_4: 0.0000e+00 - false_negatives_4: 0.0000e+00 - 20ms/epoch - 7ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.1928 - binary_accuracy: 1.0000 - auc_4: 1.0000 - precision_4: 1.0000 - true_positives_4: 39.0000 - true_negatives_4: 39.0000 - false_positives_4: 0.0000e+00 - false_negatives_4: 0.0000e+00 - 20ms/epoch - 7ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.1179 - binary_accuracy: 1.0000 - auc_4: 1.0000 - precision_4: 1.0000 - true_positives_4: 39.0000 - true_negatives_4: 39.0000 - false_positives_4: 0.0000e+00 - false_negatives_4: 0.0000e+00 - 31ms/epoch - 10ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.0691 - binary_accuracy: 1.0000 - auc_4: 1.0000 - precision_4: 1.0000 - true_positives_4: 39.0000 - true_negatives_4: 39.0000 - false_positives_4: 0.0000e+00 - false_negatives_4: 0.0000e+00 - 31ms/epoch - 10ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.0387 - binary_accuracy: 1.0000 - auc_4: 1.0000 - precision_4: 1.0000 - true_positives_4: 39.0000 - true_negatives_4: 39.0000 - false_positives_4: 0.0000e+00 - false_negatives_4: 0.0000e+00 - 17ms/epoch - 6ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.0221 - binary_accuracy: 1.0000 - auc_4: 1.0000 - precision_4: 1.0000 - true_positives_4: 39.0000 - true_negatives_4: 39.0000 - false_positives_4: 0.0000e+00 - false_negatives_4: 0.0000e+00 - 19ms/epoch - 6ms/step\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb461041bd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "Epoch 1/10\n",
      "3/3 - 2s - loss: 0.6927 - binary_accuracy: 0.4359 - auc_5: 0.5053 - precision_5: 0.4490 - true_positives_5: 22.0000 - true_negatives_5: 12.0000 - false_positives_5: 27.0000 - false_negatives_5: 17.0000 - 2s/epoch - 767ms/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.6222 - binary_accuracy: 0.9615 - auc_5: 0.9984 - precision_5: 0.9737 - true_positives_5: 37.0000 - true_negatives_5: 38.0000 - false_positives_5: 1.0000 - false_negatives_5: 2.0000 - 9ms/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.5364 - binary_accuracy: 0.9872 - auc_5: 1.0000 - precision_5: 1.0000 - true_positives_5: 38.0000 - true_negatives_5: 39.0000 - false_positives_5: 0.0000e+00 - false_negatives_5: 1.0000 - 9ms/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.4263 - binary_accuracy: 0.9872 - auc_5: 1.0000 - precision_5: 1.0000 - true_positives_5: 38.0000 - true_negatives_5: 39.0000 - false_positives_5: 0.0000e+00 - false_negatives_5: 1.0000 - 9ms/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.3042 - binary_accuracy: 0.9872 - auc_5: 0.9993 - precision_5: 1.0000 - true_positives_5: 38.0000 - true_negatives_5: 39.0000 - false_positives_5: 0.0000e+00 - false_negatives_5: 1.0000 - 8ms/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.2019 - binary_accuracy: 0.9872 - auc_5: 0.9993 - precision_5: 1.0000 - true_positives_5: 38.0000 - true_negatives_5: 39.0000 - false_positives_5: 0.0000e+00 - false_negatives_5: 1.0000 - 10ms/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.1249 - binary_accuracy: 0.9872 - auc_5: 1.0000 - precision_5: 1.0000 - true_positives_5: 38.0000 - true_negatives_5: 39.0000 - false_positives_5: 0.0000e+00 - false_negatives_5: 1.0000 - 9ms/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.0757 - binary_accuracy: 0.9872 - auc_5: 1.0000 - precision_5: 1.0000 - true_positives_5: 38.0000 - true_negatives_5: 39.0000 - false_positives_5: 0.0000e+00 - false_negatives_5: 1.0000 - 13ms/epoch - 4ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.0449 - binary_accuracy: 1.0000 - auc_5: 1.0000 - precision_5: 1.0000 - true_positives_5: 39.0000 - true_negatives_5: 39.0000 - false_positives_5: 0.0000e+00 - false_negatives_5: 0.0000e+00 - 9ms/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.0250 - binary_accuracy: 1.0000 - auc_5: 1.0000 - precision_5: 1.0000 - true_positives_5: 39.0000 - true_negatives_5: 39.0000 - false_positives_5: 0.0000e+00 - false_negatives_5: 0.0000e+00 - 10ms/epoch - 3ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "Epoch 1/10\n",
      "3/3 - 4s - loss: 0.6933 - binary_accuracy: 0.4810 - auc_6: 0.4808 - precision_6: 0.4545 - true_positives_6: 10.0000 - true_negatives_6: 28.0000 - false_positives_6: 12.0000 - false_negatives_6: 29.0000 - 4s/epoch - 1s/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.6189 - binary_accuracy: 0.9747 - auc_6: 0.9984 - precision_6: 1.0000 - true_positives_6: 37.0000 - true_negatives_6: 40.0000 - false_positives_6: 0.0000e+00 - false_negatives_6: 2.0000 - 18ms/epoch - 6ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.5369 - binary_accuracy: 0.9747 - auc_6: 0.9987 - precision_6: 0.9512 - true_positives_6: 39.0000 - true_negatives_6: 38.0000 - false_positives_6: 2.0000 - false_negatives_6: 0.0000e+00 - 28ms/epoch - 9ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.4262 - binary_accuracy: 0.9747 - auc_6: 1.0000 - precision_6: 0.9512 - true_positives_6: 39.0000 - true_negatives_6: 38.0000 - false_positives_6: 2.0000 - false_negatives_6: 0.0000e+00 - 9ms/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.3037 - binary_accuracy: 0.9873 - auc_6: 1.0000 - precision_6: 0.9750 - true_positives_6: 39.0000 - true_negatives_6: 39.0000 - false_positives_6: 1.0000 - false_negatives_6: 0.0000e+00 - 20ms/epoch - 7ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.2007 - binary_accuracy: 1.0000 - auc_6: 1.0000 - precision_6: 1.0000 - true_positives_6: 39.0000 - true_negatives_6: 40.0000 - false_positives_6: 0.0000e+00 - false_negatives_6: 0.0000e+00 - 16ms/epoch - 5ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.1240 - binary_accuracy: 1.0000 - auc_6: 1.0000 - precision_6: 1.0000 - true_positives_6: 39.0000 - true_negatives_6: 40.0000 - false_positives_6: 0.0000e+00 - false_negatives_6: 0.0000e+00 - 14ms/epoch - 5ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.0721 - binary_accuracy: 1.0000 - auc_6: 1.0000 - precision_6: 1.0000 - true_positives_6: 39.0000 - true_negatives_6: 40.0000 - false_positives_6: 0.0000e+00 - false_negatives_6: 0.0000e+00 - 11ms/epoch - 4ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.0427 - binary_accuracy: 1.0000 - auc_6: 1.0000 - precision_6: 1.0000 - true_positives_6: 39.0000 - true_negatives_6: 40.0000 - false_positives_6: 0.0000e+00 - false_negatives_6: 0.0000e+00 - 38ms/epoch - 13ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.0251 - binary_accuracy: 1.0000 - auc_6: 1.0000 - precision_6: 1.0000 - true_positives_6: 39.0000 - true_negatives_6: 40.0000 - false_positives_6: 0.0000e+00 - false_negatives_6: 0.0000e+00 - 10ms/epoch - 3ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "Epoch 1/10\n",
      "3/3 - 2s - loss: 0.7004 - binary_accuracy: 0.3544 - auc_7: 0.3782 - precision_7: 0.2381 - true_positives_7: 5.0000 - true_negatives_7: 23.0000 - false_positives_7: 16.0000 - false_negatives_7: 35.0000 - 2s/epoch - 740ms/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.6326 - binary_accuracy: 0.9494 - auc_7: 0.9891 - precision_7: 0.9737 - true_positives_7: 37.0000 - true_negatives_7: 38.0000 - false_positives_7: 1.0000 - false_negatives_7: 3.0000 - 27ms/epoch - 9ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.5532 - binary_accuracy: 0.9747 - auc_7: 0.9994 - precision_7: 0.9524 - true_positives_7: 40.0000 - true_negatives_7: 37.0000 - false_positives_7: 2.0000 - false_negatives_7: 0.0000e+00 - 10ms/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.4458 - binary_accuracy: 0.9747 - auc_7: 1.0000 - precision_7: 0.9524 - true_positives_7: 40.0000 - true_negatives_7: 37.0000 - false_positives_7: 2.0000 - false_negatives_7: 0.0000e+00 - 22ms/epoch - 7ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.3273 - binary_accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - true_positives_7: 40.0000 - true_negatives_7: 39.0000 - false_positives_7: 0.0000e+00 - false_negatives_7: 0.0000e+00 - 18ms/epoch - 6ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.2197 - binary_accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - true_positives_7: 40.0000 - true_negatives_7: 39.0000 - false_positives_7: 0.0000e+00 - false_negatives_7: 0.0000e+00 - 9ms/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.1336 - binary_accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - true_positives_7: 40.0000 - true_negatives_7: 39.0000 - false_positives_7: 0.0000e+00 - false_negatives_7: 0.0000e+00 - 10ms/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.0766 - binary_accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - true_positives_7: 40.0000 - true_negatives_7: 39.0000 - false_positives_7: 0.0000e+00 - false_negatives_7: 0.0000e+00 - 9ms/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.0425 - binary_accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - true_positives_7: 40.0000 - true_negatives_7: 39.0000 - false_positives_7: 0.0000e+00 - false_negatives_7: 0.0000e+00 - 20ms/epoch - 7ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.0241 - binary_accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - true_positives_7: 40.0000 - true_negatives_7: 39.0000 - false_positives_7: 0.0000e+00 - false_negatives_7: 0.0000e+00 - 13ms/epoch - 4ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Classifier_Name': 'DNN',\n",
       "  'Optimitied_Param': {},\n",
       "  'Score': 'out/libfeatureselection/T1/T1SEstacker//DNN_score.pkl',\n",
       "  'Model_Path': '-',\n",
       "  'TimeToStartFit': '2023-07-22 02:00:17',\n",
       "  'TimeOfSummary': '2023-07-22 02:00:38',\n",
       "  'TimeSpend': '0:00:20.918835'},\n",
       " {'accuracy': 0.725,\n",
       "  'precision': 0.7647058823529411,\n",
       "  'f1_score': 0.7027027027027027,\n",
       "  'mmc': 0.4551495636817563,\n",
       "  'rocAUC': 0.76,\n",
       "  'specificity': 0.8,\n",
       "  'sensitivity': 0.65,\n",
       "  'pro_cutoff': 0.68580323},\n",
       " {'accuracy': 0.8473684210526315,\n",
       "  'precision': 0.8387878787878789,\n",
       "  'f1_score': 0.8491442510018363,\n",
       "  'mmc': 0.7093560498101954,\n",
       "  'rocAUC': 0.8831111111111112,\n",
       "  'specificity': 0.8155555555555555,\n",
       "  'sensitivity': 0.8777777777777779,\n",
       "  'pro_cutoff': [0.66464895, 0.9232568, 0.33324152, 0.3120414, 0.5806102]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DNN_Trainer().find_best(\n",
    "    X=pd.concat([digitaa_data['t_p'], digitaa_data['t_n']]),\n",
    "    y=np.concatenate([np.ones((digitaa_data['t_p'].shape[0], )), np.zeros((digitaa_data['t_n'].shape[0], ))]),\n",
    "    validation=(\n",
    "        pd.concat([digitaa_data['v_p'], digitaa_data['v_n']]),\n",
    "        np.concatenate([np.ones((digitaa_data['v_p'].shape[0], )), np.zeros((digitaa_data['v_n'].shape[0], ))]),\n",
    "    )\n",
    ").get_summary(\n",
    "    path_to_dir=\"out/libfeatureselection/T1/T1SEstacker/\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RNN_model(seq_length: int, sizeof_ac_dict: int):\n",
    "    input1 = tf.keras.layers.Input(shape=(seq_length,), name='Input_Layer')\n",
    "    embedding1 = tf.keras.layers.Embedding(\n",
    "        input_dim=sizeof_ac_dict, output_dim=sizeof_ac_dict, name=\"AC_EMBEDED\")(input1)\n",
    "\n",
    "    conv1 = tf.keras.layers.LSTM(10)(embedding1)\n",
    "\n",
    "    flatten_layer = tf.keras.layers.Flatten()(conv1)\n",
    "\n",
    "    dense3 = tf.keras.layers.Dense(\n",
    "        1, activation=tf.keras.activations.sigmoid)(flatten_layer)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=input1, outputs=dense3, name='simple_WithRNN')\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "        loss=tf.keras.losses.binary_crossentropy,\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(),\n",
    "            tf.keras.metrics.AUC(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.TruePositives(),\n",
    "            tf.keras.metrics.TrueNegatives(),\n",
    "            tf.keras.metrics.FalsePositives(),\n",
    "            tf.keras.metrics.FalseNegatives()\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "class RNN_Trainer:\n",
    "    def __init__(self, ) -> None:\n",
    "        self.classifier_name = \"RNN\"\n",
    "        self.classifier_class = get_RNN_model\n",
    "        self.classifier_param_dict = {\n",
    "            \"seq_length\": 60,\n",
    "            \"sizeof_ac_dict\": 20\n",
    "        }\n",
    "\n",
    "        self.model = None\n",
    "        self.train_best_predicted_pair = None\n",
    "        self.train_best_5C_predicted_pair = None\n",
    "        self.best_predicted_pair = None\n",
    "        self.best_5C_predicted_pair = None\n",
    "        self.start_to_train_time = datetime.now()\n",
    "        self.end_of_train_time = None\n",
    "        pass\n",
    "\n",
    "    def find_best(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        validation: tuple,\n",
    "    ):\n",
    "\n",
    "        self.model = self.classifier_class(\n",
    "            **self.classifier_param_dict\n",
    "        )\n",
    "        self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            epochs=10,\n",
    "            use_multiprocessing=True,\n",
    "            steps_per_epoch=None,\n",
    "            verbose=2\n",
    "        )\n",
    "        self.best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                validation[0]\n",
    "            ), nan=0.0),\n",
    "            validation[1]\n",
    "        ]\n",
    "        self.train_best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                X\n",
    "            ), nan=0.0),\n",
    "            y\n",
    "        ]\n",
    "\n",
    "        # 5倍交叉验证\n",
    "        # 合并数据\n",
    "        full_X = np.concatenate([\n",
    "            X, validation[0]\n",
    "        ])\n",
    "        full_y = np.concatenate([\n",
    "            y, validation[1]\n",
    "        ])\n",
    "\n",
    "        # 跑模型\n",
    "        self.best_5C_predicted_pair = []\n",
    "        self.train_best_5C_predicted_pair = []\n",
    "        for Kfold_id, (train_id, test_id) in enumerate(\n",
    "            StratifiedKFold(\n",
    "                n_splits=5,\n",
    "                shuffle=True,\n",
    "                random_state=42\n",
    "            ).split(full_X, full_y)\n",
    "        ):\n",
    "\n",
    "            # 定义模型并加载参数\n",
    "            fiveC_model = self.classifier_class(\n",
    "                **self.classifier_param_dict,\n",
    "            )\n",
    "\n",
    "            fiveC_model.fit(\n",
    "                full_X[train_id],\n",
    "                full_y[train_id],\n",
    "                epochs=10,\n",
    "                use_multiprocessing=True,\n",
    "                steps_per_epoch=None,\n",
    "                verbose=2\n",
    "            )\n",
    "\n",
    "            # 预测并记录\n",
    "            self.best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    full_X[test_id]\n",
    "                ), nan=0.0),\n",
    "                full_y[test_id]\n",
    "            ])\n",
    "            self.train_best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    full_X[train_id]\n",
    "                ), nan=0.0),\n",
    "                full_y[train_id]\n",
    "            ])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_summary(self, path_to_dir: str = None):\n",
    "        os.makedirs(path_to_dir, exist_ok=True)\n",
    "        model_path = \"-\"\n",
    "        if \"SAVE_MODEL\" in os.environ and os.environ['SAVE_MODEL'] == \"1\":\n",
    "\n",
    "            model_path = f\"{path_to_dir}/{self.classifier_name}.pkl\"\n",
    "            if path_to_dir is not None:\n",
    "                with gzip.open(model_path, \"wb\") as f:\n",
    "                    pickle.dump(\n",
    "                        self.grid_search, f\n",
    "                    )\n",
    "\n",
    "        model_score_path = f\"{path_to_dir}/{self.classifier_name}_score.pkl\"\n",
    "        if path_to_dir is not None:\n",
    "            with gzip.open(model_score_path, \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "            with gzip.open(model_score_path + \".train\", \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.train_best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.train_best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "        else:\n",
    "            model_score_path = \"-\"\n",
    "\n",
    "        plot_roc_curve(\n",
    "            target=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "            path_to_=f\"{path_to_dir}/{self.classifier_name}.pdf\"\n",
    "        )\n",
    "\n",
    "        model_information = {\n",
    "            \"Classifier_Name\": self.classifier_name,\n",
    "            \"Optimitied_Param\": dict(),\n",
    "            \"Score\": model_score_path,\n",
    "            \"Model_Path\": model_path,\n",
    "            \"TimeToStartFit\": self.start_to_train_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "\n",
    "        training_testing_performance = get_evaluation(\n",
    "            label=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "        )\n",
    "\n",
    "        # 计算5C中的平均表现\n",
    "        FiveFold_result = {}\n",
    "        for keys in training_testing_performance.keys():\n",
    "            value_list = []\n",
    "            for item in self.best_5C_predicted_pair:\n",
    "\n",
    "                item_performance = get_evaluation(\n",
    "                    label=item[1],\n",
    "                    pred=item[0],\n",
    "                )\n",
    "                value_list.append(item_performance[keys])\n",
    "\n",
    "            if keys == \"pro_cutoff\":\n",
    "                FiveFold_result[keys] = value_list\n",
    "            else:\n",
    "                FiveFold_result[keys] = sum(value_list) / len(value_list)\n",
    "\n",
    "        self.end_of_train_time = datetime.now()\n",
    "        model_information[\"TimeOfSummary\"] = self.end_of_train_time.strftime(\n",
    "            \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "        model_information[\"TimeSpend\"] = str(\n",
    "            self.end_of_train_time - self.start_to_train_time\n",
    "        )\n",
    "\n",
    "        return model_information, training_testing_performance, FiveFold_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 - 6s - loss: 0.6926 - binary_accuracy: 0.5345 - auc_8: 0.5499 - precision_8: 0.5217 - true_positives_8: 24.0000 - true_negatives_8: 7.0000 - false_positives_8: 22.0000 - false_negatives_8: 5.0000 - 6s/epoch - 3s/step\n",
      "Epoch 2/10\n",
      "2/2 - 0s - loss: 0.6836 - binary_accuracy: 0.6207 - auc_8: 0.7176 - precision_8: 0.6000 - true_positives_8: 21.0000 - true_negatives_8: 15.0000 - false_positives_8: 14.0000 - false_negatives_8: 8.0000 - 58ms/epoch - 29ms/step\n",
      "Epoch 3/10\n",
      "2/2 - 0s - loss: 0.6692 - binary_accuracy: 0.7414 - auc_8: 0.8074 - precision_8: 0.7692 - true_positives_8: 20.0000 - true_negatives_8: 23.0000 - false_positives_8: 6.0000 - false_negatives_8: 9.0000 - 79ms/epoch - 40ms/step\n",
      "Epoch 4/10\n",
      "2/2 - 0s - loss: 0.6547 - binary_accuracy: 0.7241 - auc_8: 0.8050 - precision_8: 0.7826 - true_positives_8: 18.0000 - true_negatives_8: 24.0000 - false_positives_8: 5.0000 - false_negatives_8: 11.0000 - 58ms/epoch - 29ms/step\n",
      "Epoch 5/10\n",
      "2/2 - 0s - loss: 0.6313 - binary_accuracy: 0.7586 - auc_8: 0.8157 - precision_8: 0.8000 - true_positives_8: 20.0000 - true_negatives_8: 24.0000 - false_positives_8: 5.0000 - false_negatives_8: 9.0000 - 77ms/epoch - 39ms/step\n",
      "Epoch 6/10\n",
      "2/2 - 0s - loss: 0.6009 - binary_accuracy: 0.7414 - auc_8: 0.8282 - precision_8: 0.7500 - true_positives_8: 21.0000 - true_negatives_8: 22.0000 - false_positives_8: 7.0000 - false_negatives_8: 8.0000 - 53ms/epoch - 27ms/step\n",
      "Epoch 7/10\n",
      "2/2 - 0s - loss: 0.5659 - binary_accuracy: 0.7414 - auc_8: 0.8413 - precision_8: 0.7500 - true_positives_8: 21.0000 - true_negatives_8: 22.0000 - false_positives_8: 7.0000 - false_negatives_8: 8.0000 - 55ms/epoch - 27ms/step\n",
      "Epoch 8/10\n",
      "2/2 - 0s - loss: 0.5365 - binary_accuracy: 0.7414 - auc_8: 0.8341 - precision_8: 0.7500 - true_positives_8: 21.0000 - true_negatives_8: 22.0000 - false_positives_8: 7.0000 - false_negatives_8: 8.0000 - 59ms/epoch - 29ms/step\n",
      "Epoch 9/10\n",
      "2/2 - 0s - loss: 0.4999 - binary_accuracy: 0.7414 - auc_8: 0.8490 - precision_8: 0.7333 - true_positives_8: 22.0000 - true_negatives_8: 21.0000 - false_positives_8: 8.0000 - false_negatives_8: 7.0000 - 82ms/epoch - 41ms/step\n",
      "Epoch 10/10\n",
      "2/2 - 0s - loss: 0.4386 - binary_accuracy: 0.7759 - auc_8: 0.8841 - precision_8: 0.7857 - true_positives_8: 22.0000 - true_negatives_8: 23.0000 - false_positives_8: 6.0000 - false_negatives_8: 7.0000 - 60ms/epoch - 30ms/step\n",
      "2/2 [==============================] - 1s 14ms/step\n",
      "2/2 [==============================] - 1s 17ms/step\n",
      "Epoch 1/10\n",
      "3/3 - 6s - loss: 0.6935 - binary_accuracy: 0.4487 - auc_9: 0.5049 - precision_9: 0.4167 - true_positives_9: 10.0000 - true_negatives_9: 25.0000 - false_positives_9: 14.0000 - false_negatives_9: 29.0000 - 6s/epoch - 2s/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.6744 - binary_accuracy: 0.6410 - auc_9: 0.7913 - precision_9: 0.7619 - true_positives_9: 16.0000 - true_negatives_9: 34.0000 - false_positives_9: 5.0000 - false_negatives_9: 23.0000 - 131ms/epoch - 44ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.6522 - binary_accuracy: 0.7564 - auc_9: 0.8439 - precision_9: 0.6852 - true_positives_9: 37.0000 - true_negatives_9: 22.0000 - false_positives_9: 17.0000 - false_negatives_9: 2.0000 - 81ms/epoch - 27ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.6120 - binary_accuracy: 0.8077 - auc_9: 0.8836 - precision_9: 0.7500 - true_positives_9: 36.0000 - true_negatives_9: 27.0000 - false_positives_9: 12.0000 - false_negatives_9: 3.0000 - 116ms/epoch - 39ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.5574 - binary_accuracy: 0.8205 - auc_9: 0.8830 - precision_9: 0.8571 - true_positives_9: 30.0000 - true_negatives_9: 34.0000 - false_positives_9: 5.0000 - false_negatives_9: 9.0000 - 77ms/epoch - 26ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.4804 - binary_accuracy: 0.8077 - auc_9: 0.8988 - precision_9: 0.8333 - true_positives_9: 30.0000 - true_negatives_9: 33.0000 - false_positives_9: 6.0000 - false_negatives_9: 9.0000 - 60ms/epoch - 20ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.4490 - binary_accuracy: 0.7949 - auc_9: 0.8902 - precision_9: 0.7447 - true_positives_9: 35.0000 - true_negatives_9: 27.0000 - false_positives_9: 12.0000 - false_negatives_9: 4.0000 - 85ms/epoch - 28ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.4332 - binary_accuracy: 0.8077 - auc_9: 0.8915 - precision_9: 0.8000 - true_positives_9: 32.0000 - true_negatives_9: 31.0000 - false_positives_9: 8.0000 - false_negatives_9: 7.0000 - 123ms/epoch - 41ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.4176 - binary_accuracy: 0.7949 - auc_9: 0.9027 - precision_9: 0.7805 - true_positives_9: 32.0000 - true_negatives_9: 30.0000 - false_positives_9: 9.0000 - false_negatives_9: 7.0000 - 89ms/epoch - 30ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.4091 - binary_accuracy: 0.8205 - auc_9: 0.9204 - precision_9: 0.7778 - true_positives_9: 35.0000 - true_negatives_9: 29.0000 - false_positives_9: 10.0000 - false_negatives_9: 4.0000 - 87ms/epoch - 29ms/step\n",
      "1/1 [==============================] - 1s 769ms/step\n",
      "3/3 [==============================] - 0s 11ms/step\n",
      "Epoch 1/10\n",
      "3/3 - 9s - loss: 0.6947 - binary_accuracy: 0.4359 - auc_10: 0.4458 - precision_10: 0.3913 - true_positives_10: 9.0000 - true_negatives_10: 25.0000 - false_positives_10: 14.0000 - false_negatives_10: 30.0000 - 9s/epoch - 3s/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.6774 - binary_accuracy: 0.6538 - auc_10: 0.8840 - precision_10: 0.8750 - true_positives_10: 14.0000 - true_negatives_10: 37.0000 - false_positives_10: 2.0000 - false_negatives_10: 25.0000 - 90ms/epoch - 30ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.6560 - binary_accuracy: 0.8205 - auc_10: 0.8794 - precision_10: 0.7451 - true_positives_10: 38.0000 - true_negatives_10: 26.0000 - false_positives_10: 13.0000 - false_negatives_10: 1.0000 - 99ms/epoch - 33ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.6166 - binary_accuracy: 0.8077 - auc_10: 0.9106 - precision_10: 0.7308 - true_positives_10: 38.0000 - true_negatives_10: 25.0000 - false_positives_10: 14.0000 - false_negatives_10: 1.0000 - 90ms/epoch - 30ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.5496 - binary_accuracy: 0.8333 - auc_10: 0.9149 - precision_10: 0.7955 - true_positives_10: 35.0000 - true_negatives_10: 30.0000 - false_positives_10: 9.0000 - false_negatives_10: 4.0000 - 107ms/epoch - 36ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.4569 - binary_accuracy: 0.7949 - auc_10: 0.9244 - precision_10: 0.7949 - true_positives_10: 31.0000 - true_negatives_10: 31.0000 - false_positives_10: 8.0000 - false_negatives_10: 8.0000 - 75ms/epoch - 25ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.3868 - binary_accuracy: 0.8205 - auc_10: 0.9237 - precision_10: 0.8049 - true_positives_10: 33.0000 - true_negatives_10: 31.0000 - false_positives_10: 8.0000 - false_negatives_10: 6.0000 - 79ms/epoch - 26ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.3430 - binary_accuracy: 0.8333 - auc_10: 0.9471 - precision_10: 0.9333 - true_positives_10: 28.0000 - true_negatives_10: 37.0000 - false_positives_10: 2.0000 - false_negatives_10: 11.0000 - 141ms/epoch - 47ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.3021 - binary_accuracy: 0.8718 - auc_10: 0.9543 - precision_10: 0.9143 - true_positives_10: 32.0000 - true_negatives_10: 36.0000 - false_positives_10: 3.0000 - false_negatives_10: 7.0000 - 107ms/epoch - 36ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.2609 - binary_accuracy: 0.8718 - auc_10: 0.9658 - precision_10: 0.8919 - true_positives_10: 33.0000 - true_negatives_10: 35.0000 - false_positives_10: 4.0000 - false_negatives_10: 6.0000 - 97ms/epoch - 32ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3/3 [==============================] - 0s 18ms/step\n",
      "Epoch 1/10\n",
      "3/3 - 6s - loss: 0.6968 - binary_accuracy: 0.3974 - auc_11: 0.4241 - precision_11: 0.3000 - true_positives_11: 6.0000 - true_negatives_11: 25.0000 - false_positives_11: 14.0000 - false_negatives_11: 33.0000 - 6s/epoch - 2s/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.6796 - binary_accuracy: 0.6410 - auc_11: 0.8044 - precision_11: 0.7895 - true_positives_11: 15.0000 - true_negatives_11: 35.0000 - false_positives_11: 4.0000 - false_negatives_11: 24.0000 - 87ms/epoch - 29ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.6610 - binary_accuracy: 0.7308 - auc_11: 0.8268 - precision_11: 0.7368 - true_positives_11: 28.0000 - true_negatives_11: 29.0000 - false_positives_11: 10.0000 - false_negatives_11: 11.0000 - 110ms/epoch - 37ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.6321 - binary_accuracy: 0.7436 - auc_11: 0.8448 - precision_11: 0.7714 - true_positives_11: 27.0000 - true_negatives_11: 31.0000 - false_positives_11: 8.0000 - false_negatives_11: 12.0000 - 100ms/epoch - 33ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.5780 - binary_accuracy: 0.7692 - auc_11: 0.8672 - precision_11: 0.8182 - true_positives_11: 27.0000 - true_negatives_11: 33.0000 - false_positives_11: 6.0000 - false_negatives_11: 12.0000 - 92ms/epoch - 31ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.4935 - binary_accuracy: 0.7949 - auc_11: 0.8915 - precision_11: 0.8286 - true_positives_11: 29.0000 - true_negatives_11: 33.0000 - false_positives_11: 6.0000 - false_negatives_11: 10.0000 - 87ms/epoch - 29ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.4368 - binary_accuracy: 0.8333 - auc_11: 0.8994 - precision_11: 0.7955 - true_positives_11: 35.0000 - true_negatives_11: 30.0000 - false_positives_11: 9.0000 - false_negatives_11: 4.0000 - 124ms/epoch - 41ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.4102 - binary_accuracy: 0.8462 - auc_11: 0.9083 - precision_11: 0.7755 - true_positives_11: 38.0000 - true_negatives_11: 28.0000 - false_positives_11: 11.0000 - false_negatives_11: 1.0000 - 82ms/epoch - 27ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.3634 - binary_accuracy: 0.8462 - auc_11: 0.9306 - precision_11: 0.7872 - true_positives_11: 37.0000 - true_negatives_11: 29.0000 - false_positives_11: 10.0000 - false_negatives_11: 2.0000 - 141ms/epoch - 47ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.4473 - binary_accuracy: 0.8462 - auc_11: 0.9471 - precision_11: 1.0000 - true_positives_11: 27.0000 - true_negatives_11: 39.0000 - false_positives_11: 0.0000e+00 - false_negatives_11: 12.0000 - 75ms/epoch - 25ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3/3 [==============================] - 0s 11ms/step\n",
      "Epoch 1/10\n",
      "3/3 - 5s - loss: 0.6925 - binary_accuracy: 0.5190 - auc_12: 0.5179 - precision_12: 0.5385 - true_positives_12: 7.0000 - true_negatives_12: 34.0000 - false_positives_12: 6.0000 - false_negatives_12: 32.0000 - 5s/epoch - 2s/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.6765 - binary_accuracy: 0.6076 - auc_12: 0.8208 - precision_12: 0.9000 - true_positives_12: 9.0000 - true_negatives_12: 39.0000 - false_positives_12: 1.0000 - false_negatives_12: 30.0000 - 90ms/epoch - 30ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.6466 - binary_accuracy: 0.7342 - auc_12: 0.8817 - precision_12: 0.9091 - true_positives_12: 20.0000 - true_negatives_12: 38.0000 - false_positives_12: 2.0000 - false_negatives_12: 19.0000 - 130ms/epoch - 43ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.5807 - binary_accuracy: 0.8101 - auc_12: 0.8885 - precision_12: 0.9286 - true_positives_12: 26.0000 - true_negatives_12: 38.0000 - false_positives_12: 2.0000 - false_negatives_12: 13.0000 - 93ms/epoch - 31ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.4861 - binary_accuracy: 0.8228 - auc_12: 0.9224 - precision_12: 0.9630 - true_positives_12: 26.0000 - true_negatives_12: 39.0000 - false_positives_12: 1.0000 - false_negatives_12: 13.0000 - 75ms/epoch - 25ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.4385 - binary_accuracy: 0.8228 - auc_12: 0.9385 - precision_12: 0.9310 - true_positives_12: 27.0000 - true_negatives_12: 38.0000 - false_positives_12: 2.0000 - false_negatives_12: 12.0000 - 68ms/epoch - 23ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.4839 - binary_accuracy: 0.7342 - auc_12: 0.9263 - precision_12: 0.6552 - true_positives_12: 38.0000 - true_negatives_12: 20.0000 - false_positives_12: 20.0000 - false_negatives_12: 1.0000 - 114ms/epoch - 38ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.4977 - binary_accuracy: 0.7342 - auc_12: 0.9266 - precision_12: 0.6552 - true_positives_12: 38.0000 - true_negatives_12: 20.0000 - false_positives_12: 20.0000 - false_negatives_12: 1.0000 - 83ms/epoch - 28ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.3759 - binary_accuracy: 0.8101 - auc_12: 0.9349 - precision_12: 0.7727 - true_positives_12: 34.0000 - true_negatives_12: 30.0000 - false_positives_12: 10.0000 - false_negatives_12: 5.0000 - 87ms/epoch - 29ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.3840 - binary_accuracy: 0.8734 - auc_12: 0.9548 - precision_12: 0.9677 - true_positives_12: 30.0000 - true_negatives_12: 39.0000 - false_positives_12: 1.0000 - false_negatives_12: 9.0000 - 83ms/epoch - 28ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "Epoch 1/10\n",
      "3/3 - 9s - loss: 0.6949 - binary_accuracy: 0.4810 - auc_13: 0.4657 - precision_13: 0.4800 - true_positives_13: 12.0000 - true_negatives_13: 26.0000 - false_positives_13: 13.0000 - false_negatives_13: 28.0000 - 9s/epoch - 3s/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.6800 - binary_accuracy: 0.6835 - auc_13: 0.7936 - precision_13: 0.7273 - true_positives_13: 24.0000 - true_negatives_13: 30.0000 - false_positives_13: 9.0000 - false_negatives_13: 16.0000 - 132ms/epoch - 44ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.6578 - binary_accuracy: 0.7342 - auc_13: 0.8256 - precision_13: 0.6863 - true_positives_13: 35.0000 - true_negatives_13: 23.0000 - false_positives_13: 16.0000 - false_negatives_13: 5.0000 - 84ms/epoch - 28ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.6100 - binary_accuracy: 0.7215 - auc_13: 0.8548 - precision_13: 0.6552 - true_positives_13: 38.0000 - true_negatives_13: 19.0000 - false_positives_13: 20.0000 - false_negatives_13: 2.0000 - 86ms/epoch - 29ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.5320 - binary_accuracy: 0.7468 - auc_13: 0.8760 - precision_13: 0.7000 - true_positives_13: 35.0000 - true_negatives_13: 24.0000 - false_positives_13: 15.0000 - false_negatives_13: 5.0000 - 135ms/epoch - 45ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.4525 - binary_accuracy: 0.7975 - auc_13: 0.9074 - precision_13: 0.7727 - true_positives_13: 34.0000 - true_negatives_13: 29.0000 - false_positives_13: 10.0000 - false_negatives_13: 6.0000 - 76ms/epoch - 25ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.4226 - binary_accuracy: 0.8228 - auc_13: 0.9218 - precision_13: 0.9643 - true_positives_13: 27.0000 - true_negatives_13: 38.0000 - false_positives_13: 1.0000 - false_negatives_13: 13.0000 - 92ms/epoch - 31ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.3695 - binary_accuracy: 0.8734 - auc_13: 0.9353 - precision_13: 0.9688 - true_positives_13: 31.0000 - true_negatives_13: 38.0000 - false_positives_13: 1.0000 - false_negatives_13: 9.0000 - 134ms/epoch - 45ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.3585 - binary_accuracy: 0.8228 - auc_13: 0.9359 - precision_13: 0.8095 - true_positives_13: 34.0000 - true_negatives_13: 31.0000 - false_positives_13: 8.0000 - false_negatives_13: 6.0000 - 84ms/epoch - 28ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.2940 - binary_accuracy: 0.8987 - auc_13: 0.9385 - precision_13: 0.9706 - true_positives_13: 33.0000 - true_negatives_13: 38.0000 - false_positives_13: 1.0000 - false_negatives_13: 7.0000 - 111ms/epoch - 37ms/step\n",
      "1/1 [==============================] - 1s 902ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Classifier_Name': 'RNN',\n",
       "  'Optimitied_Param': {},\n",
       "  'Score': 'out/libfeatureselection/T1/T1SEstacker//RNN_score.pkl',\n",
       "  'Model_Path': '-',\n",
       "  'TimeToStartFit': '2023-07-22 02:00:41',\n",
       "  'TimeOfSummary': '2023-07-22 02:01:39',\n",
       "  'TimeSpend': '0:00:58.179623'},\n",
       " {'accuracy': 0.9,\n",
       "  'precision': 0.8636363636363636,\n",
       "  'f1_score': 0.9047619047619048,\n",
       "  'mmc': 0.8040302522073697,\n",
       "  'rocAUC': 0.9175,\n",
       "  'specificity': 0.85,\n",
       "  'sensitivity': 0.95,\n",
       "  'pro_cutoff': 0.26376325},\n",
       " {'accuracy': 0.7957894736842107,\n",
       "  'precision': 0.8446608946608947,\n",
       "  'f1_score': 0.7832338868561779,\n",
       "  'mmc': 0.6160175846432445,\n",
       "  'rocAUC': 0.8157777777777777,\n",
       "  'specificity': 0.8400000000000001,\n",
       "  'sensitivity': 0.7577777777777778,\n",
       "  'pro_cutoff': [0.73248637, 0.7321351, 0.43136856, 0.6674508, 0.15559557]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RNN_Trainer().find_best(\n",
    "    X=pd.concat([digitaa_data['t_p'], digitaa_data['t_n']]),\n",
    "    y=np.concatenate([np.ones((digitaa_data['t_p'].shape[0], )), np.zeros((digitaa_data['t_n'].shape[0], ))]),\n",
    "    validation=(\n",
    "        pd.concat([digitaa_data['v_p'], digitaa_data['v_n']]),\n",
    "        np.concatenate([np.ones((digitaa_data['v_p'].shape[0], )), np.zeros((digitaa_data['v_n'].shape[0], ))]),\n",
    "    )\n",
    ").get_summary(\n",
    "    path_to_dir=\"out/libfeatureselection/T1/T1SEstacker/\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SA_model(seq_length: int, sizeof_ac_dict: int):\n",
    "    input1 = tf.keras.layers.Input(shape=(seq_length,), name='Input_Layer')\n",
    "    embedding1 = tf.keras.layers.Embedding(\n",
    "        input_dim=sizeof_ac_dict, output_dim=sizeof_ac_dict, name=\"AC_EMBEDED\")(input1)\n",
    "    flatten_layer = tf.keras.layers.Flatten()(embedding1)\n",
    "    Q = tf.keras.layers.Dense(\n",
    "        20, activation=tf.keras.activations.sigmoid)(flatten_layer)\n",
    "    K = tf.keras.layers.Dense(\n",
    "        20, activation=tf.keras.activations.sigmoid)(flatten_layer)\n",
    "    V = tf.keras.layers.Dense(\n",
    "        20, activation=tf.keras.activations.sigmoid)(flatten_layer)\n",
    "\n",
    "    Attention = tf.keras.layers.Multiply()([Q, K])\n",
    "    softmax_Attention = tf.keras.activations.softmax(Attention)\n",
    "    Self_Attention = tf.keras.layers.Multiply()([V, softmax_Attention])\n",
    "\n",
    "    d = tf.keras.layers.Dense(\n",
    "        1, activation=tf.keras.activations.sigmoid)(Self_Attention)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=input1, outputs=d, name='SelfAttantion')\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "        loss=tf.keras.losses.binary_crossentropy,\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(),\n",
    "            tf.keras.metrics.AUC(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.TruePositives(),\n",
    "            tf.keras.metrics.TrueNegatives(),\n",
    "            tf.keras.metrics.FalsePositives(),\n",
    "            tf.keras.metrics.FalseNegatives()\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "class SA_Trainer:\n",
    "    def __init__(self, ) -> None:\n",
    "        self.classifier_name = \"SA\"\n",
    "        self.classifier_class = get_SA_model\n",
    "        self.classifier_param_dict = {\n",
    "            \"seq_length\": 60,\n",
    "            \"sizeof_ac_dict\": 20\n",
    "        }\n",
    "\n",
    "        self.model = None\n",
    "        self.train_best_predicted_pair = None\n",
    "        self.train_best_5C_predicted_pair = None\n",
    "        self.best_predicted_pair = None\n",
    "        self.best_5C_predicted_pair = None\n",
    "        self.start_to_train_time = datetime.now()\n",
    "        self.end_of_train_time = None\n",
    "        pass\n",
    "\n",
    "    def find_best(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        validation: tuple,\n",
    "    ):\n",
    "\n",
    "        self.model = self.classifier_class(\n",
    "            **self.classifier_param_dict\n",
    "        )\n",
    "        self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            epochs=10,\n",
    "            use_multiprocessing=True,\n",
    "            steps_per_epoch=None,\n",
    "            verbose=2\n",
    "        )\n",
    "        self.best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                validation[0]\n",
    "            ), nan=0.0),\n",
    "            validation[1]\n",
    "        ]\n",
    "        self.train_best_predicted_pair = [\n",
    "            np.nan_to_num(self.model.predict(\n",
    "                X\n",
    "            ), nan=0.0),\n",
    "            y\n",
    "        ]\n",
    "\n",
    "        # 5倍交叉验证\n",
    "        # 合并数据\n",
    "        full_X = np.concatenate([\n",
    "            X, validation[0]\n",
    "        ])\n",
    "        full_y = np.concatenate([\n",
    "            y, validation[1]\n",
    "        ])\n",
    "\n",
    "        # 跑模型\n",
    "        self.best_5C_predicted_pair = []\n",
    "        self.train_best_5C_predicted_pair = []\n",
    "        for Kfold_id, (train_id, test_id) in enumerate(\n",
    "            StratifiedKFold(\n",
    "                n_splits=5,\n",
    "                shuffle=True,\n",
    "                random_state=42\n",
    "            ).split(full_X, full_y)\n",
    "        ):\n",
    "\n",
    "            # 定义模型并加载参数\n",
    "            fiveC_model = self.classifier_class(\n",
    "                **self.classifier_param_dict,\n",
    "            )\n",
    "\n",
    "            fiveC_model.fit(\n",
    "                full_X[train_id],\n",
    "                full_y[train_id],\n",
    "                epochs=10,\n",
    "                use_multiprocessing=True,\n",
    "                steps_per_epoch=None,\n",
    "                verbose=2\n",
    "            )\n",
    "\n",
    "            # 预测并记录\n",
    "            self.best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    full_X[test_id]\n",
    "                ), nan=0.0),\n",
    "                full_y[test_id]\n",
    "            ])\n",
    "            self.train_best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict(\n",
    "                    full_X[train_id]\n",
    "                ), nan=0.0),\n",
    "                full_y[train_id]\n",
    "            ])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_summary(self, path_to_dir: str = None):\n",
    "        os.makedirs(path_to_dir, exist_ok=True)\n",
    "        model_path = \"-\"\n",
    "        if \"SAVE_MODEL\" in os.environ and os.environ['SAVE_MODEL'] == \"1\":\n",
    "\n",
    "            model_path = f\"{path_to_dir}/{self.classifier_name}.pkl\"\n",
    "            if path_to_dir is not None:\n",
    "                with gzip.open(model_path, \"wb\") as f:\n",
    "                    pickle.dump(\n",
    "                        self.grid_search, f\n",
    "                    )\n",
    "\n",
    "        model_score_path = f\"{path_to_dir}/{self.classifier_name}_score.pkl\"\n",
    "        if path_to_dir is not None:\n",
    "            with gzip.open(model_score_path, \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "            with gzip.open(model_score_path + \".train\", \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"best_predicted_pair\": self.train_best_predicted_pair,\n",
    "                        \"best_5C_predicted_pair\": self.train_best_5C_predicted_pair,\n",
    "                    }, f\n",
    "                )\n",
    "        else:\n",
    "            model_score_path = \"-\"\n",
    "\n",
    "        plot_roc_curve(\n",
    "            target=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "            path_to_=f\"{path_to_dir}/{self.classifier_name}.pdf\"\n",
    "        )\n",
    "\n",
    "        model_information = {\n",
    "            \"Classifier_Name\": self.classifier_name,\n",
    "            \"Optimitied_Param\": dict(),\n",
    "            \"Score\": model_score_path,\n",
    "            \"Model_Path\": model_path,\n",
    "            \"TimeToStartFit\": self.start_to_train_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "\n",
    "        training_testing_performance = get_evaluation(\n",
    "            label=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0],\n",
    "        )\n",
    "\n",
    "        # 计算5C中的平均表现\n",
    "        FiveFold_result = {}\n",
    "        for keys in training_testing_performance.keys():\n",
    "            value_list = []\n",
    "            for item in self.best_5C_predicted_pair:\n",
    "\n",
    "                item_performance = get_evaluation(\n",
    "                    label=item[1],\n",
    "                    pred=item[0],\n",
    "                )\n",
    "                value_list.append(item_performance[keys])\n",
    "\n",
    "            if keys == \"pro_cutoff\":\n",
    "                FiveFold_result[keys] = value_list\n",
    "            else:\n",
    "                FiveFold_result[keys] = sum(value_list) / len(value_list)\n",
    "\n",
    "        self.end_of_train_time = datetime.now()\n",
    "        model_information[\"TimeOfSummary\"] = self.end_of_train_time.strftime(\n",
    "            \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "        model_information[\"TimeSpend\"] = str(\n",
    "            self.end_of_train_time - self.start_to_train_time\n",
    "        )\n",
    "\n",
    "        return model_information, training_testing_performance, FiveFold_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 - 2s - loss: 0.6941 - binary_accuracy: 0.5000 - auc_14: 0.4483 - precision_14: 0.5000 - true_positives_14: 29.0000 - true_negatives_14: 0.0000e+00 - false_positives_14: 29.0000 - false_negatives_14: 0.0000e+00 - 2s/epoch - 1s/step\n",
      "Epoch 2/10\n",
      "2/2 - 0s - loss: 0.6904 - binary_accuracy: 0.5000 - auc_14: 0.6504 - precision_14: 0.5000 - true_positives_14: 29.0000 - true_negatives_14: 0.0000e+00 - false_positives_14: 29.0000 - false_negatives_14: 0.0000e+00 - 8ms/epoch - 4ms/step\n",
      "Epoch 3/10\n",
      "2/2 - 0s - loss: 0.6854 - binary_accuracy: 0.5000 - auc_14: 0.9887 - precision_14: 0.5000 - true_positives_14: 29.0000 - true_negatives_14: 0.0000e+00 - false_positives_14: 29.0000 - false_negatives_14: 0.0000e+00 - 15ms/epoch - 7ms/step\n",
      "Epoch 4/10\n",
      "2/2 - 0s - loss: 0.6769 - binary_accuracy: 0.6552 - auc_14: 1.0000 - precision_14: 0.5918 - true_positives_14: 29.0000 - true_negatives_14: 9.0000 - false_positives_14: 20.0000 - false_negatives_14: 0.0000e+00 - 17ms/epoch - 9ms/step\n",
      "Epoch 5/10\n",
      "2/2 - 0s - loss: 0.6642 - binary_accuracy: 0.9138 - auc_14: 1.0000 - precision_14: 0.8529 - true_positives_14: 29.0000 - true_negatives_14: 24.0000 - false_positives_14: 5.0000 - false_negatives_14: 0.0000e+00 - 14ms/epoch - 7ms/step\n",
      "Epoch 6/10\n",
      "2/2 - 0s - loss: 0.6476 - binary_accuracy: 1.0000 - auc_14: 1.0000 - precision_14: 1.0000 - true_positives_14: 29.0000 - true_negatives_14: 29.0000 - false_positives_14: 0.0000e+00 - false_negatives_14: 0.0000e+00 - 19ms/epoch - 9ms/step\n",
      "Epoch 7/10\n",
      "2/2 - 0s - loss: 0.6282 - binary_accuracy: 1.0000 - auc_14: 1.0000 - precision_14: 1.0000 - true_positives_14: 29.0000 - true_negatives_14: 29.0000 - false_positives_14: 0.0000e+00 - false_negatives_14: 0.0000e+00 - 25ms/epoch - 12ms/step\n",
      "Epoch 8/10\n",
      "2/2 - 0s - loss: 0.6080 - binary_accuracy: 1.0000 - auc_14: 1.0000 - precision_14: 1.0000 - true_positives_14: 29.0000 - true_negatives_14: 29.0000 - false_positives_14: 0.0000e+00 - false_negatives_14: 0.0000e+00 - 17ms/epoch - 8ms/step\n",
      "Epoch 9/10\n",
      "2/2 - 0s - loss: 0.5898 - binary_accuracy: 1.0000 - auc_14: 1.0000 - precision_14: 1.0000 - true_positives_14: 29.0000 - true_negatives_14: 29.0000 - false_positives_14: 0.0000e+00 - false_negatives_14: 0.0000e+00 - 39ms/epoch - 19ms/step\n",
      "Epoch 10/10\n",
      "2/2 - 0s - loss: 0.5749 - binary_accuracy: 1.0000 - auc_14: 1.0000 - precision_14: 1.0000 - true_positives_14: 29.0000 - true_negatives_14: 29.0000 - false_positives_14: 0.0000e+00 - false_negatives_14: 0.0000e+00 - 22ms/epoch - 11ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 1/10\n",
      "3/3 - 3s - loss: 0.6940 - binary_accuracy: 0.5000 - auc_15: 0.4231 - precision_15: 0.5000 - true_positives_15: 39.0000 - true_negatives_15: 0.0000e+00 - false_positives_15: 39.0000 - false_negatives_15: 0.0000e+00 - 3s/epoch - 878ms/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.6896 - binary_accuracy: 0.5000 - auc_15: 0.7278 - precision_15: 0.5000 - true_positives_15: 39.0000 - true_negatives_15: 0.0000e+00 - false_positives_15: 39.0000 - false_negatives_15: 0.0000e+00 - 24ms/epoch - 8ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.6830 - binary_accuracy: 0.5513 - auc_15: 0.9862 - precision_15: 0.5270 - true_positives_15: 39.0000 - true_negatives_15: 4.0000 - false_positives_15: 35.0000 - false_negatives_15: 0.0000e+00 - 29ms/epoch - 10ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.6702 - binary_accuracy: 0.7308 - auc_15: 0.9997 - precision_15: 0.6500 - true_positives_15: 39.0000 - true_negatives_15: 18.0000 - false_positives_15: 21.0000 - false_negatives_15: 0.0000e+00 - 13ms/epoch - 4ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.6520 - binary_accuracy: 0.8846 - auc_15: 0.9990 - precision_15: 0.8125 - true_positives_15: 39.0000 - true_negatives_15: 30.0000 - false_positives_15: 9.0000 - false_negatives_15: 0.0000e+00 - 27ms/epoch - 9ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.6298 - binary_accuracy: 0.9615 - auc_15: 0.9970 - precision_15: 0.9500 - true_positives_15: 38.0000 - true_negatives_15: 37.0000 - false_positives_15: 2.0000 - false_negatives_15: 1.0000 - 10ms/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.6071 - binary_accuracy: 0.9872 - auc_15: 0.9997 - precision_15: 1.0000 - true_positives_15: 38.0000 - true_negatives_15: 39.0000 - false_positives_15: 0.0000e+00 - false_negatives_15: 1.0000 - 26ms/epoch - 9ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.5873 - binary_accuracy: 0.9872 - auc_15: 1.0000 - precision_15: 1.0000 - true_positives_15: 38.0000 - true_negatives_15: 39.0000 - false_positives_15: 0.0000e+00 - false_negatives_15: 1.0000 - 10ms/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.5714 - binary_accuracy: 0.9872 - auc_15: 1.0000 - precision_15: 1.0000 - true_positives_15: 38.0000 - true_negatives_15: 39.0000 - false_positives_15: 0.0000e+00 - false_negatives_15: 1.0000 - 40ms/epoch - 13ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.5572 - binary_accuracy: 1.0000 - auc_15: 1.0000 - precision_15: 1.0000 - true_positives_15: 39.0000 - true_negatives_15: 39.0000 - false_positives_15: 0.0000e+00 - false_negatives_15: 0.0000e+00 - 25ms/epoch - 8ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "3/3 - 3s - loss: 0.6938 - binary_accuracy: 0.5000 - auc_16: 0.4560 - precision_16: 0.5000 - true_positives_16: 39.0000 - true_negatives_16: 0.0000e+00 - false_positives_16: 39.0000 - false_negatives_16: 0.0000e+00 - 3s/epoch - 881ms/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.6888 - binary_accuracy: 0.5513 - auc_16: 0.9783 - precision_16: 0.5270 - true_positives_16: 39.0000 - true_negatives_16: 4.0000 - false_positives_16: 35.0000 - false_negatives_16: 0.0000e+00 - 23ms/epoch - 8ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.6810 - binary_accuracy: 0.6667 - auc_16: 0.9961 - precision_16: 0.6000 - true_positives_16: 39.0000 - true_negatives_16: 13.0000 - false_positives_16: 26.0000 - false_negatives_16: 0.0000e+00 - 19ms/epoch - 6ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.6660 - binary_accuracy: 0.8974 - auc_16: 1.0000 - precision_16: 0.8298 - true_positives_16: 39.0000 - true_negatives_16: 31.0000 - false_positives_16: 8.0000 - false_negatives_16: 0.0000e+00 - 22ms/epoch - 7ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.6445 - binary_accuracy: 0.9615 - auc_16: 1.0000 - precision_16: 0.9286 - true_positives_16: 39.0000 - true_negatives_16: 36.0000 - false_positives_16: 3.0000 - false_negatives_16: 0.0000e+00 - 42ms/epoch - 14ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.6204 - binary_accuracy: 1.0000 - auc_16: 1.0000 - precision_16: 1.0000 - true_positives_16: 39.0000 - true_negatives_16: 39.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 0.0000e+00 - 46ms/epoch - 15ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.5972 - binary_accuracy: 1.0000 - auc_16: 1.0000 - precision_16: 1.0000 - true_positives_16: 39.0000 - true_negatives_16: 39.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 0.0000e+00 - 19ms/epoch - 6ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.5773 - binary_accuracy: 1.0000 - auc_16: 1.0000 - precision_16: 1.0000 - true_positives_16: 39.0000 - true_negatives_16: 39.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 0.0000e+00 - 14ms/epoch - 5ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.5603 - binary_accuracy: 1.0000 - auc_16: 1.0000 - precision_16: 1.0000 - true_positives_16: 39.0000 - true_negatives_16: 39.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 0.0000e+00 - 16ms/epoch - 5ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.5461 - binary_accuracy: 1.0000 - auc_16: 1.0000 - precision_16: 1.0000 - true_positives_16: 39.0000 - true_negatives_16: 39.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 0.0000e+00 - 15ms/epoch - 5ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "Epoch 1/10\n",
      "3/3 - 2s - loss: 0.6934 - binary_accuracy: 0.5000 - auc_17: 0.4744 - precision_17: 0.0000e+00 - true_positives_17: 0.0000e+00 - true_negatives_17: 39.0000 - false_positives_17: 0.0000e+00 - false_negatives_17: 39.0000 - 2s/epoch - 784ms/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.6883 - binary_accuracy: 0.5256 - auc_17: 0.8718 - precision_17: 1.0000 - true_positives_17: 2.0000 - true_negatives_17: 39.0000 - false_positives_17: 0.0000e+00 - false_negatives_17: 37.0000 - 25ms/epoch - 8ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.6785 - binary_accuracy: 0.9744 - auc_17: 0.9957 - precision_17: 1.0000 - true_positives_17: 37.0000 - true_negatives_17: 39.0000 - false_positives_17: 0.0000e+00 - false_negatives_17: 2.0000 - 50ms/epoch - 17ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.6606 - binary_accuracy: 0.9872 - auc_17: 0.9984 - precision_17: 1.0000 - true_positives_17: 38.0000 - true_negatives_17: 39.0000 - false_positives_17: 0.0000e+00 - false_negatives_17: 1.0000 - 19ms/epoch - 6ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.6359 - binary_accuracy: 0.9872 - auc_17: 0.9947 - precision_17: 1.0000 - true_positives_17: 38.0000 - true_negatives_17: 39.0000 - false_positives_17: 0.0000e+00 - false_negatives_17: 1.0000 - 34ms/epoch - 11ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.6072 - binary_accuracy: 0.9872 - auc_17: 0.9921 - precision_17: 1.0000 - true_positives_17: 38.0000 - true_negatives_17: 39.0000 - false_positives_17: 0.0000e+00 - false_negatives_17: 1.0000 - 40ms/epoch - 13ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.5807 - binary_accuracy: 0.9872 - auc_17: 0.9967 - precision_17: 1.0000 - true_positives_17: 38.0000 - true_negatives_17: 39.0000 - false_positives_17: 0.0000e+00 - false_negatives_17: 1.0000 - 21ms/epoch - 7ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.5599 - binary_accuracy: 0.9872 - auc_17: 0.9984 - precision_17: 1.0000 - true_positives_17: 38.0000 - true_negatives_17: 39.0000 - false_positives_17: 0.0000e+00 - false_negatives_17: 1.0000 - 26ms/epoch - 9ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.5431 - binary_accuracy: 0.9872 - auc_17: 1.0000 - precision_17: 1.0000 - true_positives_17: 38.0000 - true_negatives_17: 39.0000 - false_positives_17: 0.0000e+00 - false_negatives_17: 1.0000 - 21ms/epoch - 7ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.5301 - binary_accuracy: 0.9872 - auc_17: 1.0000 - precision_17: 1.0000 - true_positives_17: 38.0000 - true_negatives_17: 39.0000 - false_positives_17: 0.0000e+00 - false_negatives_17: 1.0000 - 22ms/epoch - 7ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "Epoch 1/10\n",
      "3/3 - 3s - loss: 0.6931 - binary_accuracy: 0.5063 - auc_18: 0.5189 - precision_18: 0.0000e+00 - true_positives_18: 0.0000e+00 - true_negatives_18: 40.0000 - false_positives_18: 0.0000e+00 - false_negatives_18: 39.0000 - 3s/epoch - 921ms/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.6880 - binary_accuracy: 0.5190 - auc_18: 0.9260 - precision_18: 1.0000 - true_positives_18: 1.0000 - true_negatives_18: 40.0000 - false_positives_18: 0.0000e+00 - false_negatives_18: 38.0000 - 12ms/epoch - 4ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.6774 - binary_accuracy: 0.9114 - auc_18: 0.9853 - precision_18: 1.0000 - true_positives_18: 32.0000 - true_negatives_18: 40.0000 - false_positives_18: 0.0000e+00 - false_negatives_18: 7.0000 - 28ms/epoch - 9ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.6592 - binary_accuracy: 0.9873 - auc_18: 0.9904 - precision_18: 1.0000 - true_positives_18: 38.0000 - true_negatives_18: 40.0000 - false_positives_18: 0.0000e+00 - false_negatives_18: 1.0000 - 34ms/epoch - 11ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.6360 - binary_accuracy: 0.9873 - auc_18: 0.9965 - precision_18: 1.0000 - true_positives_18: 38.0000 - true_negatives_18: 40.0000 - false_positives_18: 0.0000e+00 - false_negatives_18: 1.0000 - 28ms/epoch - 9ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.6099 - binary_accuracy: 0.9873 - auc_18: 0.9965 - precision_18: 1.0000 - true_positives_18: 38.0000 - true_negatives_18: 40.0000 - false_positives_18: 0.0000e+00 - false_negatives_18: 1.0000 - 9ms/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.5858 - binary_accuracy: 0.9873 - auc_18: 0.9974 - precision_18: 1.0000 - true_positives_18: 38.0000 - true_negatives_18: 40.0000 - false_positives_18: 0.0000e+00 - false_negatives_18: 1.0000 - 24ms/epoch - 8ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.5659 - binary_accuracy: 0.9873 - auc_18: 0.9990 - precision_18: 1.0000 - true_positives_18: 38.0000 - true_negatives_18: 40.0000 - false_positives_18: 0.0000e+00 - false_negatives_18: 1.0000 - 49ms/epoch - 16ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.5486 - binary_accuracy: 0.9873 - auc_18: 1.0000 - precision_18: 1.0000 - true_positives_18: 38.0000 - true_negatives_18: 40.0000 - false_positives_18: 0.0000e+00 - false_negatives_18: 1.0000 - 27ms/epoch - 9ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.5336 - binary_accuracy: 1.0000 - auc_18: 1.0000 - precision_18: 1.0000 - true_positives_18: 39.0000 - true_negatives_18: 40.0000 - false_positives_18: 0.0000e+00 - false_negatives_18: 0.0000e+00 - 17ms/epoch - 6ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "Epoch 1/10\n",
      "3/3 - 2s - loss: 0.6934 - binary_accuracy: 0.4684 - auc_19: 0.4776 - precision_19: 0.4844 - true_positives_19: 31.0000 - true_negatives_19: 6.0000 - false_positives_19: 33.0000 - false_negatives_19: 9.0000 - 2s/epoch - 792ms/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.6885 - binary_accuracy: 0.8354 - auc_19: 0.8375 - precision_19: 0.7547 - true_positives_19: 40.0000 - true_negatives_19: 26.0000 - false_positives_19: 13.0000 - false_negatives_19: 0.0000e+00 - 37ms/epoch - 12ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.6791 - binary_accuracy: 0.6962 - auc_19: 1.0000 - precision_19: 0.6250 - true_positives_19: 40.0000 - true_negatives_19: 15.0000 - false_positives_19: 24.0000 - false_negatives_19: 0.0000e+00 - 34ms/epoch - 11ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.6626 - binary_accuracy: 0.7722 - auc_19: 0.9994 - precision_19: 0.6897 - true_positives_19: 40.0000 - true_negatives_19: 21.0000 - false_positives_19: 18.0000 - false_negatives_19: 0.0000e+00 - 25ms/epoch - 8ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.6385 - binary_accuracy: 0.9367 - auc_19: 1.0000 - precision_19: 0.8889 - true_positives_19: 40.0000 - true_negatives_19: 34.0000 - false_positives_19: 5.0000 - false_negatives_19: 0.0000e+00 - 20ms/epoch - 7ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.6110 - binary_accuracy: 1.0000 - auc_19: 1.0000 - precision_19: 1.0000 - true_positives_19: 40.0000 - true_negatives_19: 39.0000 - false_positives_19: 0.0000e+00 - false_negatives_19: 0.0000e+00 - 19ms/epoch - 6ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.5869 - binary_accuracy: 0.9873 - auc_19: 1.0000 - precision_19: 1.0000 - true_positives_19: 39.0000 - true_negatives_19: 39.0000 - false_positives_19: 0.0000e+00 - false_negatives_19: 1.0000 - 19ms/epoch - 6ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.5665 - binary_accuracy: 1.0000 - auc_19: 1.0000 - precision_19: 1.0000 - true_positives_19: 40.0000 - true_negatives_19: 39.0000 - false_positives_19: 0.0000e+00 - false_negatives_19: 0.0000e+00 - 27ms/epoch - 9ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.5498 - binary_accuracy: 1.0000 - auc_19: 1.0000 - precision_19: 1.0000 - true_positives_19: 40.0000 - true_negatives_19: 39.0000 - false_positives_19: 0.0000e+00 - false_negatives_19: 0.0000e+00 - 63ms/epoch - 21ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.5365 - binary_accuracy: 1.0000 - auc_19: 1.0000 - precision_19: 1.0000 - true_positives_19: 40.0000 - true_negatives_19: 39.0000 - false_positives_19: 0.0000e+00 - false_negatives_19: 0.0000e+00 - 33ms/epoch - 11ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Classifier_Name': 'SA',\n",
       "  'Optimitied_Param': {},\n",
       "  'Score': 'out/libfeatureselection/T1/T1SEstacker//SA_score.pkl',\n",
       "  'Model_Path': '-',\n",
       "  'TimeToStartFit': '2023-07-22 02:01:39',\n",
       "  'TimeOfSummary': '2023-07-22 02:02:04',\n",
       "  'TimeSpend': '0:00:25.157071'},\n",
       " {'accuracy': 0.825,\n",
       "  'precision': 0.8095238095238095,\n",
       "  'f1_score': 0.8292682926829269,\n",
       "  'mmc': 0.6508140266182866,\n",
       "  'rocAUC': 0.8474999999999999,\n",
       "  'specificity': 0.8,\n",
       "  'sensitivity': 0.85,\n",
       "  'pro_cutoff': 0.50885713},\n",
       " {'accuracy': 0.8473684210526315,\n",
       "  'precision': 0.8738461538461537,\n",
       "  'f1_score': 0.8356674294431732,\n",
       "  'mmc': 0.7177854865345493,\n",
       "  'rocAUC': 0.8782222222222223,\n",
       "  'specificity': 0.8577777777777778,\n",
       "  'sensitivity': 0.8377777777777776,\n",
       "  'pro_cutoff': [0.5510745, 0.584809, 0.4764116, 0.50236607, 0.55200666]})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x270 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SA_Trainer().find_best(\n",
    "    X=pd.concat([digitaa_data['t_p'], digitaa_data['t_n']]),\n",
    "    y=np.concatenate([np.ones((digitaa_data['t_p'].shape[0], )), np.zeros((digitaa_data['t_n'].shape[0], ))]),\n",
    "    validation=(\n",
    "        pd.concat([digitaa_data['v_p'], digitaa_data['v_n']]),\n",
    "        np.concatenate([np.ones((digitaa_data['v_p'].shape[0], )), np.zeros((digitaa_data['v_n'].shape[0], ))]),\n",
    "    )\n",
    ").get_summary(\n",
    "    path_to_dir=\"out/libfeatureselection/T1/T1SEstacker/\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_type = 1\n",
    "job_name = \"T1-TT-rStacker\"\n",
    "path_to_score_dir = \"out/libfeatureselection/T1/T1SEstacker/model/\"\n",
    "path_to_dnnscore_dir = \"out/libfeatureselection/T1/T1SEstacker/\"\n",
    "path_to_model_score_path = \"out/libfeatureselection/T1/T1SEstacker/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from libfeatureselection import model_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allname_list = [\n",
    "    item['name']\n",
    "    for item in model_space.find_space\n",
    "]\n",
    "model_list_dict = { item['name']:item for item in model_space.find_space }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "def get_optimal_threshold(target: np.ndarray, predict: np.ndarray, multi_dim: int):\n",
    "    \n",
    "    if multi_dim is not None:\n",
    "        predict = predict[:, multi_dim]\n",
    "\n",
    "    predict = np.nan_to_num(\n",
    "        predict, copy=True, nan=0.0\n",
    "    )\n",
    "    fpr, tpr, thresholds = roc_curve(target, predict)\n",
    "    best_one_optimal_idx = np.argmax(tpr - fpr)\n",
    "    pro_cutoff = thresholds[best_one_optimal_idx]\n",
    "    predict_l = [1 if i >= pro_cutoff else 0 for i in predict]\n",
    "\n",
    "    return pro_cutoff\n",
    "\n",
    "def get_threshold_for_dict(_score_dict: dict, multi_dim: int = None):\n",
    "    # best_predicted_pair\n",
    "    _score_dict['best_predicted_pair_pro_cutoff'] = get_optimal_threshold(\n",
    "        target=_score_dict['best_predicted_pair'][1],\n",
    "        predict=_score_dict['best_predicted_pair'][0],\n",
    "        multi_dim=multi_dim\n",
    "    )\n",
    "    _score_dict['best_predicted_binary'] = (\n",
    "        _score_dict['best_predicted_pair'][0] >= _score_dict['best_predicted_pair_pro_cutoff']\n",
    "    ).astype(int)\n",
    "\n",
    "    if multi_dim is not None:\n",
    "        _score_dict['best_predicted_binary'] = _score_dict['best_predicted_binary'][:, multi_dim]\n",
    "\n",
    "    # best_5C_predicted_pair\n",
    "    _score_dict['best_5C_predicted_pair_pro_cutoff'] = [\n",
    "        get_optimal_threshold(\n",
    "            target=fold_item[1],\n",
    "            predict=fold_item[0],\n",
    "            multi_dim=multi_dim\n",
    "        )\n",
    "        for fold_item in _score_dict['best_5C_predicted_pair']\n",
    "    ]\n",
    "    _score_dict['best_5C_predicted_binary'] = [\n",
    "        (\n",
    "            _score_dict['best_5C_predicted_pair'][fold_id][0] >= _score_dict['best_5C_predicted_pair_pro_cutoff'][fold_id]\n",
    "        ).astype(int) \n",
    "        for fold_id in range(len(_score_dict['best_5C_predicted_pair']))\n",
    "    ]\n",
    "    _score_dict['best_5C_predicted_binary'] = [\n",
    "        _score_dict['best_5C_predicted_binary'][fold_id] if multi_dim is None else _score_dict['best_5C_predicted_binary'][fold_id][:, multi_dim]\n",
    "        for fold_id in range(len(_score_dict['best_5C_predicted_pair']))\n",
    "    ]\n",
    "\n",
    "    return _score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_dict = {\n",
    "    model_name: get_threshold_for_dict(\n",
    "        pickle.load(\n",
    "            gzip.open(f\"{path_to_score_dir}/ac/{model_name}_score.pkl.train\", \"rb\")\n",
    "        ),\n",
    "        multi_dim=1\n",
    "    )\n",
    "    for model_name in [\n",
    "        'SVC',\n",
    "        'GaussianNB',\n",
    "        'RandomForestClassifier',\n",
    "        'DecisionTreeClassifier'\n",
    "    ]\n",
    "} | {\n",
    "    \"BPBAac\": get_threshold_for_dict(\n",
    "        pickle.load(\n",
    "            gzip.open(f\"{path_to_score_dir}/bpb/SVC_score.pkl.train\", \"rb\")\n",
    "        ),\n",
    "        multi_dim=1\n",
    "    )\n",
    "} | {\n",
    "    model_name: get_threshold_for_dict(\n",
    "        pickle.load(\n",
    "            gzip.open(f\"{path_to_dnnscore_dir}/{model_name}_score.pkl.train\", \"rb\")\n",
    "        ),\n",
    "        multi_dim=0\n",
    "    )\n",
    "    for model_name in [\n",
    "        'DNN',\n",
    "        'RNN',\n",
    "        'SA',\n",
    "    ]\n",
    "}\n",
    "score_dict = {\n",
    "    model_name: get_threshold_for_dict(\n",
    "        pickle.load(\n",
    "            gzip.open(f\"{path_to_score_dir}/ac/{model_name}_score.pkl\", \"rb\")\n",
    "        ),\n",
    "        multi_dim=1\n",
    "    )\n",
    "    for model_name in [\n",
    "        'SVC',\n",
    "        'GaussianNB',\n",
    "        'RandomForestClassifier',\n",
    "        'DecisionTreeClassifier'\n",
    "    ]\n",
    "} | {\n",
    "    \"BPBAac\": get_threshold_for_dict(\n",
    "        pickle.load(\n",
    "            gzip.open(f\"{path_to_score_dir}/bpb/SVC_score.pkl\", \"rb\")\n",
    "        ),\n",
    "        multi_dim=1\n",
    "    )\n",
    "} | {\n",
    "    model_name: get_threshold_for_dict(\n",
    "        pickle.load(\n",
    "            gzip.open(f\"{path_to_dnnscore_dir}/{model_name}_score.pkl\", \"rb\")\n",
    "        ),\n",
    "        multi_dim=0\n",
    "    )\n",
    "    for model_name in [\n",
    "        'DNN',\n",
    "        'RNN',\n",
    "        'SA',\n",
    "    ]\n",
    "}\n",
    "voting_model_name_list = [\n",
    "    'SVC',\n",
    "    'GaussianNB',\n",
    "    'RandomForestClassifier',\n",
    "    'DecisionTreeClassifier',\n",
    "    \"BPBAac\",\n",
    "    'DNN',\n",
    "    'RNN',\n",
    "    'SA',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "train_tt_voting_score_pair = [\n",
    "    np.stack([\n",
    "        train_score_dict[model_name]['best_predicted_binary'] for model_name in voting_model_name_list\n",
    "    ], axis=1),\n",
    "    next(iter(train_score_dict.items()))[1]['best_predicted_pair'][1],\n",
    "]\n",
    "tt_voting_score_pair = [\n",
    "    np.stack([\n",
    "        score_dict[model_name]['best_predicted_binary'] for model_name in voting_model_name_list\n",
    "    ], axis=1),\n",
    "    next(iter(score_dict.items()))[1]['best_predicted_pair'][1],\n",
    "]\n",
    "\n",
    "tt_voting_score_pair[0] = SVC(probability=True).fit(\n",
    "    train_tt_voting_score_pair[0],\n",
    "    train_tt_voting_score_pair[1],\n",
    ").predict_proba(tt_voting_score_pair[0])\n",
    "\n",
    "train_cv_voting_score_pair_list = [\n",
    "    [\n",
    "        np.stack([\n",
    "            score_dict[model_name]['best_5C_predicted_binary'][fold_id] for model_name in voting_model_name_list\n",
    "        ], axis=1),\n",
    "        next(iter(score_dict.items()))[1]['best_5C_predicted_pair'][fold_id][1],\n",
    "    ]\n",
    "    for fold_id in range(len(next(iter(score_dict.items()))[1]['best_5C_predicted_pair']))\n",
    "]\n",
    "cv_voting_score_pair_list = [\n",
    "    [\n",
    "        np.stack([\n",
    "            score_dict[model_name]['best_5C_predicted_binary'][fold_id] for model_name in voting_model_name_list\n",
    "        ], axis=1),\n",
    "        next(iter(score_dict.items()))[1]['best_5C_predicted_pair'][fold_id][1],\n",
    "    ]\n",
    "    for fold_id in range(len(next(iter(score_dict.items()))[1]['best_5C_predicted_pair']))\n",
    "]\n",
    "for fold_id in range(len(next(iter(score_dict.items()))[1]['best_5C_predicted_pair'])):\n",
    "    cv_voting_score_pair_list[fold_id][0] = SVC(probability=True).fit(\n",
    "        train_cv_voting_score_pair_list[fold_id][0],\n",
    "        train_cv_voting_score_pair_list[fold_id][1],\n",
    "    ).predict_proba(cv_voting_score_pair_list[fold_id][0])\n",
    "\n",
    "os.makedirs(path_to_model_score_path, exist_ok=True)\n",
    "with gzip.open(f\"{path_to_model_score_path}/{job_name}_score.pkl\", \"wb\") as f:\n",
    "    pickle.dump(\n",
    "        {\n",
    "            \"best_predicted_pair\": tt_voting_score_pair,\n",
    "            \"best_5C_predicted_pair\": cv_voting_score_pair_list,\n",
    "        }, f\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TxSEml_Backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
