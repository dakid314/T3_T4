{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import typing\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.base import ClassifierMixin\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold,StratifiedShuffleSplit\n",
    "from sklearn.model_selection._search import BaseSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "import pymrmr\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from skopt.space import Real, Categorical\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_score, accuracy_score, f1_score, matthews_corrcoef, auc,precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def get_evaluation(label: list, pred: list, pro_cutoff: float = None):\n",
    "    fpr, tpr, thresholds = roc_curve(label, pred)\n",
    "    if pro_cutoff is None:\n",
    "        best_one_optimal_idx = np.argmax(tpr - fpr)\n",
    "        pro_cutoff = thresholds[best_one_optimal_idx]\n",
    "    pred_l = [1 if i >= pro_cutoff else 0 for i in pred]\n",
    "    #后面新增的计算prAUC\n",
    "    confusion_matrix_1d = confusion_matrix(label, pred_l).ravel()\n",
    "    confusion_dict = {N: n for N, n in zip(['tn', 'fp', 'fn', 'tp'], list(\n",
    "        confusion_matrix_1d * 2 / np.sum(confusion_matrix_1d)))}\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(label, pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    evaluation = {\n",
    "        \"accuracy\": accuracy_score(label, pred_l),\n",
    "        \"precision\": precision_score(label, pred_l),\n",
    "        \"f1_score\": f1_score(label, pred_l),\n",
    "        \"mmc\": matthews_corrcoef(label, pred_l),\n",
    "        \"rocAUC\": auc(fpr, tpr),\n",
    "        \"prAUC\": pr_auc,\n",
    "        \"specificity\": confusion_dict['tn'] / (confusion_dict['tn'] + confusion_dict['fp']),\n",
    "        \"sensitivity\": confusion_dict['tp'] / (confusion_dict['tp'] + confusion_dict['fn']),\n",
    "        'pro_cutoff': pro_cutoff\n",
    "    }\n",
    "    return evaluation\n",
    "\n",
    "def plot_roc_curve(target, pred, path_to_: str):\n",
    "    fpr, tpr, thresholds = roc_curve(target, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(19.2, 10.8))\n",
    "    plt.plot(fpr, tpr, color='red', lw=2,\n",
    "             label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC) curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.savefig(f\"{path_to_}\")\n",
    "    plt.clf()\n",
    "class MyOptimitzer:\n",
    "    def __init__(self, classifier_name: str, classifier_class: ClassifierMixin, classifier_param_dict: dict) -> None:\n",
    "        self.classifier_name = classifier_name\n",
    "        self.classifier_class = classifier_class\n",
    "        self.classifier_param_dict = classifier_param_dict\n",
    "\n",
    "        self.grid_search: BaseSearchCV = None\n",
    "        self.train_best_predicted_pair = None\n",
    "        self.train_best_5C_predicted_pair = None\n",
    "        self.best_predicted_pair = None\n",
    "        self.best_5C_predicted_pair = None\n",
    "        self.start_to_train_time = datetime.now()\n",
    "        self.end_of_train_time = None\n",
    "        pass\n",
    "\n",
    "    def find_best(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        validation: tuple,\n",
    "        search_method: typing.Literal[\"GridSearchCV\", \"BayesSearchCV\"],\n",
    "        n_jobs: int = 28\n",
    "    ):\n",
    "\n",
    "        \n",
    "\n",
    "        if search_method == \"GridSearchCV\":\n",
    "            self.grid_search = GridSearchCV(\n",
    "                self.classifier_class(),\n",
    "                param_grid=self.classifier_param_dict,\n",
    "                cv=StratifiedKFold(\n",
    "                    n_splits=5,\n",
    "                    shuffle=True,\n",
    "                    random_state=42\n",
    "                ),\n",
    "                scoring='roc_auc',\n",
    "                n_jobs=n_jobs,\n",
    "                refit=True\n",
    "            )\n",
    "        elif search_method == \"BayesSearchCV\":\n",
    "            self.grid_search = BayesSearchCV(\n",
    "                self.classifier_class(),\n",
    "                search_spaces=self.classifier_param_dict,\n",
    "                cv=StratifiedKFold(\n",
    "                    n_splits=5,\n",
    "                    shuffle=True,\n",
    "                    random_state=42\n",
    "                ),\n",
    "                scoring='roc_auc',\n",
    "                n_jobs=n_jobs,\n",
    "                n_points=n_jobs,\n",
    "                n_iter=5,\n",
    "                refit=True\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'search_method: typing.Literal[\"GridSearchCV\", \"BayesSearchCV\"]'\n",
    "            )\n",
    "        y_origin = y\n",
    "        if self.classifier_name == \"LabelPropagation\":\n",
    "            y = y.copy()\n",
    "            y[\n",
    "                np.random.choice(\n",
    "                    a=np.arange(X.shape[0]),\n",
    "                    size=max(int(X.shape[0] * 0.25), 1)\n",
    "                )\n",
    "            ] = -1\n",
    "        full_X = np.concatenate([\n",
    "            X, validation[0]\n",
    "        ])\n",
    "        full_y = np.concatenate([\n",
    "            y_origin, validation[1]\n",
    "        ])\n",
    "\n",
    "        self.grid_search.fit(full_X, full_y)\n",
    "        self.best_predicted_pair = [\n",
    "            np.nan_to_num(self.grid_search.predict_proba(\n",
    "                X=validation[0]\n",
    "            ), nan=0.0),\n",
    "            validation[1]\n",
    "        ]\n",
    "        self.train_best_predicted_pair = [\n",
    "            np.nan_to_num(self.grid_search.predict_proba(\n",
    "                X=X\n",
    "            ), nan=0.0),\n",
    "            y\n",
    "        ]\n",
    "\n",
    "        # 5倍交叉验证\n",
    "        \n",
    "        # 跑模型\n",
    "        self.best_5C_predicted_pair = []\n",
    "        self.train_best_5C_predicted_pair = []\n",
    "        for Kfold_id, (train_id, test_id) in enumerate(\n",
    "            StratifiedKFold(\n",
    "                n_splits=5,\n",
    "                shuffle=True,\n",
    "                random_state=42\n",
    "            ).split(full_X, full_y)\n",
    "        ):\n",
    "            \n",
    "\n",
    "            # 定义模型并加载参数\n",
    "            fiveC_model = self.classifier_class(\n",
    "                **self.grid_search.best_params_,\n",
    "            )\n",
    "            y_to_train = full_y[train_id].copy()\n",
    "            if self.classifier_name == \"LabelPropagation\":\n",
    "                y_to_train[\n",
    "                    np.random.choice(\n",
    "                        a=np.arange(y_to_train.shape[0]),\n",
    "                        size=max(int(y_to_train.shape[0] * 0.25), 1)\n",
    "                    )\n",
    "                ] = -1\n",
    "\n",
    "            \n",
    "            fiveC_model.fit(\n",
    "                full_X[train_id],\n",
    "                y_to_train\n",
    "            )\n",
    "\n",
    "            # 预测并记录\n",
    "            self.best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict_proba(\n",
    "                    X=full_X[test_id]\n",
    "                ), nan=0.0),\n",
    "                full_y[test_id]\n",
    "            ])\n",
    "            self.train_best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict_proba(\n",
    "                    X=full_X[train_id]\n",
    "                ), nan=0.0),\n",
    "                y_to_train\n",
    "            ])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_summary(self, path_to_dir: str = None):\n",
    "        os.makedirs(path_to_dir, exist_ok=True)\n",
    "        model_path = \"-\"\n",
    "        \n",
    "\n",
    "        model_path = f\"{path_to_dir}/{self.classifier_name}.pkl\"\n",
    "        if path_to_dir is not None:\n",
    "            with open(model_path, \"bw+\") as f:\n",
    "                pickle.dump(\n",
    "                    self.grid_search, f\n",
    "                )\n",
    "            \n",
    "        training_testing_performance = get_evaluation(\n",
    "            label=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0][:, 1],\n",
    "        )\n",
    "\n",
    "        # 计算5C中的平均表现\n",
    "        FiveFold_result = {}\n",
    "        for keys in training_testing_performance.keys():\n",
    "            value_list = []\n",
    "            for item in self.best_5C_predicted_pair:\n",
    "\n",
    "                item_performance = get_evaluation(\n",
    "                    label=item[1],\n",
    "                    pred=item[0][:, 1],\n",
    "                )\n",
    "                value_list.append(item_performance[keys])\n",
    "\n",
    "            if keys == \"pro_cutoff\":\n",
    "                FiveFold_result[keys] = value_list\n",
    "            else:\n",
    "                FiveFold_result[keys] = sum(value_list) / len(value_list)\n",
    "\n",
    "        self.end_of_train_time = datetime.now()\n",
    "\n",
    "        return pd.Series({\n",
    "                        \"Classifier_Name\": self.classifier_name,\n",
    "                        \"Optimitied_Param\": dict(self.grid_search.best_params_),\n",
    "                        \"Model_Path\": model_path\n",
    "                    } | FiveFold_result\n",
    "                        )\n",
    "\n",
    "#读取数据\n",
    "prot_type = ['T3','T4','T1','T2','T6'][3]\n",
    "cd_hit = [30,70,50][1]\n",
    "feature_list = ['18pp','AAC','BPBaac','CTDC','CTDT','CTriad','onehot',\n",
    "                'PC-PseAAC','ppt25','QSO','SC-PseAAC','CTDD','DPC']\n",
    "rate = ['1_1'][0]\n",
    "a = 0\n",
    "for feature_name in feature_list:\n",
    "    if feature_name in ['SC-PseAAC', 'PC-PseAAC']:\n",
    "        neg_df = pd.read_csv(f'/mnt/md0/Public/T3_T4/txseml_addon/out/libfeatureselection/{prot_type}/feature_research_neg/{cd_hit}/{feature_name}/{a}/all_n{prot_type}_{cd_hit}_{rate}.fasta.csv', header=None)\n",
    "        pos_df = pd.read_csv(f'/mnt/md0/Public/T3_T4/txseml_addon/out/libfeatureselection/{prot_type}/feature_research_pos/{prot_type}_training_{cd_hit}.fasta_{feature_name}.csv', header=None)\n",
    "    else:\n",
    "        neg_df = pd.read_csv(f'/mnt/md0/Public/T3_T4/txseml_addon/out/libfeatureselection/{prot_type}/feature_research_neg/{cd_hit}/{feature_name}/{a}/all_n{prot_type}_{cd_hit}_{rate}.fasta.csv')\n",
    "        pos_df = pd.read_csv(f'/mnt/md0/Public/T3_T4/txseml_addon/out/libfeatureselection/{prot_type}/feature_research_pos/{prot_type}_training_{cd_hit}.fasta_{feature_name}.csv')\n",
    "    if feature_name == 'BPBaac':\n",
    "        feature = pd.read_csv(f'/mnt/md0/Public/T3_T4/txseml_addon/out/libfeatureselection/{prot_type}/feature_research_neg/{cd_hit}/{feature_name}/{a}/all_n{prot_type}_{cd_hit}_{rate}.fasta.csv')\n",
    "    elif feature_name in ['SC-PseAAC', 'PC-PseAAC']:\n",
    "        pos_df1 = pos_df.iloc[0:,0:]\n",
    "        neg_df1 = neg_df.iloc[0:,0:]\n",
    "    else:\n",
    "        pos_df1 = pos_df.iloc[0:,1:]\n",
    "        neg_df1 = neg_df.iloc[0:,1:]\n",
    "    if  feature_name == 'BPBaac':\n",
    "        feature = feature.iloc[0:,1:]\n",
    "        num = len(feature)-len(pos_df)\n",
    "        neg_target = np.zeros((num))\n",
    "        pos_target = np.ones((len(pos_df)))\n",
    "        neg_target_series = pd.Series(neg_target)\n",
    "        pos_target_series = pd.Series(pos_target)\n",
    "    else:\n",
    "        feature = pd.concat([pos_df1, neg_df1])\n",
    "        neg_target = np.zeros((len(neg_df1)))\n",
    "        pos_target = np.ones((len(pos_df1)))\n",
    "        neg_target_series = pd.Series(neg_target)\n",
    "        pos_target_series = pd.Series(pos_target)\n",
    "\n",
    "\n",
    "\n",
    "    target = pd.concat([pos_target_series, neg_target_series], ignore_index=True)\n",
    "    print((target == 1).sum())\n",
    "    if feature_name == 'CTriad':\n",
    "\n",
    "        feature_ = np.array([eval(row) for row in feature['CTriad']])\n",
    "        target_ = target.values\n",
    "    else:\n",
    "        feature_ = feature.astype(\"float\").values\n",
    "        target_ = target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Blast.Applications import NcbiblastpCommandline\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "\n",
    "bac_type = ['T3','T4','T1','T2','T6'][3]\n",
    "folder_path = f'/mnt/md0/Public/T3_T4/data/new_{bac_type}/val_tofeature'\n",
    "files = os.listdir(folder_path)\n",
    "stand_ = ['strict','lossen']\n",
    "for stand in stand_:\n",
    "    for fasta_file in files:\n",
    "        negative_sequences = []\n",
    "    # 读取阴性蛋白质序列数据\n",
    "        for seq_record in SeqIO.parse(f\"{folder_path}/{fasta_file}\", \"fasta\"):\n",
    "            negative_sequences.append(seq_record)\n",
    "            # 执行blast比对\n",
    "        output_file = f\"{stand}_{fasta_file}.xml\"\n",
    "        blastp_cline = NcbiblastpCommandline(cmd='blastp', query=f\"/mnt/md0/Public/T3_T4/data/new_T2/pos/T2_training_30.fasta\", subject=f\"{folder_path}/{fasta_file}\", outfmt=5, out=output_file)\n",
    "        blastp_cline()\n",
    "\n",
    "            # 解析blast结果\n",
    "        from Bio.Blast import NCBIXML\n",
    "        blast_results = NCBIXML.parse(open(output_file))\n",
    "        filtered_sequences = []  # 存储经筛选后的阴性蛋白质序列\n",
    "\n",
    "        for result in blast_results:\n",
    "            for alignment in result.alignments:\n",
    "                for hsp in alignment.hsps:\n",
    "                    if stand == 'strict':\n",
    "                        if hsp.identities / alignment.length >= 0.7 and hsp.align_length / alignment.length >= 0.9:\n",
    "                            filtered_sequences.append(alignment.title.split()[1])\n",
    "                    if stand == 'lossen':\n",
    "                        if hsp.identities / alignment.length >= 0.3 and hsp.align_length / alignment.length >= 0.5:\n",
    "                            filtered_sequences.append(alignment.title.split()[1])\n",
    "        \n",
    "        # 输出筛选后的阴性蛋白质序列\n",
    "        # with open(f\"{fasta_file}_nonT4\", \"w\") as output_handle:\n",
    "        #     for seq_record in negative_sequences:\n",
    "        #         if seq_record.id not in filtered_sequences:\n",
    "        #             SeqIO.write(seq_record, output_handle, \"fasta\")\n",
    "        \n",
    "        with open(f\"{stand}_{fasta_file}\", \"w\") as output_handle:\n",
    "            for seq_record in negative_sequences:\n",
    "                if seq_record.id in filtered_sequences:\n",
    "                    SeqIO.write(seq_record, output_handle, \"fasta\")\n",
    "        print(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_score, accuracy_score, f1_score, matthews_corrcoef, recall_score,auc,precision_recall_curve\n",
    "import os\n",
    "feature_name_list = ['18pp','AAC','BPBaac','CTDC','CTDT','CTriad',\n",
    "                'PC-PseAAC','ppt25','QSO','SC-PseAAC']\n",
    "data = {'feature': '','batch':'','bac_name':'','stand':'', 'model': '', 'rate':'','rocAUC': '', 'prAUC': '', 'MCC': '', 'F1': '', \n",
    "        'Precision': '', 'Accuracy': '', 'Sensitivity': '', 'Specificity': '', 'FPR': '', 'Recall': '','pro_cutoff':''}\n",
    "df = pd.DataFrame(columns=data.keys())\n",
    "\n",
    "rate_list = ['1_1','1_10','1_30','1_50','1_80','1_100']\n",
    "\n",
    "bac_name = ['Ralstonia_pseudosolanacearum_GMI1000','Salmonella_LT2',\n",
    "            'Coxiella_burnetii_RSA_331','new_Pseudomonas_sp.MIS38',\n",
    "            'new_Burkholderia_mallei_ATCC_23344','new_Pseudomonas_aeruginosa_PAO1',\n",
    "            'new1_Coxiella_burnetii_RSA_331','new_Burkholderia_pseudomallei_1710b'][7]\n",
    "stand_ = ['lossen','strict']\n",
    "\n",
    "bac_type = ['T3','T4','T1','T2','T6'][3]\n",
    "\n",
    "cd_hit_ = [30,70]\n",
    "for cd_hit in cd_hit_:\n",
    "    for stand in stand_:\n",
    "        fasta_file =f\"/mnt/md0/Public/T3_T4/data/new_{bac_type}/val_data/{stand}_{bac_name}.fasta\"\n",
    "        protein_ids = []\n",
    "        for seq_record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "            protein_id = seq_record.id\n",
    "            protein_ids.append(protein_id)\n",
    "        for feature_name in feature_name_list:\n",
    "            batch = 0\n",
    "            while batch <5:\n",
    "                for model_name in [\"XGBClassifier\", \"GaussianNB\", \"GradientBoostingClassifier\",   \n",
    "                                        \"SVC\",\"KNeighborsClassifier\", \n",
    "                                        \"RandomForestClassifier\"]:\n",
    "                    for rate in rate_list:\n",
    "                        model_save_dir = f\"/mnt/md0/Public/T3_T4/model/{bac_type}/{cd_hit}_model/{feature_name}/{rate}/{batch}\"\n",
    "\n",
    "                        val_df = pd.read_csv(f'/mnt/md0/Public/T3_T4/txseml_addon/out/libfeatureselection/{bac_type}/val_data/{bac_name}.fasta_{feature_name}.csv')\n",
    "                        val_df1 = val_df.iloc[0:, 1:]\n",
    "                        \n",
    "                        target_list = val_df['protein_id']\n",
    "                        target = []\n",
    "                        for a in range(len(target_list)):\n",
    "                            if target_list[a] in protein_ids:\n",
    "                                target.append(1)\n",
    "                            else:\n",
    "                                target.append(0)\n",
    "                        feature = pd.DataFrame(val_df1)\n",
    "                        if feature_name == 'CTriad':\n",
    "                            feature_ = np.array([eval(row) for row in feature['CTriad']])\n",
    "                        else:\n",
    "                            feature_ = feature.astype(\"float\").values\n",
    "                            target_ = np.reshape(target, (len(target), 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wujiam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
