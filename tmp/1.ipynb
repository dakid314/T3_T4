{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_score, accuracy_score, f1_score, matthews_corrcoef, recall_score,auc,precision_recall_curve\n",
    "\n",
    "\n",
    "data = {'stand':'','rocAUC': '', 'prAUC': '', 'MCC': '', 'F1': '', \n",
    "        'Precision': '', 'Accuracy': '', 'Sensitivity': '', 'Specificity': '',\n",
    "        'FPR': '', 'Recall': '','pro_cutoff':''}\n",
    "df = pd.DataFrame(columns=data.keys())\n",
    "\n",
    "\n",
    "\n",
    "bac_name = ['Ralstonia_pseudosolanacearum_GMI1000','Salmonella_LT2','Coxiella_burnetii_RSA_331',\n",
    "            'new_Pseudomonas_sp.MIS38','new_Burkholderia_mallei_ATCC_23344','val'][0]\n",
    "\n",
    "\n",
    "bac_type = ['T3','T4','T1','T2','T5'][0]\n",
    "stand_ = ['lossen','strict']\n",
    "cd_hit = [30,70][1]\n",
    "\n",
    "for stand in stand_:\n",
    "    fasta_file =f\"/mnt/md0/Public/T3_T4/data/new_{bac_type}/val_data/{stand}_{bac_name}.fasta\"\n",
    "    protein_ids = []\n",
    "    for seq_record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        protein_id = seq_record.id\n",
    "        protein_ids.append(protein_id)\n",
    "    \n",
    "    for pro_cutoff in [0.1,0.2,0.3,0.4,0.5,\n",
    "                        0.6,0.7,0.8,0.9]: \n",
    "        val_df = pd.read_excel(f'T3/80.xlsx')\n",
    "        pred = val_df['Voting']\n",
    "        target_list = val_df['protein']\n",
    "        target = []\n",
    "        for a in range(len(target_list)):\n",
    "            if target_list[a] in protein_ids:\n",
    "                target.append(1)\n",
    "            else:\n",
    "                target.append(0)\n",
    "        \n",
    "        target_ = np.reshape(target, (len(target), 1))\n",
    "        predict_result_list = []\n",
    "\n",
    "\n",
    "        def calculate_fpr(y_true, y_pred):\n",
    "            tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "            fpr = fp / (fp + tn)\n",
    "            return fpr\n",
    "        fpr, tpr, thresholds = roc_curve(target_, pred)\n",
    "            \n",
    "            \n",
    "            \n",
    "        pred_l = [1 if i >= pro_cutoff else 0 for i in pred]\n",
    "        #后面新增的计算prAUC\n",
    "        confusion_matrix_1d = confusion_matrix(target_, pred_l).ravel()\n",
    "        confusion_dict = {N: n for N, n in zip(['tn', 'fp', 'fn', 'tp'], list(\n",
    "            confusion_matrix_1d * 2 / np.sum(confusion_matrix_1d)))}\n",
    "        \n",
    "        FPR = calculate_fpr(target_,pred_l)\n",
    "        \n",
    "        precision, recall, _ = precision_recall_curve(target_, pred)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        Recall = recall_score(target_, pred_l)\n",
    "        evaluation = {\n",
    "            \"stand\":stand,\n",
    "            \"rocAUC\": auc(fpr, tpr),\n",
    "            \"prAUC\": pr_auc,\n",
    "            \"MCC\": matthews_corrcoef(target_, pred_l),\n",
    "            \"F1\": f1_score(target_, pred_l),\n",
    "            \"Precision\": precision_score(target_, pred_l,zero_division=1),\n",
    "            \"Accuracy\": accuracy_score(target_, pred_l),\n",
    "            \"Sensitivity\": confusion_dict['tp'] / (confusion_dict['tp'] + confusion_dict['fn']),\n",
    "            \"Specificity\": confusion_dict['tn'] / (confusion_dict['tn'] + confusion_dict['fp']),\n",
    "            \"FPR\":FPR,\n",
    "            \"Recall\":Recall,\n",
    "            'pro_cutoff': pro_cutoff\n",
    "        }\n",
    "        df = pd.concat([df, pd.DataFrame(evaluation, index=[0])], ignore_index=True)\n",
    "\n",
    "df.to_excel(f'80.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_score, accuracy_score, f1_score, matthews_corrcoef, recall_score,auc,precision_recall_curve\n",
    "import os\n",
    "feature_data_set = []\n",
    "model_list = [\"XGBClassifier\", \"GaussianNB\", \"GradientBoostingClassifier\",   \n",
    "                                \"SVC\",\"KNeighborsClassifier\", \n",
    "                                \"RandomForestClassifier\"]\n",
    "feature_list = ['18pp','AAC','BPBaac','CTDC','CTDT','CTriad','onehot',\n",
    "            'PC-PseAAC','ppt25','QSO','SC-PseAAC','CTDD','DPC','ppt']\n",
    "rate = '1_100'\n",
    "data_dir = 'txseml_addon/out/libfeatureselection/T3/val_data'\n",
    "bac_name = 'new_Ralstonia_pseudosolanacearum_GMI1000.fasta'\n",
    "seq_id_list = []\n",
    "for record in SeqIO.parse('data/new_T3/val_tofeature/new_Ralstonia_pseudosolanacearum_GMI1000.fasta', \"fasta\"):\n",
    "        seq_id_list.append(record.id)\n",
    "allresult_dict = {}\n",
    "for model_name in model_list:\n",
    "    \n",
    "    for feature_name in feature_list:\n",
    "        tmp_result_dict = {}\n",
    "        a = 0\n",
    "        while a< 5:\n",
    "            model_save_dir = f\"/mnt/md0/Public/T3_T4/model/T3/70_model/{feature_name}/{rate}/{a}\"\n",
    "            \n",
    "            val_df = pd.read_csv(f'{data_dir}/{bac_name}_{feature_name}.csv')\n",
    "            \n",
    "            val_df1 = val_df.iloc[0:, 1:]\n",
    "            \n",
    "            feature = pd.DataFrame(val_df1)\n",
    "            if feature_name == 'CTriad':\n",
    "                feature_ = np.array([eval(row) for row in feature['CTriad']])\n",
    "            else:\n",
    "                feature_ = feature.astype(\"float\").values\n",
    "            \n",
    "            model = pickle.load(open(f\"{model_save_dir}/{model_name}.pkl\", \"br\"))\n",
    "            \n",
    "            with open(f\"{rate}_threshold.json\", \"r\", encoding=\"UTF-8\") as f:\n",
    "                threshold_dict = json.load(f)[f'{model_name}']\n",
    "            \n",
    "            tmp_result_dict[a] = (\n",
    "                np.nan_to_num(model.predict_proba(feature_), nan=0.0)[:, 1] >= threshold_dict[feature_name]\n",
    "                ).astype(int)\n",
    "            a+=1\n",
    "        tmp = np.stack([\n",
    "                tmp_result_dict[a] for a in [0,1,2,3,4]\n",
    "            ], axis=1).mean(axis=1)\n",
    "        pred = pd.DataFrame(tmp)\n",
    "        feature_data_set.append({\n",
    "            \"name\": f\"{model_name}_{feature_name}\",\n",
    "            \"submit\": pred,\n",
    "        })\n",
    "         \n",
    "            \n",
    "data_set_split = {\n",
    "    datatype: pd.concat([\n",
    "        item[datatype] for item in feature_data_set\n",
    "    ], axis=1)\n",
    "    for datatype in [\"submit\",]\n",
    "}\n",
    "data = pd.DataFrame(data_set_split[\"submit\"])\n",
    "data.insert(0, \"protein_id\", seq_id_list)\n",
    "data.to_csv('feature.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('feature.csv',header=None)\n",
    "\n",
    "feature = df.iloc[0:,1:]\n",
    "\n",
    "protein = list(df[0])\n",
    "fasta_file =f\"blast_out/T3/Ralstonia_pseudosolanacearum_GMI1000/lossen/lossen_Ralstonia_pseudosolanacearum_GMI1000_blast.fasta\"\n",
    "protein_ids = []\n",
    "for seq_record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    protein_id = seq_record.id\n",
    "    protein_ids.append(protein_id)\n",
    "target = []\n",
    "for id in protein:\n",
    "    if id in protein_ids:\n",
    "        target.append(1)\n",
    "    else:\n",
    "        target.append(0)\n",
    "        \n",
    "feature_ = feature.astype(\"float\").values\n",
    "target_ = np.reshape(target, (len(target), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('feature.csv',header=None)\n",
    "\n",
    "feature = df.iloc[0:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "clo = list(df.columns)\n",
    "fir = clo.index('ABS1')\n",
    "las = clo.index('ABS33')\n",
    "label = df.loc[0:6,'ABS34']\n",
    "feature = df.iloc[0:7,fir:las+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ = feature.astype(\"int\").values\n",
    "label_= label.astype(\"int\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.iloc[7:8,fir:las+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    " \n",
    "# 生成模拟数据\n",
    "np.random.seed(42)\n",
    "X = np.sort(5 * np.random.rand(100, 1), axis=0)\n",
    "y = np.sin(X).ravel() + np.random.normal(0, 0.1, X.shape[0])\n",
    " \n",
    "# 将数据集划分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# 绘制数据点\n",
    "plt.scatter(feature_, label_, color='darkorange', label='data')\n",
    "plt.title('Data Points')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义支持向量机回归模型，使用RBF核函数\n",
    "svr = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    " \n",
    "# 训练模型\n",
    "svr.fit(feature_, label_)\n",
    " \n",
    "# 对测试集进行预测\n",
    "#y_pred = svr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svr.predict(test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[7,'ABS34']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算均方误差 (MSE) 和决定系数 (R²)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    " \n",
    "print(\"均方误差 (MSE):\", mse)\n",
    "print(\"决定系数 (R²):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制测试集预测值与实际值的对比图\n",
    "plt.scatter(X_test, y_test, color='darkorange', label='Actual')\n",
    "plt.scatter(X_test, y_pred, color='navy', label='Predicted')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=2, label='SVR Model')\n",
    "plt.title('SVR: Actual vs Predicted')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Target')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wujiam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
